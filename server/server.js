import express from 'express';
import cors from 'cors';
import pg from 'pg';
import dotenv from 'dotenv';
import fetch from 'node-fetch'; // Ensure node-fetch is available or use global fetch in Node 18+
import multer from 'multer';
import AdmZip from 'adm-zip';
import fs from 'fs';
import zlib from 'zlib';
import path from 'path';
import { fileURLToPath } from 'url';
import { analyzeUsersDeterministic } from './analyzers/userRules.js';
import { WebAuthentikSetup } from './authentik-setup.js';
import { CopilotClient, COPILOT_MODELS } from './copilot.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;

// Database Configuration
const pool = new pg.Pool({
  connectionString: process.env.DATABASE_URL || 'postgresql://postgres:postgres@db:5432/postgres',
});

// Automatic Database Initialization
async function initializeDatabase() {
  try {
    const initSqlPath = path.join(__dirname, 'init.sql');
    if (fs.existsSync(initSqlPath)) {
      const initSql = fs.readFileSync(initSqlPath, 'utf8');
      console.log('üîÑ Initializing database schema...');
      await pool.query(initSql);
      console.log('‚úÖ Database schema initialized successfully');
    } else {
      console.warn('‚ö†Ô∏è init.sql not found, skipping schema initialization');
    }
  } catch (error) {
    console.error('‚ùå Failed to initialize database:', error.message);
    // Optional: exit process or let it continue depending on criticality
  }
}

// Run initialization on startup
initializeDatabase();


// Middleware
app.use(cors());
app.use(express.json({ limit: '500mb' }));
app.use(express.text({ limit: '500mb' }));

// Constants
const CATEGORIES = [
  'Users', 'GPOs', 'Computers', 'OUs', 'Groups', 'Domains',
  'Containers', 'ACLs', 'CertServices', 'Meta', 'DCHealth', 'DNS', 'DHCP', 'Security', 'Kerberos', 'Sites',
  'FSMORolesHealth', 'ReplicationStatus', 'ReplicationHealthAllDCs', 'LingeringObjectsRisk', 'TrustHealth', 'OrphanedTrusts',
  'DNSRootHints', 'DNSConflicts', 'DNSScavengingDetailed', 'DHCPRogueServers', 'DHCPOptionsAudit',
  'PasswordPolicies'
];

const MAX_PROMPT = 8000;
const CHUNK_SIZE = 50;
const MAX_PARALLEL_CHUNKS = 3;

// =============================================================================
// v1.8.0: ANTHROPIC MODEL SELECTION - Claude 4.5 (Opus & Sonnet)
// Dynamic model selection based on category complexity
// =============================================================================
const ANTHROPIC_MODELS = {
  OPUS: 'claude-opus-4-5-20251101',    // Released Nov 2025 - Premium model
  SONNET: 'claude-sonnet-4-5-20250929'  // Released Sep 2025 - Best balance
};

// Categories that require deeper analysis ‚Üí Use Opus 4.5
// These involve complex security implications, privilege escalation paths, or critical infrastructure
const OPUS_CATEGORIES = new Set([
  'Kerberos',       // Golden Ticket, delegation, encryption analysis
  'Security',       // NTLM, SMB, LDAP signing, critical configs
  'ACLs',           // Complex permission analysis, privilege escalation paths
  'TrustHealth',    // Inter-domain trust relationships, SID filtering
  'CertServices',   // PKI vulnerabilities (ESC1-ESC8), template analysis
  'FSMORolesHealth' // Critical FSMO roles, domain operation health
]);

/**
 * Select the appropriate Claude model based on category complexity
 * @param {string} category - The AD category being analyzed
 * @param {boolean} forceOpus - Override to always use Opus (for deep analysis requests)
 * @returns {string} - The model ID to use
 */
function selectAnthropicModel(category, forceOpus = false) {
  if (forceOpus) {
    console.log(`[${timestamp()}] [ModelSelect] Forced Opus 4.5 for ${category}`);
    return ANTHROPIC_MODELS.OPUS;
  }

  if (OPUS_CATEGORIES.has(category)) {
    console.log(`[${timestamp()}] [ModelSelect] Using Opus 4.5 for complex category: ${category}`);
    return ANTHROPIC_MODELS.OPUS;
  }

  console.log(`[${timestamp()}] [ModelSelect] Using Sonnet 4.5 for category: ${category}`);
  return ANTHROPIC_MODELS.SONNET;
}

// Helper: Log to DB
const timestamp = () => new Date().toISOString();

async function addLog(assessmentId, level, message, categoryId = null) {
  try {
    console.log(`[${timestamp()}] [${level.toUpperCase()}] ${message}`);
    await pool.query(
      'INSERT INTO assessment_logs (assessment_id, level, message, category_id) VALUES ($1, $2, $3, $4)',
      [assessmentId, level, message, categoryId]
    );
  } catch (error) {
    console.error(`[${timestamp()}] ‚ùå Error logging to DB:`, error.message);
  }
}

// Helper: Sanitize text to remove null bytes and other problematic characters
function sanitizeText(text) {
  if (!text) return '';
  // Ensure text is a string before calling .replace()
  const str = typeof text === 'string' ? text : String(text);
  // Remove null bytes (0x00) and other control characters except newlines and tabs
  return str.replace(/\x00/g, '').replace(/[\x01-\x08\x0B-\x0C\x0E-\x1F\x7F]/g, '');
}

// Helper: Chunk array
function chunkArray(array, size) {
  const result = [];
  for (let i = 0; i < array.length; i += size) {
    result.push(array.slice(i, i + size));
  }
  return result;
}

// Helper: Get system configuration
// Helper: Get system configuration with Env Fallback
async function getConfig(key) {
  try {
    const result = await pool.query('SELECT value FROM system_config WHERE key = $1', [key]);
    if (result.rows[0]?.value) return result.rows[0].value;
  } catch (error) {
    // console.error(`[${timestamp()}] Error getting config ${key}:`, error.message);
  }

  // Fallback to Environment Variables
  const envKey = key.toUpperCase();
  return process.env[envKey] || null;
}

// Helper: Set system configuration
async function setConfig(key, value) {
  try {
    await pool.query(
      'INSERT INTO system_config (key, value, updated_at) VALUES ($1, $2, CURRENT_TIMESTAMP) ON CONFLICT (key) DO UPDATE SET value = $2, updated_at = CURRENT_TIMESTAMP',
      [key, value]
    );
    return true;
  } catch (error) {
    console.error(`[${timestamp()}] Error setting config ${key}:`, error.message);
    return false;
  }
}

// =============================================================================
// v2.0.0: GITHUB COPILOT INTEGRATION
// Allows using GitHub Copilot subscription for AI analysis
// =============================================================================
const copilotClient = new CopilotClient(getConfig, setConfig);

// Helper: Extract Category Data
// v1.8.1: Added alias mapping for common category name variations
const CATEGORY_ALIASES = {
  'sites': ['sitetopology', 'adtopology', 'topology'],
  'replicationstatus': ['replicationhealthalldcs', 'replication', 'adreplication'],
};

function extractCategoryData(jsonData, categoryName) {
  // First try exact match (case-insensitive)
  let categoryKey = Object.keys(jsonData).find(key =>
    key.toLowerCase() === categoryName.toLowerCase()
  );

  // If not found, try aliases
  if (!categoryKey) {
    const aliases = CATEGORY_ALIASES[categoryName.toLowerCase()] || [];
    for (const alias of aliases) {
      categoryKey = Object.keys(jsonData).find(key =>
        key.toLowerCase() === alias.toLowerCase()
      );
      if (categoryKey) {
        console.log(`[extractCategoryData] Using alias '${categoryKey}' for category '${categoryName}'`);
        break;
      }
    }
  }

  if (!categoryKey || !jsonData[categoryKey]) return null;

  const categoryData = jsonData[categoryKey];
  let result = [];

  // FIX v1.7.0: Validaci√≥n robusta de categoryData.Data
  if (categoryData.Data !== undefined && categoryData.Data !== null) {
    // Validar que Data no sea null, undefined, o empty string
    if (Array.isArray(categoryData.Data)) {
      // Filtrar elementos null/undefined del array
      result = categoryData.Data.filter(item => item !== null && item !== undefined);
    } else if (typeof categoryData.Data === 'object' && Object.keys(categoryData.Data).length > 0) {
      result = [categoryData.Data];
    } else if (categoryData.Data === '' || (typeof categoryData.Data === 'object' && Object.keys(categoryData.Data).length === 0)) {
      // Empty string or empty object - return empty array (not null to allow filtering)
      console.log(`[extractCategoryData] Warning: ${categoryName}.Data is empty, skipping`);
      result = [];
    } else {
      // Primitive non-empty value, wrap in array
      result = [categoryData.Data];
    }
  } else if (Array.isArray(categoryData)) {
    // Direct array format: { CategoryName: [...] }
    result = categoryData.filter(item => item !== null && item !== undefined);
  } else if (typeof categoryData === 'object' && Object.keys(categoryData).length > 0) {
    // Single object format: { CategoryName: { prop: value } }
    result = [categoryData];
  } else {
    // Invalid or empty data
    console.log(`[extractCategoryData] Warning: ${categoryName} has no valid data structure`);
    return null;
  }

  // Final validation: ensure we don't return array with only invalid items
  if (result.length === 0) {
    console.log(`[extractCategoryData] ${categoryName}: No valid items after filtering`);
  }

  // Smart Filtering to reduce AI hallucinations and token usage
  // v1.7.0: Added detailed logging for filter transparency
  if (categoryName.toLowerCase() === 'users' && result.length > 0) {
    const originalCount = result.length;
    const filterStats = {
      disabled: 0, passwordNeverExpires: 0, passwordNotRequired: 0,
      delegation: 0, privileged: 0, adminCount: 0,
      asrepRoastable: 0, kerberoastable: 0
    };

    result = result.filter(user => {
      if (!user) return false;

      // Track each risk flag
      if (user.Enabled === false) filterStats.disabled++;
      if (user.PasswordNeverExpires === true) filterStats.passwordNeverExpires++;
      if (user.PasswordNotRequired === true) filterStats.passwordNotRequired++;
      if (user.TrustedForDelegation === true) filterStats.delegation++;
      if (user.IsPrivileged === true) filterStats.privileged++;
      if (user.AdminCount === 1) filterStats.adminCount++;
      if (user.DoNotRequirePreAuth === true || user.IsASREPRoastable === true) filterStats.asrepRoastable++;
      if (user.IsKerberoastable === true) filterStats.kerberoastable++;

      // Keep if any risk/relevant flag is present
      return (
        user.Enabled === false ||
        user.PasswordNeverExpires === true ||
        user.PasswordNotRequired === true ||
        user.TrustedForDelegation === true ||
        user.IsPrivileged === true ||
        user.AdminCount === 1 ||
        user.DoNotRequirePreAuth === true ||
        user.IsASREPRoastable === true ||
        user.IsKerberoastable === true
      );
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Users' category reduced from ${originalCount} to ${result.length} items (keeping only high-risk objects)`);
      console.log(`[SmartFilter] Users breakdown: disabled=${filterStats.disabled}, pwdNeverExp=${filterStats.passwordNeverExpires}, pwdNotReq=${filterStats.passwordNotRequired}, delegation=${filterStats.delegation}, privileged=${filterStats.privileged}, adminCount=${filterStats.adminCount}, asrep=${filterStats.asrepRoastable}, kerberoast=${filterStats.kerberoastable}`);
    }
  }

  // Smart Filtering for Computers
  // FIX v1.7.0: Added Windows Server 2012/2012 R2 (EOL October 2023) to legacy list + detailed logging
  if (categoryName.toLowerCase() === 'computers' && result.length > 0) {
    const originalCount = result.length;
    const filterStats = { stale: 0, delegation: 0, disabled: 0, legacyOS: 0, noLAPS: 0, weakEncryption: 0 };

    result = result.filter(computer => {
      if (!computer) return false;

      const os = (computer.OperatingSystem || '').toLowerCase();
      // Legacy OS detection - includes all EOL Windows versions
      const isLegacy = os.includes('2012') || os.includes('2008') || os.includes('2003') ||
                       os.includes('2000') || os.includes('xp') || os.includes('vista') ||
                       os.includes('windows 7') || os.includes('windows 8');

      // Track each risk flag
      if (computer.IsStale === true) filterStats.stale++;
      if (computer.TrustedForDelegation === true) filterStats.delegation++;
      if (computer.Enabled === false) filterStats.disabled++;
      if (isLegacy) filterStats.legacyOS++;
      if (computer.LAPSEnabled === false && os.includes('server')) filterStats.noLAPS++;
      if (computer.SupportedEncryptionTypes?.includes('RC4')) filterStats.weakEncryption++;

      return (
        computer.IsStale === true ||
        computer.TrustedForDelegation === true ||
        computer.Enabled === false ||
        isLegacy ||
        (computer.LAPSEnabled === false && os.includes('server')) ||
        (computer.SupportedEncryptionTypes && computer.SupportedEncryptionTypes.includes('RC4'))
      );
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Computers' category reduced from ${originalCount} to ${result.length} items`);
      console.log(`[SmartFilter] Computers breakdown: stale=${filterStats.stale}, delegation=${filterStats.delegation}, disabled=${filterStats.disabled}, legacyOS=${filterStats.legacyOS}, noLAPS=${filterStats.noLAPS}, weakEncryption=${filterStats.weakEncryption}`);
    }
  }

  // Smart Filtering for Groups (Focus on Privileged or Empty)
  // v1.7.0: Fixed redundant logic and added detailed logging
  if (categoryName.toLowerCase() === 'groups' && result.length > 0) {
    const originalCount = result.length;
    const filterStats = { privileged: 0, empty: 0, excessiveMembers: 0 };

    result = result.filter(group => {
      if (!group) return false;

      // Check if privileged (Tier 0/1 administrative groups)
      const isPrivileged = group.IsPrivileged === true;
      if (isPrivileged) filterStats.privileged++;

      // v1.7.0: Fixed - Use single source of truth for empty check
      // Prefer MemberCount if available, fallback to Members array
      const memberCount = group.MemberCount !== undefined
        ? group.MemberCount
        : (group.Members ? group.Members.length : undefined);
      const isEmpty = memberCount === 0;
      if (isEmpty) filterStats.empty++;

      // NEW v1.7.0: Groups with excessive members (potential over-permissioning)
      const hasExcessiveMembers = memberCount !== undefined && memberCount > 50;
      if (hasExcessiveMembers) filterStats.excessiveMembers++;

      return isPrivileged || isEmpty || hasExcessiveMembers;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Groups' category reduced from ${originalCount} to ${result.length} items`);
      console.log(`[SmartFilter] Groups breakdown: privileged=${filterStats.privileged}, empty=${filterStats.empty}, excessiveMembers=${filterStats.excessiveMembers}`);
    }
  }

  // =============================================================================
  // SMART FILTERING v1.6.0 - Based on Industry Standards (CIS, PingCastle, Microsoft)
  // =============================================================================

  // Smart Filtering for GPOs (Focus on Problematic GPOs)
  // Source: CIS Benchmark, PingCastle, Microsoft Best Practices
  if (categoryName.toLowerCase() === 'gpos' && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(gpo => {
      // Threshold: CIS recommends keeping GPOs focused and small
      const settingsCount = gpo.SettingsCount || gpo.TotalSettings || 0;
      const hasNoLinks = !gpo.Links || gpo.Links.length === 0 || gpo.LinksTo?.length === 0;
      const isDisabled = gpo.GpoStatus === 'AllSettingsDisabled' || gpo.GpoStatus === 'UserSettingsDisabled' || gpo.GpoStatus === 'ComputerSettingsDisabled';
      const hasVersionMismatch = gpo.UserVersionDS !== gpo.UserVersionSysvol || gpo.ComputerVersionDS !== gpo.ComputerVersionSysvol;
      // CIS: GPOs should be small and focused, >30 settings indicates sprawl
      const isMonolithic = settingsCount > 30;
      // PingCastle: Check for non-admin users with GPO edit permissions
      const hasDangerousPermissions = gpo.Permissions?.some(p =>
        p.Permission === 'GpoEditDeleteModifySecurity' &&
        !['Domain Admins', 'Enterprise Admins', 'Admins. del dominio', 'Administradores de empresas', 'SYSTEM'].includes(p.Trustee)
      );
      // NEW: GPO has WMI filter (complexity indicator)
      const hasWMIFilter = gpo.WmiFilter && gpo.WmiFilter !== '';
      // NEW: GPO modified recently but not linked (potential test GPO left behind)
      const isRecentlyModified = gpo.ModificationTime && (Date.now() - new Date(gpo.ModificationTime).getTime()) < 30 * 24 * 60 * 60 * 1000;
      const isOrphanedRecent = hasNoLinks && isRecentlyModified;

      return (
        hasNoLinks || // GPOs hu√©rfanas (PingCastle rule)
        isDisabled || // GPOs deshabilitadas
        hasVersionMismatch || // Problemas de replicaci√≥n SYSVOL
        isMonolithic || // GPOs monol√≠ticas (CIS)
        hasDangerousPermissions || // Permisos peligrosos (PingCastle)
        isOrphanedRecent // Recently created but not linked
      );
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'GPOs' category reduced from ${originalCount} to ${result.length} items (keeping only problematic GPOs)`);
    }
  }

  // Smart Filtering for DNS (Focus on Issues)
  // Source: Microsoft DNS Best Practices, CIS
  // FIX v1.7.0: Iterate ALL items, not just check result[0]
  if (categoryName.toLowerCase() === 'dns' && result.length > 0) {
    // Check if ANY item in the array has the expected DNS structure
    const hasDNSStructure = result.some(item =>
      item && (item.SecurityIssues !== undefined || item.ScavengingEnabled !== undefined ||
               item.DynamicUpdate !== undefined || item.Forwarders !== undefined || item.ZoneTransfer !== undefined)
    );

    if (hasDNSStructure) {
      const originalCount = result.length;
      result = result.filter(item => {
        if (!item) return false;
        return (
          (item.SecurityIssues && Array.isArray(item.SecurityIssues) && item.SecurityIssues.length > 0) ||
          item.ScavengingEnabled === false || // CIS: Scavenging should be enabled
          item.DynamicUpdate === 'NonsecureAndSecure' || // Microsoft: Insecure dynamic updates
          item.DynamicUpdate === 'Nonsecure' ||
          // Public DNS forwarders without conditional
          (item.Forwarders && Array.isArray(item.Forwarders) && item.Forwarders.some(f =>
            typeof f === 'string' && (f.includes('8.8.8.8') || f.includes('1.1.1.1'))
          )) ||
          // Zone transfer to any
          item.ZoneTransfer === 'Any' ||
          // NEW v1.7.0: Aging/Scavenging not configured properly
          (item.AgingEnabled === false && item.ZoneType === 'Primary') ||
          // NEW v1.7.0: Stale DNS records threshold exceeded
          (item.StaleRecordCount && item.StaleRecordCount > 100)
        );
      });
      if (originalCount !== result.length) {
        console.log(`[SmartFilter] 'DNS' category reduced from ${originalCount} to ${result.length} items`);
      }
    }
  }

  // NEW: Inject DNS Forwarders configuration to DNS category
  // DNS Forwarders are collected in DNSConfiguration.Forwarders but not extracted by default
  if (categoryName.toLowerCase() === 'dns' && jsonData.DNSConfiguration?.Forwarders) {
    const forwarders = jsonData.DNSConfiguration.Forwarders;
    if (Array.isArray(forwarders) && forwarders.length > 0) {
      // Add forwarders as a special object type to the DNS analysis
      forwarders.forEach(fwd => {
        if (fwd && fwd.Forwarders && fwd.Forwarders.length > 0) {
          result.push({
            Type: 'ForwardersConfig',
            DCName: fwd.DCName,
            Forwarders: fwd.Forwarders,
            ForwardingTimeout: fwd.ForwardingTimeout,
            IsSlave: fwd.IsSlave,
            SecurityWarning: fwd.SecurityWarning || null,
            // Flag for easy identification by LLM
            _isForwarderConfig: true
          });
        }
      });
      console.log(`[extractCategoryData] Added ${forwarders.length} DNS Forwarder configs to DNS category`);
    }
  }

  // Smart Filtering for DCHealth (Focus on Unhealthy DCs)
  // Source: Microsoft TechNet, Quest AD Health
  if (categoryName.toLowerCase() === 'dchealth' && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(dc => {
      const hasErrors = dc.Errors && dc.Errors.length > 0;
      const hasWarnings = dc.Warnings && dc.Warnings.length > 0;
      const isUnhealthy = dc.OverallHealth === 'Critical' || dc.OverallHealth === 'Warning' || dc.Health === 'Unhealthy';
      const hasServiceIssues = dc.ServicesStatus && Object.values(dc.ServicesStatus).some(s => s !== 'Running');
      // Adjusted: 5GB is more critical threshold for DC (SYSVOL needs space)
      const hasLowDiskSpace = dc.FreeDiskSpaceGB && dc.FreeDiskSpaceGB < 5;
      // NEW: DC uptime issues (too short = instability, too long = missing patches)
      const hasUptimeIssue = (dc.UptimeDays && dc.UptimeDays < 1) || (dc.UptimeDays && dc.UptimeDays > 90);
      // NEW: DC running legacy OS (EOL)
      const isLegacyOS = dc.OperatingSystem && (dc.OperatingSystem.includes('2008') || dc.OperatingSystem.includes('2012'));
      // NEW: DC not a Global Catalog in multi-domain
      const notGC = dc.IsGlobalCatalog === false;

      return hasErrors || hasWarnings || isUnhealthy || hasServiceIssues || hasLowDiskSpace || hasUptimeIssue || isLegacyOS || notGC;
    });

    if (result.length === 0 && originalCount > 0) {
      result = [{ Summary: 'All Domain Controllers are healthy', HealthyCount: originalCount }];
    }

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'DCHealth' category reduced from ${originalCount} to ${result.length} items (keeping only unhealthy DCs)`);
    }
  }

  // Smart Filtering for Replication (Focus on Failures)
  // Source: Microsoft TechNet replication best practices
  const replicationCategories = ['replicationhealthalldcs', 'replicationstatus'];
  if (replicationCategories.includes(categoryName.toLowerCase()) && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(rep => {
      const hasFailed = rep.LastReplicationResult !== 0 && rep.LastReplicationResult !== undefined;
      const hasError = rep.Status === 'Failed' || rep.Status === 'Error';
      const isStale = rep.ConsecutiveFailures > 0;
      // Microsoft: Intrasite should replicate within 5 minutes, intersite within schedule
      // Using 60 minutes as universal threshold for "concerning" latency
      const hasHighLatency = rep.LatencyMinutes && rep.LatencyMinutes > 60;
      // NEW: Replication never succeeded
      const neverReplicated = rep.LastReplicationSuccess === null || rep.LastReplicationSuccess === undefined;
      // NEW: USN Rollback detection (critical - Microsoft)
      const hasUSNRollback = rep.USNRollbackDetected === true;

      return hasFailed || hasError || isStale || hasHighLatency || neverReplicated || hasUSNRollback;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Replication' category reduced from ${originalCount} to ${result.length} items (keeping only failures)`);
    }
  }

  // Smart Filtering for Trusts (Focus on Broken/Risky Trusts)
  // Source: Microsoft Trust Security, PingCastle
  const trustCategories = ['trusthealth', 'orphanedtrusts'];
  if (trustCategories.includes(categoryName.toLowerCase()) && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(trust => {
      const isBroken = trust.ValidationStatus !== 'Healthy' && trust.ValidationStatus !== undefined;
      const hasIssues = trust.Issues && trust.Issues.length > 0;
      // Microsoft: SID Filtering prevents SID History injection attacks
      const noSIDFiltering = trust.SIDFilteringEnabled === false || trust.SIDFilteringQuarantined === false;
      const isOrphaned = trust.Status === 'ORPHANED' || trust.Status === 'SUSPICIOUS';
      // Trust password should rotate automatically; >180 days indicates issue
      const oldPassword = trust.PasswordAgeDays && trust.PasswordAgeDays > 180;
      // NEW: Selective Authentication not enabled (PingCastle P-TrustLogin)
      const noSelectiveAuth = trust.SelectiveAuthentication === false && trust.TrustType === 'Forest';
      // NEW: External trust (higher risk than forest trust)
      const isExternalTrust = trust.TrustType === 'External';

      return isBroken || hasIssues || noSIDFiltering || isOrphaned || oldPassword || noSelectiveAuth || isExternalTrust;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Trusts' category reduced from ${originalCount} to ${result.length} items (keeping only problematic trusts)`);
    }
  }

  // Smart Filtering for FSMO Roles (Focus on Issues)
  // Source: Microsoft FSMO Best Practices, PingCastle
  if (categoryName.toLowerCase() === 'fsmoroleshealth' && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(fsmo => {
      const hasIssues = fsmo.Issues && fsmo.Issues.length > 0;
      const isUnhealthy = fsmo.Health !== 'Healthy' && fsmo.Health !== undefined;
      // Single Point of Failure (Quest, Microsoft)
      const allOnSingleDC = fsmo.AllFSMOOnSingleDC === true;
      // PingCastle: PDC should sync with external NTP, not VM host
      const hasVMTimeSync = fsmo.PDCTimeSyncSource && (fsmo.PDCTimeSyncSource.includes('VM IC') || fsmo.PDCTimeSyncSource.includes('Hyper-V') || fsmo.PDCTimeSyncSource.includes('Local CMOS'));
      // Microsoft: RID Pool exhaustion is critical
      const ridPoolLow = fsmo.RIDPoolStatus?.PercentUsed > 80;
      // NEW: FSMO holder is not reachable
      const fsmoUnreachable = fsmo.Reachable === false;
      // NEW: Infrastructure Master on GC in multi-domain (Microsoft KB)
      const infraOnGC = fsmo.InfrastructureMasterOnGC === true && fsmo.IsMultiDomain === true;

      return hasIssues || isUnhealthy || allOnSingleDC || hasVMTimeSync || ridPoolLow || fsmoUnreachable || infraOnGC;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'FSMORolesHealth' category reduced from ${originalCount} to ${result.length} items`);
    }
  }

  // Smart Filtering for Sites (Focus on Topology Issues)
  // Source: PingCastle S-DC-SubnetMissing, Microsoft AD Sites
  if (categoryName.toLowerCase() === 'sites' && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(site => {
      // PingCastle S-DC-SubnetMissing
      const hasNoSubnets = !site.Subnets || site.Subnets.length === 0;
      // DCs should not remain in default site
      const isDefaultSite = site.Name === 'Default-First-Site-Name';
      // Site without DC is orphaned
      const hasNoDC = !site.DomainControllers || site.DomainControllers.length === 0;
      const hasIssues = site.Issues && site.Issues.length > 0;
      // NEW: Site link cost issues (very high cost = suboptimal routing)
      const hasHighCost = site.SiteLinkCost && site.SiteLinkCost > 500;
      // NEW: Manual bridgehead server (potential SPOF)
      const hasManualBridgehead = site.HasManualBridgehead === true;

      return hasNoSubnets || isDefaultSite || hasNoDC || hasIssues || hasHighCost || hasManualBridgehead;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Sites' category reduced from ${originalCount} to ${result.length} items (keeping only problematic sites)`);
    }
  }

  // NEW: Smart Filtering for Kerberos (Focus on Security Issues)
  // Source: MITRE ATT&CK, Microsoft Kerberos Security
  if (categoryName.toLowerCase() === 'kerberos' && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(item => {
      // MITRE: Weak encryption types enable credential theft
      const hasWeakEncryption = item.SupportedETypes?.includes('RC4') || item.SupportedETypes?.includes('DES');
      // CIS: Kerberos delegation issues
      const hasDelegationIssues = item.DelegationIssues && item.DelegationIssues.length > 0;
      // Microsoft: TGT lifetime too long
      const longTGTLifetime = item.MaxTicketAge && item.MaxTicketAge > 10;
      // NEW: Pre-authentication disabled (AS-REP roasting)
      const preAuthDisabled = item.PreAuthNotRequired === true;

      return hasWeakEncryption || hasDelegationIssues || longTGTLifetime || preAuthDisabled;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Kerberos' category reduced from ${originalCount} to ${result.length} items`);
    }
  }

  // NEW: Smart Filtering for Security category
  // Source: CIS Benchmark, Microsoft Security Baseline
  if (categoryName.toLowerCase() === 'security' && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(item => {
      // CIS: Password policy issues
      const weakPasswordPolicy = item.MinPasswordLength && item.MinPasswordLength < 14;
      const noPasswordExpiration = item.MaxPasswordAge === 0;
      // Microsoft: LDAP signing not enforced
      const noLDAPSigning = item.LDAPSigning === 'None' || item.LDAPSigning === false;
      // SMBv1 enabled (CVE-2017-0144 EternalBlue)
      const smbV1Enabled = item.SMBv1Enabled === true;
      // NTLM not restricted
      const ntlmNotRestricted = item.NTLMRestriction === 'None' || item.NTLMRestriction === false;
      // NEW: Audit policy not configured
      const noAuditPolicy = item.AuditPolicyConfigured === false;
      // NEW: LAPS not deployed
      const noLAPS = item.LAPSDeployed === false;
      // NEW: Credential Guard not enabled
      const noCredentialGuard = item.CredentialGuardEnabled === false;

      return weakPasswordPolicy || noPasswordExpiration || noLDAPSigning || smbV1Enabled || ntlmNotRestricted || noAuditPolicy || noLAPS || noCredentialGuard;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'Security' category reduced from ${originalCount} to ${result.length} items`);
    }
  }

  // NEW: Smart Filtering for OUs (Focus on Hygiene Issues)
  if (categoryName.toLowerCase() === 'ous' && result.length > 0) {
    const originalCount = result.length;
    result = result.filter(ou => {
      // Empty OUs (hygiene)
      const isEmpty = ou.ObjectCount === 0 || (ou.ChildCount === 0 && ou.ObjectCount === 0);
      // OU blocking inheritance (shadow IT)
      const blocksInheritance = ou.BlockInheritance === true;
      // OU with no GPO linked (potential orphaned OU)
      const noGPOLinked = !ou.LinkedGPOs || ou.LinkedGPOs.length === 0;
      // Deep nesting (>5 levels creates complexity)
      const deepNesting = ou.NestingLevel && ou.NestingLevel > 5;

      return isEmpty || blocksInheritance || deepNesting;
    });

    if (originalCount !== result.length) {
      console.log(`[SmartFilter] 'OUs' category reduced from ${originalCount} to ${result.length} items`);
    }
  }

  return result;
}

// ------------------------------------------------------------------
// AI ORCHESTRATOR & ANALYZER
// ------------------------------------------------------------------

async function analyzeCategory(assessmentId, category, data, options = {}) {
  try {
    // v1.9.5: Read API keys from database (system_config) with env fallback
    const provider = await getConfig('ai_provider') || process.env.AI_PROVIDER || 'anthropic';

    let apiKey = null;
    // v2.0.0: Copilot provider doesn't need an API key
    if (provider === 'copilot') {
      // Check if Copilot is authenticated
      const copilotStatus = await copilotClient.getAuthStatus();
      if (!copilotStatus.authenticated) {
        throw new Error('GitHub Copilot not authenticated. Please connect with GitHub first.');
      }
      apiKey = 'copilot'; // Placeholder - not actually used
    } else if (provider === 'anthropic') {
      apiKey = await getConfig('anthropic_api_key') || process.env.ANTHROPIC_API_KEY;
    } else if (provider === 'openai') {
      apiKey = await getConfig('openai_api_key') || process.env.OPENAI_API_KEY;
    } else if (provider === 'deepseek') {
      apiKey = await getConfig('deepseek_api_key') || process.env.DEEPSEEK_API_KEY;
    } else if (provider === 'google') {
      apiKey = await getConfig('google_api_key') || process.env.GOOGLE_API_KEY;
    } else {
      apiKey = process.env.ANTHROPIC_API_KEY || process.env.OPENAI_API_KEY;
    }

    // v2.0.0: Dynamic model selection
    let model;
    if (provider === 'copilot') {
      model = await getConfig('copilot_model') || 'gpt-4o';
      await addLog(assessmentId, 'info', `Usando GitHub Copilot con modelo: ${model}`, category);
    } else if (provider === 'anthropic') {
      const forceOpus = options.deepAnalysis || false;
      model = selectAnthropicModel(category, forceOpus);
      await addLog(assessmentId, 'info', `Modelo seleccionado: ${model.includes('opus') ? 'Opus 4.5' : 'Sonnet 4.5'}`, category);
    } else {
      model = process.env.AI_MODEL || 'gpt-4o';
    }

    if (!apiKey && provider !== 'copilot') {
      throw new Error('AI API Key not configured');
    }

    let allFindings = [];

    // -----------------------------------------------------------------
    // FASE 3 PILOT: Deterministic Analysis for 'Users'
    // -----------------------------------------------------------------
    if (category === 'Users') {
      console.log(`[${timestamp()}] [DETERMINISTIC] Running Phase 3 Engine for ${category}...`);
      await addLog(assessmentId, 'info', `Ejecutando an√°lisis determin√≠stico (Fase 3) para ${category}`, category);

      // Execute Deterministic Logic
      allFindings = analyzeUsersDeterministic(data);

      console.log(`[${timestamp()}] [DETERMINISTIC] Found ${allFindings.length} mathematically verified findings.`);
      await addLog(assessmentId, 'info', `An√°lisis determin√≠stico completado: ${allFindings.length} hallazgos encontrados`, category);

    } else {
      // -----------------------------------------------------------------
      // FASE 2: Regular AI Analysis + Post-Validation (Legacy for other categories)
      // -----------------------------------------------------------------
      await addLog(assessmentId, 'info', `Starting AI analysis for ${category}...`, category);

      // CRITICAL: Prevent hallucinations on empty datasets
      if (!data || data.length === 0) {
        console.log(`[${timestamp()}] [AI] ${category}: empty dataset (after filtering), skipping analysis to prevent hallucinations.`);
        await addLog(assessmentId, 'info', `Skipping ${category} (no risk objects found).`, category);
        return [];
      }

      const MAX_CHUNK_SIZE = 40; // Reduced to improve AI focus
      if (data.length > MAX_CHUNK_SIZE) {
        console.log(`[${timestamp()}] [AI] ${category}: Large dataset (${data.length} items), chunking...`);
        const chunks = chunkArray(data, MAX_CHUNK_SIZE);
        const mergedFindingsMap = new Map();

        // v1.7.0: Process chunks with per-chunk validation
        const processChunk = async (chunk, index) => {
          await addLog(assessmentId, 'info', `Analizando bloque ${index + 1}/${chunks.length} (${chunk.length.toLocaleString()} items)`, category);
          const prompt = buildPrompt(category, chunk);
          console.log(`[${timestamp()}] [AI] Chunk ${index + 1} prompt: ${prompt.length} chars`);
          try {
            // Rate limit protection
            await new Promise(r => setTimeout(r, 1000 * Math.random()));
            const findings = await callAI(prompt, provider, model, apiKey);
            console.log(`[${timestamp()}] [AI] Chunk ${index + 1} returned ${findings.length} raw findings`);

            // v1.7.0: VALIDATE PER CHUNK before merging
            // This catches hallucinations early and prevents contaminating the merge
            const validatedFindings = validateFindingsPerChunk(findings, chunk, category);
            console.log(`[${timestamp()}] [AI] Chunk ${index + 1}: ${validatedFindings.length}/${findings.length} findings passed validation`);

            if (validatedFindings.length > 0) {
              await addLog(assessmentId, 'info', `Bloque ${index + 1}: ${validatedFindings.length} hallazgos verificados`, category);
            }
            return validatedFindings;
          } catch (e) {
            console.error(`Error processing chunk ${index}:`, e);
            await addLog(assessmentId, 'error', `Error en bloque ${index + 1}: ${e.message}`, category);
            return [];
          }
        };

        // Sequential Chunk Processing to be safe with limits
        for (let i = 0; i < chunks.length; i++) {
          const chunkFindings = await processChunk(chunks[i], i);
          chunkFindings.forEach(f => {
            // Merge Logic - only validated findings reach here
            let key = f.type_id;
            if (!key && f.cis_control) key = f.cis_control.split(' ')[0];
            if (!key) key = (f.title || '').replace(/^\d+\s+/, '');

            if (!mergedFindingsMap.has(key)) {
              mergedFindingsMap.set(key, { ...f });
            } else {
              const existing = mergedFindingsMap.get(key);
              const existingCount = existing.affected_count || existing.evidence?.count || 0;
              const newCount = f.affected_count || f.evidence?.count || 0;
              const totalCount = existingCount + newCount;

              existing.affected_count = totalCount;
              if (existing.evidence) existing.evidence.count = totalCount;

              const existingObjects = existing.evidence?.affected_objects || [];
              const newObjects = f.evidence?.affected_objects || [];
              // Use Set to deduplicate and preserve order
              existing.evidence.affected_objects = [...new Set([...existingObjects, ...newObjects])];

              // Update title with new count
              if (/^\d+/.test(existing.title)) {
                existing.title = existing.title.replace(/^\d+/, totalCount.toString());
              }
            }
          });

          // Progress log
          if (i % 2 === 0) {
            await addLog(assessmentId, 'info', `Progreso: ${i + 1}/${chunks.length} bloques procesados`, category);
          }
        }

        allFindings = Array.from(mergedFindingsMap.values());
        console.log(`[${timestamp()}] [AI] ${category}: Merged into ${allFindings.length} unique findings`);

      } else {
        // Small dataset
        console.log(`[${timestamp()}] [AI] ${category}: Small dataset (${data.length} items), processing in single chunk`);
        const prompt = buildPrompt(category, data);
        allFindings = await callAI(prompt, provider, model, apiKey);
      }

      // POST-PROCESSING: Strict Grounding Check
      // Only needed for AI generated findings
      allFindings = validateFindings(allFindings, data, category);
      console.log(`[${timestamp()}] [AI] ${category} analysis complete (validated): ${allFindings.length} findings`);
      await addLog(assessmentId, 'info', `AI analysis complete: ${allFindings.length} verified findings`, category);
    }

    // Save findings to database (Common path for both engines)
    console.log(`[${timestamp()}] [DB] Saving ${allFindings.length} findings for ${category}`);
    if (allFindings.length > 0) {
      for (const f of allFindings) {
        await pool.query(
          `INSERT INTO findings (
            assessment_id, title, severity, description, recommendation, evidence,
            mitre_attack, cis_control, impact_business, remediation_commands,
            prerequisites, operational_impact, microsoft_docs, current_vs_recommended,
            timeline, affected_count
          )
           VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16)`,
          [
            assessmentId,
            sanitizeText(f.title || 'Security Issue'),
            f.severity || 'medium',
            sanitizeText(f.description || 'No description'),
            sanitizeText(f.recommendation || 'Review finding'),
            JSON.stringify(f.evidence || {}),
            sanitizeText(f.mitre_attack || ''),
            sanitizeText(f.cis_control || ''),
            sanitizeText(f.impact_business || ''),
            sanitizeText(f.remediation_commands || ''),
            sanitizeText(f.prerequisites || ''),
            sanitizeText(f.operational_impact || ''),
            sanitizeText(f.microsoft_docs || ''),
            sanitizeText(f.current_vs_recommended || ''),
            sanitizeText(f.timeline || ''),
            f.affected_count || 0
          ]
        );
      }
      await addLog(assessmentId, 'info', 'Findings saved successfully', category);
    }

    return allFindings;

  } catch (error) {
    console.error(`Error analyzing ${category}:`, error);
    await addLog(assessmentId, 'error', `Analysis error: ${error.message}`, category);
    return [];
  }
}

// =============================================================================
// üõ°Ô∏è SECURITY v1.7.0: ATTRIBUTE VALIDATION SYSTEM
// Ensures AI cannot invent attributes for real objects
// =============================================================================

/**
 * Attribute validation rules per finding type
 * Maps type_id/title patterns to validation functions
 */
const ATTRIBUTE_VALIDATION_RULES = {
  // User-related findings
  'PASSWORD_NEVER_EXPIRES': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => obj.Enabled === true && obj.PasswordNeverExpires === true
  },
  'INACTIVE_ACCOUNTS': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => {
      if (!obj.Enabled || !obj.LastLogonDate) return false;
      const lastLogon = parseFlexibleDate(obj.LastLogonDate);
      if (!lastLogon) return false;
      const ninetyDaysAgo = new Date();
      ninetyDaysAgo.setDate(ninetyDaysAgo.getDate() - 90);
      return lastLogon < ninetyDaysAgo;
    }
  },
  'ADMIN_COUNT_EXPOSURE': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => obj.Enabled === true && obj.AdminCount === 1
  },
  'KERBEROASTING': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => obj.Enabled === true &&
      obj.ServicePrincipalNames &&
      (Array.isArray(obj.ServicePrincipalNames) ? obj.ServicePrincipalNames.length > 0 : true) &&
      obj.SamAccountName?.toLowerCase() !== 'krbtgt'
  },
  'ASREP_ROASTING': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => obj.Enabled === true && (obj.DoNotRequirePreAuth === true || obj.IsASREPRoastable === true)
  },
  'UNCONSTRAINED_DELEGATION': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => obj.Enabled === true && obj.TrustedForDelegation === true
  },
  'PASSWORD_NOT_REQUIRED': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => obj.Enabled === true && obj.PasswordNotRequired === true
  },
  'PRIVILEGED_NO_PROTECTION': {
    category: 'Users',
    identifierField: 'SamAccountName',
    validate: (obj) => obj.Enabled === true && obj.IsPrivileged === true
  },

  // Computer-related findings
  'LEGACY_OS': {
    category: 'Computers',
    identifierField: 'Name',
    validate: (obj) => {
      const os = (obj.OperatingSystem || '').toLowerCase();
      return os.includes('2012') || os.includes('2008') || os.includes('2003') ||
             os.includes('2000') || os.includes('xp') || os.includes('vista') ||
             os.includes('windows 7') || os.includes('windows 8');
    }
  },
  'STALE_COMPUTER': {
    category: 'Computers',
    identifierField: 'Name',
    validate: (obj) => obj.IsStale === true || obj.Enabled === false
  },
  'COMPUTER_UNCONSTRAINED_DELEGATION': {
    category: 'Computers',
    identifierField: 'Name',
    validate: (obj) => obj.TrustedForDelegation === true
  },

  // Group-related findings
  'EMPTY_GROUP': {
    category: 'Groups',
    identifierField: 'Name',
    validate: (obj) => obj.MemberCount === 0 || (obj.Members && obj.Members.length === 0)
  },
  'PRIVILEGED_GROUP': {
    category: 'Groups',
    identifierField: 'Name',
    validate: (obj) => obj.IsPrivileged === true
  },

  // GPO-related findings
  'UNLINKED_GPO': {
    category: 'GPOs',
    identifierField: 'DisplayName',
    validate: (obj) => !obj.Links || obj.Links.length === 0 || obj.LinksTo?.length === 0
  },
  'DISABLED_GPO': {
    category: 'GPOs',
    identifierField: 'DisplayName',
    validate: (obj) => obj.GpoStatus === 'AllSettingsDisabled' ||
                       obj.GpoStatus === 'UserSettingsDisabled' ||
                       obj.GpoStatus === 'ComputerSettingsDisabled'
  },

  // DCHealth / HygieneAnalysis findings (v3.6.13)
  // These validate against HygieneAnalysis data extracted from NETLOGON/NTDS events
  'GHOST_COMPUTER_ACCOUNTS': {
    category: 'DCHealth',
    identifierField: 'Name',
    // Validates that reported ghost computers exist in HygieneAnalysis.GhostComputers
    validate: (obj, finding) => {
      // For DCHealth, the object is the DC itself
      // The affected_objects should match items in HygieneAnalysis.GhostComputers
      if (!obj.HygieneAnalysis?.GhostComputers) return false;
      return obj.HygieneAnalysis.GhostComputers.length > 0;
    },
    // Custom validation for affected objects
    validateAffectedObject: (objName, dcData) => {
      if (!dcData.HygieneAnalysis?.GhostComputers) return false;
      return dcData.HygieneAnalysis.GhostComputers.some(ghost =>
        ghost.toLowerCase().includes(objName.toLowerCase()) ||
        objName.toLowerCase().includes(ghost.toLowerCase())
      );
    }
  },
  'TRUST_RELATIONSHIP_FAILURE': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => {
      if (!obj.HygieneAnalysis?.TrustFailures) return false;
      return obj.HygieneAnalysis.TrustFailures.length > 0;
    },
    validateAffectedObject: (objName, dcData) => {
      if (!dcData.HygieneAnalysis?.TrustFailures) return false;
      return dcData.HygieneAnalysis.TrustFailures.some(trust =>
        trust.toLowerCase().includes(objName.toLowerCase()) ||
        objName.toLowerCase().includes(trust.toLowerCase())
      );
    }
  },
  'CREDENTIAL_DESYNC': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => {
      if (!obj.HygieneAnalysis?.CredentialDesync) return false;
      return obj.HygieneAnalysis.CredentialDesync.length > 0;
    },
    validateAffectedObject: (objName, dcData) => {
      if (!dcData.HygieneAnalysis?.CredentialDesync) return false;
      return dcData.HygieneAnalysis.CredentialDesync.some(cred =>
        cred.toLowerCase().includes(objName.toLowerCase()) ||
        objName.toLowerCase().includes(cred.toLowerCase())
      );
    }
  },
  'SECURE_CHANNEL_FAILURE': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => {
      if (!obj.HygieneAnalysis?.SecureChannelFailures) return false;
      return obj.HygieneAnalysis.SecureChannelFailures.length > 0;
    },
    validateAffectedObject: (objName, dcData) => {
      if (!dcData.HygieneAnalysis?.SecureChannelFailures) return false;
      return dcData.HygieneAnalysis.SecureChannelFailures.some(sc =>
        sc.toLowerCase().includes(objName.toLowerCase()) ||
        objName.toLowerCase().includes(sc.toLowerCase())
      );
    }
  },
  'REPLICATION_PARTNER_ISSUE': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => {
      if (!obj.HygieneAnalysis?.ReplicationPartnerIssues) return false;
      return obj.HygieneAnalysis.ReplicationPartnerIssues.length > 0;
    },
    validateAffectedObject: (objName, dcData) => {
      if (!dcData.HygieneAnalysis?.ReplicationPartnerIssues) return false;
      return dcData.HygieneAnalysis.ReplicationPartnerIssues.some(rp =>
        rp.toLowerCase().includes(objName.toLowerCase()) ||
        objName.toLowerCase().includes(rp.toLowerCase())
      );
    }
  },
  // Traditional DCHealth findings
  'REPLICATION_FAILURE': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => obj.ConsecutiveReplicationFailures > 0 || obj.ReplicationStatus === 'Error'
  },
  'OS_OBSOLETE_DC': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => {
      const os = (obj.OperatingSystem || '').toLowerCase();
      return os.includes('2012') || os.includes('2008') || os.includes('2003');
    }
  },
  'FSMO_PLACEMENT_ISSUE': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => obj.FSMORoles && obj.FSMORoles.length > 3 // More than 3 roles = SPOF risk
  },
  'NTP_MISCONFIGURED': {
    category: 'DCHealth',
    identifierField: 'Name',
    validate: (obj) => {
      const source = (obj.TimeSyncConfig?.Source || '').toLowerCase();
      return source.includes('local cmos') || source.includes('free-running') ||
             source.includes('vm ic time');
    }
  },

  // DNS-related findings
  'DNS_FORWARDERS_PUBLIC': {
    category: 'DNS',
    identifierField: 'DCName',
    validate: (obj) => {
      // obj is from DNSConfiguration.Forwarders array
      if (obj._isForwarderConfig) return true; // Injected by extractCategoryData
      return obj.Forwarders && obj.Forwarders.length > 0;
    }
  },
  'DNS_FORWARDERS_INSECURE': {
    category: 'DNS',
    identifierField: 'DCName',
    validate: (obj) => {
      if (obj._isForwarderConfig) return true;
      return obj.SecurityWarning && obj.SecurityWarning.length > 0;
    }
  },
  'DNS_ZONE_TRANSFER': {
    category: 'DNS',
    identifierField: 'ZoneName',
    validate: (obj) => obj.SecureSecondaries === false || obj.SecureSecondaries === 'NoSecurity'
  },
  'DNS_DYNAMIC_UPDATE': {
    category: 'DNS',
    identifierField: 'ZoneName',
    validate: (obj) => obj.DynamicUpdate === 'NonsecureAndSecure' || obj.DynamicUpdate === 'Insecure'
  },

  // PasswordPolicies-related findings
  'PASSWORD_POLICY_WEAK_LENGTH': {
    category: 'PasswordPolicies',
    identifierField: 'Name',
    validate: (obj) => {
      // obj can be DefaultDomainPolicy or a FineGrainedPolicy
      return obj.MinPasswordLength !== undefined && obj.MinPasswordLength < 12;
    }
  },
  'PASSWORD_POLICY_NO_COMPLEXITY': {
    category: 'PasswordPolicies',
    identifierField: 'Name',
    validate: (obj) => obj.ComplexityEnabled === false
  },
  'PASSWORD_POLICY_REVERSIBLE_ENCRYPTION': {
    category: 'PasswordPolicies',
    identifierField: 'Name',
    validate: (obj) => obj.ReversibleEncryptionEnabled === true
  },
  'PASSWORD_POLICY_NO_LOCKOUT': {
    category: 'PasswordPolicies',
    identifierField: 'Name',
    validate: (obj) => obj.LockoutThreshold === 0 || obj.LockoutThreshold === undefined
  },
  'PASSWORD_POLICY_LONG_MAX_AGE': {
    category: 'PasswordPolicies',
    identifierField: 'Name',
    validate: (obj) => {
      // MaxPasswordAge typically in days or TimeSpan format
      if (obj.MaxPasswordAge === 0) return true; // Never expires
      if (typeof obj.MaxPasswordAge === 'number') return obj.MaxPasswordAge > 90;
      return false;
    }
  },
  'PASSWORD_POLICY_WEAK_HISTORY': {
    category: 'PasswordPolicies',
    identifierField: 'Name',
    validate: (obj) => {
      return obj.PasswordHistoryCount !== undefined && obj.PasswordHistoryCount < 12;
    }
  }
};

/**
 * Flexible date parser for multiple formats
 * Supports: /Date(\d+)/, ISO 8601, Unix timestamp
 */
function parseFlexibleDate(dateValue) {
  if (!dateValue) return null;

  try {
    // Format 1: /Date(1234567890000)/
    if (typeof dateValue === 'string' && dateValue.includes('/Date(')) {
      const match = dateValue.match(/\/Date\((-?\d+)\)\//);
      if (match) return new Date(parseInt(match[1]));
    }

    // Format 2: ISO 8601 string
    if (typeof dateValue === 'string' && dateValue.includes('-')) {
      const parsed = new Date(dateValue);
      if (!isNaN(parsed.getTime())) return parsed;
    }

    // Format 3: Unix timestamp (number or string)
    const timestamp = typeof dateValue === 'number' ? dateValue : parseInt(dateValue);
    if (!isNaN(timestamp)) {
      // Handle both seconds and milliseconds
      const date = new Date(timestamp > 1e12 ? timestamp : timestamp * 1000);
      if (!isNaN(date.getTime())) return date;
    }

    return null;
  } catch (e) {
    console.warn(`[parseFlexibleDate] Failed to parse: ${dateValue}`);
    return null;
  }
}

/**
 * Validates that affected objects actually have the claimed attributes
 * @param {Object} finding - The finding to validate
 * @param {Array} data - Raw data for the category
 * @param {string} category - Category name
 * @returns {Object} - { isValid: boolean, validObjects: string[], invalidObjects: string[] }
 */
function validateAttributes(finding, data, category) {
  const result = { isValid: true, validObjects: [], invalidObjects: [], rule: null };

  if (!finding || !data || !Array.isArray(data)) return result;

  const affectedObjects = finding.evidence?.affected_objects || [];
  if (affectedObjects.length === 0) return result;

  // Find matching rule by type_id or title pattern
  let rule = null;
  const typeId = finding.type_id || '';
  const title = (finding.title || '').toLowerCase();

  // Try exact match first
  if (typeId && ATTRIBUTE_VALIDATION_RULES[typeId]) {
    rule = ATTRIBUTE_VALIDATION_RULES[typeId];
  } else {
    // Try pattern matching on title
    for (const [ruleId, ruleConfig] of Object.entries(ATTRIBUTE_VALIDATION_RULES)) {
      const pattern = ruleId.toLowerCase().replace(/_/g, ' ');
      if (title.includes(pattern) || title.includes(ruleId.toLowerCase())) {
        rule = ruleConfig;
        result.rule = ruleId;
        break;
      }
    }
  }

  // If no matching rule, skip attribute validation (allow the finding)
  if (!rule) {
    result.validObjects = affectedObjects;
    return result;
  }

  // Check if rule applies to this category
  if (rule.category && rule.category.toLowerCase() !== category.toLowerCase()) {
    result.validObjects = affectedObjects;
    return result;
  }

  // Build lookup map for data objects
  const identifierField = rule.identifierField || 'Name';
  const dataMap = new Map();
  data.forEach(obj => {
    if (obj && obj[identifierField]) {
      dataMap.set(obj[identifierField].toLowerCase(), obj);
    }
    // Also try SamAccountName as fallback
    if (obj && obj.SamAccountName) {
      dataMap.set(obj.SamAccountName.toLowerCase(), obj);
    }
    // And Name
    if (obj && obj.Name) {
      dataMap.set(obj.Name.toLowerCase(), obj);
    }
  });

  // Validate each affected object
  for (const objName of affectedObjects) {
    if (!objName) continue;

    const lowerName = objName.toString().toLowerCase();
    const cleanName = lowerName.replace(/^(cn=|name=|user=|computer=)/, '').split(',')[0].trim();

    const realObj = dataMap.get(cleanName) || dataMap.get(lowerName);

    // v3.6.13: Special handling for DCHealth with validateAffectedObject
    // For DCHealth/HygieneAnalysis, affected_objects are computers from logs,
    // not the DC itself, so we need to validate against HygieneAnalysis arrays
    if (rule.validateAffectedObject && category.toLowerCase() === 'dchealth') {
      // Check if any DC in the data has this object in its HygieneAnalysis
      let foundInAnyDC = false;
      for (const dc of data) {
        if (rule.validateAffectedObject(objName, dc)) {
          foundInAnyDC = true;
          break;
        }
      }
      if (foundInAnyDC) {
        result.validObjects.push(objName);
      } else {
        result.invalidObjects.push(objName);
        console.log(`[validateAttributes] ‚ùå DCHealth object "${objName}" not found in any DC's HygieneAnalysis`);
      }
    } else if (realObj && rule.validate(realObj)) {
      result.validObjects.push(objName);
    } else {
      result.invalidObjects.push(objName);
      console.log(`[validateAttributes] ‚ùå Object "${objName}" failed attribute check for rule (exists: ${!!realObj}, validate: ${realObj ? rule.validate(realObj) : 'N/A'})`);
    }
  }

  result.isValid = result.validObjects.length > 0;
  return result;
}

// =============================================================================
// v1.7.0: PER-CHUNK VALIDATION
// Lightweight validation for chunk processing - validates against chunk data only
// =============================================================================

/**
 * Validate findings against chunk data before merging
 * This is a lighter version of validateFindings optimized for chunk processing
 * @param {Array} findings - Findings from AI for this chunk
 * @param {Array} chunkData - The chunk data that was sent to AI
 * @param {string} category - Category name
 * @returns {Array} - Validated findings
 */
function validateFindingsPerChunk(findings, chunkData, category) {
  if (!findings || findings.length === 0) return [];
  if (!chunkData || chunkData.length === 0) return [];

  // Build index of valid identifiers from chunk data
  const validIdentifiers = new Set();

  chunkData.forEach(obj => {
    if (!obj) return;
    // Add common identifier fields
    ['SamAccountName', 'Name', 'DisplayName', 'DistinguishedName', 'DNSHostName'].forEach(field => {
      if (obj[field] && typeof obj[field] === 'string') {
        validIdentifiers.add(obj[field].toLowerCase());
      }
    });
  });

  const validatedFindings = [];

  for (const finding of findings) {
    if (!finding) continue;

    const evidence = finding.evidence || {};
    const affectedObjects = evidence.affected_objects || [];

    // Global findings (no specific objects) - allow for non-object categories
    if (affectedObjects.length === 0) {
      if (['Users', 'Computers', 'Groups'].includes(category)) {
        // These require specific objects
        if ((evidence.count || 0) > 0 || (finding.affected_count || 0) > 0) {
          console.log(`[ChunkValidation] üõë Rejected: "${finding.title}" claims count but no objects`);
          continue;
        }
      }
      validatedFindings.push(finding);
      continue;
    }

    // Validate each affected object exists in chunk
    const validObjects = affectedObjects.filter(objName => {
      if (!objName) return false;
      const lowerName = objName.toString().toLowerCase();
      const cleanName = lowerName.replace(/^(cn=|name=|user=|computer=)/, '').split(',')[0].trim();

      return validIdentifiers.has(cleanName) || validIdentifiers.has(lowerName) ||
        // Partial match for domain-prefixed names (DOMAIN\user)
        Array.from(validIdentifiers).some(id => id.includes(cleanName) || cleanName.includes(id));
    });

    if (validObjects.length === 0) {
      console.log(`[ChunkValidation] üõë Rejected: "${finding.title}" - no valid objects in chunk`);
      continue;
    }

    // Update finding with validated objects
    finding.evidence.affected_objects = validObjects;
    finding.evidence.count = validObjects.length;
    finding.affected_count = validObjects.length;

    // Update title count if present
    if (/^\d+/.test(finding.title)) {
      finding.title = finding.title.replace(/^\d+/, validObjects.length.toString());
    }

    validatedFindings.push(finding);
  }

  return validatedFindings;
}

// üõ°Ô∏è SECURITY: Grounding Verification Function
// Ensures AI cannot invent objects that don't exist in the input data.
// v1.7.0: Optimized with n-gram index for O(1) fuzzy matching
function validateFindings(findings, data, category) {
  if (!findings || findings.length === 0) return [];

  // Create a Set of all valid object identifiers for O(1) lookup
  const validNames = new Set();
  // v1.7.0: Create n-gram index for faster fuzzy matching
  const ngramIndex = new Map(); // Maps 3-char substrings to full names

  // Helper to extract n-grams from a string
  const extractNgrams = (str, n = 3) => {
    const ngrams = [];
    const lower = str.toLowerCase();
    for (let i = 0; i <= lower.length - n; i++) {
      ngrams.push(lower.substring(i, i + n));
    }
    return ngrams;
  };

  // Recursive function to extract all strings from an object
  const extractStrings = (obj) => {
    if (!obj) return;

    if (typeof obj === 'string') {
      if (obj.length > 2 && obj.length < 100) {
        const lower = obj.toLowerCase();
        validNames.add(lower);
        // Index n-grams for this string
        extractNgrams(lower).forEach(ngram => {
          if (!ngramIndex.has(ngram)) {
            ngramIndex.set(ngram, new Set());
          }
          ngramIndex.get(ngram).add(lower);
        });
      }
      return;
    }

    if (Array.isArray(obj)) {
      obj.forEach(item => extractStrings(item));
      return;
    }

    if (typeof obj === 'object') {
      Object.keys(obj).forEach(key => {
        // Add keys as well, as they often contain DC names or hostnames
        if (key.length > 2 && key.length < 100) {
          const lowerKey = key.toLowerCase();
          validNames.add(lowerKey);
          extractNgrams(lowerKey).forEach(ngram => {
            if (!ngramIndex.has(ngram)) {
              ngramIndex.set(ngram, new Set());
            }
            ngramIndex.get(ngram).add(lowerKey);
          });
        }
        extractStrings(obj[key]);
      });
    }
  };

  data.forEach(item => extractStrings(item));
  console.log(`[Validation] Built index with ${validNames.size} valid names, ${ngramIndex.size} n-gram entries`);

  const validatedFindings = [];

  for (const finding of findings) {
    const evidence = finding.evidence || {};
    let affectedObjects = evidence.affected_objects || [];

    // 1. GLOBAL/GENERIC CHECKS (Type II Findings)
    if (affectedObjects.length === 0) {
      if (['Users', 'Computers', 'Groups'].includes(category)) {
        if (evidence.count > 0 || finding.affected_count > 0) {
          console.log(`[Validation] üõë PURGING HALLUCINATION: "${finding.title}" (Category: ${category}) claims issues but lists NO objects.`);
          continue;
        }
      }
      validatedFindings.push(finding);
      continue;
    }

    // 2. SPECIFIC OBJECT CHECKS (Type I Findings)
    // v1.7.0: Optimized validation using n-gram index
    const validObjects = affectedObjects.filter(objName => {
      if (!objName) return false;
      const lowerObj = objName.toString().toLowerCase();
      // Clean up common prefixes
      const cleanName = lowerObj.replace(/^(cn=|name=|user=|computer=)/, '').split(',')[0].trim();

      // Fast path: exact match O(1)
      if (validNames.has(cleanName) || validNames.has(lowerObj)) {
        return true;
      }

      // v1.7.0: Optimized fuzzy matching using n-gram index
      // Instead of O(n) iteration, use n-grams to find candidates
      if (cleanName.length >= 3) {
        const searchNgrams = extractNgrams(cleanName);
        const candidates = new Set();

        // Find all names that share at least one n-gram with the search term
        searchNgrams.forEach(ngram => {
          const matches = ngramIndex.get(ngram);
          if (matches) {
            matches.forEach(m => candidates.add(m));
          }
        });

        // Check candidates for actual match (now O(candidates) not O(validNames))
        for (const candidate of candidates) {
          if (candidate.includes(cleanName) || cleanName.includes(candidate)) {
            return true;
          }
        }
      }

      return false;
    });

    // 3. DECISION GATES - EXISTENCE CHECK
    if (validObjects.length === 0) {
      console.log(`[Validation] üõë BLOCKING TOTAL HALLUCINATION: Finding "${finding.title}" listed ${affectedObjects.length} objects but NONE exist in real data.`);
      continue; // DELETE FINDING
    }

    if (validObjects.length !== affectedObjects.length) {
      console.log(`[Validation] ‚ö†Ô∏è PARTIAL HALLUCINATION FIX (existence): Finding "${finding.title}" reduced from ${affectedObjects.length} to ${validObjects.length} real objects.`);
    }

    // 4. NEW v1.7.0: ATTRIBUTE VALIDATION
    // Verify that objects actually have the claimed vulnerability attributes
    finding.evidence.affected_objects = validObjects; // Update before attribute check
    const attrValidation = validateAttributes(finding, data, category);

    if (!attrValidation.isValid) {
      console.log(`[Validation] üõë BLOCKING ATTRIBUTE HALLUCINATION: Finding "${finding.title}" - objects exist but NONE have the claimed attributes.`);
      continue; // DELETE FINDING
    }

    if (attrValidation.invalidObjects.length > 0) {
      console.log(`[Validation] ‚ö†Ô∏è PARTIAL ATTRIBUTE FIX: Finding "${finding.title}" reduced from ${validObjects.length} to ${attrValidation.validObjects.length} (attribute-verified).`);
    }

    // Use attribute-validated objects (more strict than existence-only)
    const finalValidObjects = attrValidation.validObjects;

    // 5. REWRITE REALITY
    // Force the finding to match the verified reality
    finding.evidence.affected_objects = finalValidObjects;
    finding.evidence.count = finalValidObjects.length;
    finding.affected_count = finalValidObjects.length;

    // Update title to be mathematically correct
    if (/^\d+/.test(finding.title)) {
      finding.title = finding.title.replace(/^\d+/, finalValidObjects.length.toString());
    } else {
      // If title doesn't start with number but finding implies count, prepend it
      if (!finding.title.includes(finalValidObjects.length.toString())) {
        finding.title = `(${finalValidObjects.length}) ${finding.title}`;
      }
    }

    validatedFindings.push(finding);
  }

  console.log(`[Validation] ‚úÖ Final result: ${validatedFindings.length}/${findings.length} findings passed all validations`);
  return validatedFindings;
}

function buildPrompt(cat, d) {
  const str = (v, max) => JSON.stringify(v || [], null, 2).substring(0, max);

  const categoryInstructions = {
    Users: `Analiza estos usuarios de Active Directory para identificar vulnerabilidades de seguridad.

**‚ö†Ô∏è INSTRUCCIONES DE AN√ÅLISIS DE DATOS (JSON):**
1. Recibir√°s una lista de objetos JSON. CADA objeto es un usuario.
2. Debes ITERAR mentalmente sobre CADA usuario de la lista.
3. Verifica las condiciones de seguridad para CADA uno.
4. CUENTA cu√°ntos usuarios cumplen cada condici√≥n de vulnerabilidad.
5. Si encuentras al menos 1 usuario vulnerable, GENERA EL HALLAZGO.

**‚ö†Ô∏è VALIDACI√ìN CR√çTICA:**
- Los nombres de usuarios en affected_objects deben ser REALES de los datos analizados (propiedad 'SamAccountName').
- Si los datos muestran 0 usuarios con un problema, NO generes finding para eso.

**BUSCA ESPEC√çFICAMENTE (SOLO SI HAY EVIDENCIA):**

1. **Contrase√±as que nunca expiran** (PasswordNeverExpires=true AND Enabled=true)
   - Riesgo: Contrase√±as comprometidas permanecen v√°lidas indefinidamente
   - CIS Control: 5.2.1 - Ensure password expiration is enabled for all accounts
   - Impacto: Permite persistencia de atacantes, vulnera compliance (NIST 800-53)
   - Comando b√∫squeda: Get-ADUser -Filter {PasswordNeverExpires -eq $true -and Enabled -eq $true} -Properties PasswordNeverExpires, LastLogonDate
   - Comando fix: Set-ADUser -Identity "SamAccountName" -PasswordNeverExpires $false
   - Verificaci√≥n: Get-ADUser -Identity "SamAccountName" -Properties PasswordNeverExpires | Select Name, PasswordNeverExpires
   - Timeline: Remediar en 7 d√≠as

2. **Usuarios privilegiados excesivos** (miembros de Domain Admins > 5, Enterprise Admins > 3)
   - Riesgo: Exceso de cuentas con privilegios elevados aumenta superficie de ataque exponencialmente
   - CIS Control: 5.1.1 - Minimize administrative accounts to essential personnel only
   - Impacto: Mayor probabilidad de compromiso, dificulta auditor√≠a forense
   - Comando b√∫squeda: Get-ADGroupMember -Identity "Domain Admins" -Recursive | Select Name, SamAccountName
   - Comando auditor√≠a: Get-ADUser -Filter {AdminCount -eq 1} -Properties AdminCount, LastLogonDate | Select Name, LastLogonDate
   - Recomendaci√≥n: Implementar JIT (Just-In-Time) Admin Access con Azure AD PIM o PAM
   - Timeline: Revisar en 14 d√≠as, justificar cada cuenta

3. **Cuentas inactivas habilitadas** (LastLogonDate > 90 d√≠as AND Enabled=true)
   - Riesgo: Cuentas olvidadas son vectores de ataque, dif√≠ciles de monitorear
   - CIS Control: 5.3.1 - Disable or remove inactive accounts within 90 days
   - Impacto: Backdoors potenciales, vulnera principio de least privilege
   - Comando b√∫squeda: $InactiveDate = (Get-Date).AddDays(-90); Get-ADUser -Filter {LastLogonDate -lt $InactiveDate -and Enabled -eq $true} -Properties LastLogonDate
   - Comando fix: Disable-ADAccount -Identity "SamAccountName"
   - Verificaci√≥n: Get-ADUser -Identity "SamAccountName" -Properties Enabled | Select Name, Enabled
   - Timeline: Deshabilitar en 30 d√≠as tras notificar manager

4. **Kerberoasting vulnerable** (ServicePrincipalNames presentes en cuentas de usuario)
   - Riesgo: Atacantes pueden solicitar TGS y crackear passwords offline sin detectar
   - MITRE ATT&CK: T1558.003 (Kerberoasting)
   - Impacto: Compromiso de cuentas de servicio suele llevar a movimiento lateral
   - Comando b√∫squeda: Get-ADUser -Filter {ServicePrincipalName -like "*"} -Properties ServicePrincipalName, PasswordLastSet
   - Comando auditor√≠a: Get-ADUser -Filter {ServicePrincipalName -like "*"} -Properties PasswordLastSet | Where {$_.PasswordLastSet -lt (Get-Date).AddDays(-365)}
   - Recomendaci√≥n: Usar gMSA (Group Managed Service Accounts) o passwords > 25 caracteres
   - Timeline: Migrar a gMSA en 60 d√≠as

5. **ASREPRoasting vulnerable** (DoNotRequirePreAuth=true)
   - Riesgo: Permite obtener TGT sin autenticaci√≥n previa, crackearlo offline
   - MITRE ATT&CK: T1558.004 (AS-REP Roasting)
   - Impacto: Bypass de autenticaci√≥n, extracci√≥n de hashes sin credenciales
   - Comando b√∫squeda: Get-ADUser -Filter {DoNotRequirePreAuth -eq $true} -Properties DoNotRequirePreAuth
   - Comando fix: Set-ADUser -Identity "SamAccountName" -DoNotRequirePreAuth $false
   - Verificaci√≥n: Get-ADUser -Identity "SamAccountName" -Properties DoNotRequirePreAuth
   - Timeline: Remediar INMEDIATAMENTE (24 horas)

6. **Delegaci√≥n sin restricciones en usuarios** (TrustedForDelegation=true, no service accounts)
   - Riesgo: Permite ataques de pass-the-ticket, suplantaci√≥n de cualquier usuario incluyendo DAs
   - MITRE ATT&CK: T1134.005 (SID-History Injection), T1550.003 (Pass the Ticket)
   - Impacto: Escalaci√≥n de privilegios total, compromiso de dominio
   - Comando b√∫squeda: Get-ADUser -Filter {TrustedForDelegation -eq $true} -Properties TrustedForDelegation
   - Comando fix: Set-ADUser -Identity "SamAccountName" -TrustedForDelegation $false
   - Alternativa segura: Usar constrained delegation: Set-ADUser -Identity "SamAccountName" -Add @{'msDS-AllowedToDelegateTo'='HTTP/server.domain.com'}
   - Timeline: Remediar INMEDIATAMENTE (24 horas)

7. **Protected Users Group** (cuentas admin NO est√°n en el grupo)
   - Riesgo: Cuentas privilegiadas vulnerables a credential theft, pass-the-hash
   - CIS Control: 5.8.1 - Add privileged accounts to Protected Users security group
   - Comando b√∫squeda: Get-ADGroupMember "Domain Admins" | Where {(Get-ADUser $_.SamAccountName -Properties MemberOf).MemberOf -notcontains (Get-ADGroup "Protected Users").DistinguishedName}
   - Comando fix: Add-ADGroupMember -Identity "Protected Users" -Members "SamAccountName"
   - Nota: Validar compatibilidad de aplicaciones antes de mover cuentas
   - Timeline: Implementar en 30 d√≠as tras testing
    
8. **Riesgo de Kerberos Token Bloat** (EstimatedTokenSize > 12000 bytes)
   - Riesgo: Fallos de logon intermitentes, errores HTTP 400 en aplicaciones web, GPOs fallando
   - Causa: Pertenencia a demasiados grupos de seguridad
   - KB Microsoft: https://support.microsoft.com/en-us/help/327825
   - Impacto: Denegaci√≥n de servicio para usuarios espec√≠ficos (VIPs suelen ser los m√°s afectados)
   - Validaci√≥n datos: EstimatedTokenSize > 12000
   - Comando verificar: (Get-ADUser "SamAccountName" -Properties MemberOf).MemberOf.Count
   - Comando fix: Reducir membres√≠a de grupos, limpiar grupos anidados
   - Workaround temporal: Aumentar MaxTokenSize en servidores (regedit)
   - Timeline: Investigar y planificar limpieza de grupos en 30 d√≠as

**PARA CADA HALLAZGO, PROPORCIONA (EN ESPA√ëOL):**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: PASSWORD_NEVER_EXPIRES, PRIVILEGED_USERS_EXCESS, INACTIVE_ACCOUNTS, KERBEROASTING_VULN
  IMPORTANTE: Si encuentras un problema nuevo, genera un ID descriptivo (ej: WEAK_PASSWORD_POLICY).
  Este ID es CR√çTICO para agrupar hallazgos similares en reportes grandes.
  
- **T√≠tulo**: N√∫mero REAL de usuarios afectados + problema espec√≠fico
  Ejemplo: "15 usuarios con contrase√±as que nunca expiran detectados"
  
- **Descripci√≥n**: 2-3 p√°rrafos con:
  * N√∫mero exacto y problema (con datos de los findings)
  * Vector de ataque espec√≠fico (credential stuffing, brute force, etc.)
  * Impacto en negocio (acceso no autorizado, exfiltraci√≥n de datos, ransomware)
  * Referencia a CIS/MITRE con n√∫mero espec√≠fico
  * Regulaciones afectadas (GDPR Art. 32, NIST 800-53 IA-5)
  
- **Recomendaci√≥n**: Pasos inmediatamente ejecutables:
  * Comandos PowerShell con SamAccountName reales de los datos
  * Cada comando debe ser copy-paste ready
  * Script completo si son > 5 usuarios: ForEach-Object loop
  * Path de GPO para automatizar: Computer Config > Policies > Security Settings > Account Policies
  * Comando de verificaci√≥n post-fix
  * Nivel de dificultad: Bajo (1 comando) / Medio (requiere GPO) / Alto (requiere arquitectura)
  
- **Evidencia**: 
  * affected_objects: Array con SamAccountName reales (m√°ximo 10, si son m√°s indicar "...y X m√°s")
  * count: N√∫mero total REAL de los datos
  * details: Informaci√≥n espec√≠fica (ej: "LastLogonDate promedio: 245 d√≠as, PasswordLastSet promedio: 18 meses")`,

    GPOs: `Analiza estas Group Policy Objects para identificar configuraciones inseguras.

**‚ö†Ô∏è VALIDACI√ìN CR√çTICA PARA GPOs:**
- Si los datos muestran "cpassword": null o "cpassword" no aparece ‚Üí NO generar finding de cpassword
- Solo reporta GPOs que existan en los datos con valores problem√°ticos verificables
- Los comandos PowerShell deben ser ESPEC√çFICOS para GPO (Get-GPO, Get-GPOReport, Set-GPPermission)
- NO uses comandos no relacionados como Get-WMIObject para problemas de GPO

**BUSCA ESPEC√çFICAMENTE (CON EVIDENCIA REAL):**
1. **GPOs sin aplicar** (Links vac√≠os o deshabilitados)
   - Riesgo: Pol√≠ticas de seguridad no se est√°n aplicando
   - Comando para verificar: Get-GPO -All | Where-Object {$_.GpoStatus -eq 'AllSettingsDisabled'}
   
2. **Permisos peligrosos** (Authenticated Users puede editar)
   - Riesgo: Usuarios no privilegiados pueden modificar pol√≠ticas
   - CIS Control: 2.3.10.5 - Restrict GPO modification
   - Comando para auditar: Get-GPPermission -Name "GPO_NAME" -All

3. **GPO Preference Passwords** (cpassword con valor real en XML)
   - ‚ö†Ô∏è SOLO SI encuentras valor cpassword NO NULO
   - Riesgo: Contrase√±as almacenadas con cifrado reversible AES-256 crackeado
   - MITRE ATT&CK: T1552.006
   - Comando para buscar: Get-ChildItem "\\\\domain\\SYSVOL\\*\\Policies\\*\\Machine\\Preferences" -Recurse -Filter "*.xml" | Select-String "cpassword"

4. **‚ö†Ô∏è MEDIUM: GPOs Monol√≠ticas (Complejidad Excesiva)**
   - Si 'TotalSettings' > 50
   - Riesgo: Tiempos de inicio de sesi√≥n lentos, dificultad par debugar
   - Impacto: Higiene Operativa
   - Recomendaci√≥n: Dividir la GPO en unidades l√≥gicas m√°s peque√±as (ej: 'Browser Settings', 'Security Baseline')

5. **‚ö†Ô∏è HIGH: Desajuste de Versiones (Version Mismatch)**
   - Si 'UserDSVersion' != 'UserSysvolVersion' O 'ComputerDSVersion' != 'ComputerSysvolVersion'
   - Riesgo: Problemas de replicaci√≥n de SYSVOL (Journal Wrap, DFSR roto)
   - Impacto: Las pol√≠ticas pueden no aplicarse consistentemente en todos los DCs
   - Recomendaci√≥n: Forzar replicaci√≥n de SYSVOL o investigar errores de DFSR

6. **Configuraciones de seguridad d√©biles** (SOLO SI EST√ÅN EN LOS DATOS):
   - Password policy: MinimumPasswordLength < 14 caracteres
   - Lockout threshold: LockoutThreshold < 5 intentos o 0 (deshabilitado)
   - Maximum password age: > 90 d√≠as o 0 (nunca expira)
   - Password history: PasswordHistorySize < 24
   - Comando para verificar: Get-ADDefaultDomainPasswordPolicy

7. **GPOs con configuraciones conflictivas**
   - M√∫ltiples GPOs configurando el mismo setting
   - Comando para detectar: Get-GPOReport -Name "GPO_NAME" -ReportType HTML

**PARA CADA HALLAZGO, PROPORCIONA:**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: GPO_WEAK_PASSWORD_POLICY, GPO_UNLINKED, GPO_PREFERENCE_PASSWORD.
- **T√≠tulo**: En ESPA√ëOL, espec√≠fico con n√∫mero de GPOs afectadas
  Ejemplo: "2 GPOs con configuraciones de contrase√±a d√©biles detectadas"
  
- **Descripci√≥n**: En ESPA√ëOL, impacto en la postura de seguridad:
  * Qu√© configuraci√≥n espec√≠fica est√° mal (con valores reales de los datos)
  * Por qu√© facilita ataques (brute force, credential stuffing, etc.)
  * Impacto en cumplimiento (CIS, NIST, ISO 27001)
  
- **Recomendaci√≥n**: En ESPA√ëOL, pasos ACCIONABLES:
  * Path en GPMC: Computer Configuration > Policies > Windows Settings > Security Settings > ...
  * Configuraci√≥n correcta seg√∫n CIS Benchmark (valor espec√≠fico)
  * Comandos PowerShell SOLO para GPO (Get-GPO, Set-GPLink, etc.)
  * Cada comando debe incluir el nombre real del GPO de los datos
  * Comando de verificaci√≥n: Get-GPOReport -Name "NOMBRE_REAL" -ReportType XML
  
- **Evidencia**: Nombres REALES de GPOs de los datos y sus configuraciones problem√°ticas con valores espec√≠ficos`,

    Computers: `Analiza estos equipos de Active Directory para identificar riesgos.

**BUSCA ESPEC√çFICAMENTE:**
1. **Sistemas operativos obsoletos** (Windows Server 2008/2003, Windows 7/XP/Vista)
   - ‚ö†Ô∏è IMPORTANTE: Windows Server 2025, 2022, 2019, 2016 NO son obsoletos.
   - ‚ö†Ô∏è Windows Server 2012 R2 est√° en fin de soporte (EOL), pero 2025 es el M√ÅS NUEVO. NO lo marques como obsoleto.
   - Riesgo: Sin soporte, vulnerabilidades sin parchar
   - CIS Control: 7.1 - Maintain supported OS versions

2. **Equipos inactivos** (LastLogonDate > 90 d√≠as)
   - Riesgo: Equipos comprometidos no detectados
   
3. **Delegaci√≥n sin restricciones** (TrustedForDelegation=true, no DC)
   - Riesgo: Permite ataques de pass-the-ticket
   - MITRE ATT&CK: T1550.003

4. **Controladores de dominio**:
   - Versiones de OS desactualizadas
   - Roles FSMO mal distribuidos
   - Sin redundancia geogr√°fica

**PARA CADA HALLAZGO, PROPORCIONA:**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: OS_OBSOLETE, INACTIVE_COMPUTERS, UNCONSTRAINED_DELEGATION_COMPUTER.
- **T√≠tulo**: N√∫mero de equipos afectados y tipo de problema
- **Descripci√≥n**: Riesgo espec√≠fico y vectores de ataque
- **Recomendaci√≥n**: Plan de remediaci√≥n:
  * Para OS obsoletos: Plan de migraci√≥n/actualizaci√≥n
  * Para delegaci√≥n: C√≥mo deshabilitar o restringir
  * Comandos PowerShell para implementar
- **Evidencia**: Lista de equipos (hostname, OS, √∫ltima actividad)`,

    ReplicationStatus: `Analiza la salud de la replicaci√≥n de Active Directory y la topolog√≠a del bosque.

**‚ö†Ô∏è CONTEXTO CR√çTICO:**
La replicaci√≥n es el coraz√≥n de AD. Fallos aqu√≠ significan contrase√±as no sincronizadas, objetos fantasma y posible corrupci√≥n de la base de datos.
Debes detectar problemas de topolog√≠a, conexiones hu√©rfanas y errores de replicaci√≥n persistentes.

**üìä ESTRUCTURA DE DATOS (IMPORTANTE - LEE CON CUIDADO):**
Los datos vienen como objeto ReplicationStatus con 3 secciones:

1. **Connections** (array): Lista de conexiones de replicaci√≥n configuradas
   - From: DN del servidor origen (ej: "CN=NTDS Settings,CN=DC1,CN=Servers,CN=SiteName,...")
   - To: DN del servidor destino
   - Name: Nombre de la conexi√≥n (GUID o nombre manual)
   - AutoGenerated: true/false (si fue creada por KCC autom√°ticamente)
   - IsDeleted: true/false (si est√° marcada para eliminaci√≥n)

2. **Partners** (array): Estado actual de replicaci√≥n con cada partner
   - Partner: DN del partner de replicaci√≥n
   - LastSuccess: Timestamp de √∫ltima sincronizaci√≥n exitosa (formato /Date(timestamp)/)
   - LastResult: 0 = √©xito, otro valor = c√≥digo de error
   - Failures: n√∫mero de fallos consecutivos

3. **Errors** (array): Lista de errores de replicaci√≥n activos (vac√≠o si no hay problemas)

**=== SECCI√ìN 1: AN√ÅLISIS DE CONEXIONES ===**

1. **üî¥ CRITICAL: Objetos Eliminados (Lingering Objects)**
   - Conexiones donde From o To contienen "\\0ADEL:" o "DEL:"
   - Riesgo: Corrupci√≥n de base de datos, reaparici√≥n de objetos borrados
   - Acci√≥n: Eliminar conexi√≥n y ejecutar limpieza de metadatos

2. **‚ö†Ô∏è HIGH: Conexiones Marcadas como Eliminadas**
   - Conexiones con IsDeleted: true que a√∫n existen
   - Riesgo: Topolog√≠a inconsistente
   - Acci√≥n: Limpiar metadatos del DC eliminado

3. **‚ö†Ô∏è HIGH: Exceso de Conexiones (KCC Storm)**
   - Analiza cu√°ntas conexiones llegan a cada servidor (campo "To")
   - Si un servidor tiene > 10 conexiones entrantes: posible KCC storm
   - Riesgo: Sobrecarga de red, topolog√≠a ineficiente

4. **üìã INFO: Balance de Conexiones Autom√°ticas vs Manuales**
   - Cuenta conexiones con AutoGenerated: true vs false
   - Si hay muchas manuales (AutoGenerated: false): puede indicar modificaciones no est√°ndar
   - Best practice: KCC debe gestionar la mayor√≠a de conexiones

**=== SECCI√ìN 2: AN√ÅLISIS DE PARTNERS Y ESTADO DE REPLICACI√ìN ===**

5. **üî¥ CRITICAL: Fallos de Replicaci√≥n Activos**
   - Partners con LastResult != 0
   - Partners con Failures > 0
   - Incluye el c√≥digo de error espec√≠fico y nombre del partner afectado

6. **üî¥ CRITICAL: Replicaci√≥n Antigua**
   - Convierte LastSuccess de /Date(timestamp)/ a fecha legible
   - Si LastSuccess > 24 horas: CRITICAL
   - Si LastSuccess > 1 hora: HIGH
   - Si LastSuccess < 15 minutos: Saludable
   - Calcula: tiempo_actual - timestamp_en_milisegundos

7. **‚úÖ INFO: Estado Saludable**
   - Si Partners tiene todos LastResult: 0 y Failures: 0
   - Genera finding positivo indicando replicaci√≥n funcionando correctamente

**=== SECCI√ìN 3: AN√ÅLISIS DE ERRORES ===**

8. **üî¥ CRITICAL: Errores Activos**
   - Si el array Errors tiene elementos, analiza cada uno
   - Extrae c√≥digos de error, servidores afectados, mensajes

**=== AN√ÅLISIS DE TOPOLOG√çA ===**

9. **üìã HYGIENE: Extracci√≥n de Sitios**
   - De los DNs extrae los nombres de Sites (ej: "CN=Servers,CN=SiteName,CN=Sites")
   - Lista todos los sitios encontrados
   - Verifica si hay conexiones entre todos los sitios

10. **üìã HYGIENE: Extracci√≥n de DCs**
    - Extrae nombres de DCs de los campos From/To/Partner
    - Patr√≥n: "CN=NTDS Settings,CN=NOMBRE_DC,CN=Servers..."
    - Lista todos los DCs identificados

**üõ°Ô∏è VALIDACI√ìN ANTI-ALUCINACI√ìN:**

Antes de generar findings, CUENTA y VERIFICA:
1. Total de Connections: len(Connections[])
2. Total de Partners: len(Partners[])
3. Total de Errors: len(Errors[])
4. Para cada Partner: LastResult (0=ok), Failures (0=ok)
5. Extrae nombres REALES de DCs y Sites de los DNs

**EJEMPLO DE AN√ÅLISIS CORRECTO:**
Datos: {
  Connections: [{From:"...CN=DC1...", To:"...CN=DC2...", AutoGenerated:true}],
  Partners: [{Partner:"...CN=DC2...", LastResult:0, Failures:0, LastSuccess:"/Date(1234567890000)/"}],
  Errors: []
}
‚Üí 1 conexi√≥n configurada (DC1 ‚Üí DC2), auto-generada por KCC
‚Üí 1 partner activo con LastResult=0 (√©xito), 0 fallos
‚Üí 0 errores activos
‚Üí Finding: "REPLICATION_HEALTHY - Topolog√≠a de replicaci√≥n funcionando correctamente"

**PARA CADA HALLAZGO, PROPORCIONA:**
- **type_id**: REPLICATION_LINGERING_OBJECTS, REPLICATION_FAILURE_CRITICAL, REPLICATION_HEALTHY, REPLICATION_TOPOLOGY_ANALYSIS, etc.
- **T√≠tulo**: Descriptivo del problema o estado
- **Descripci√≥n**: Explica t√©cnicamente qu√© encontraste, con n√∫meros exactos
- **Recomendaci√≥n**: Comandos PowerShell espec√≠ficos (repadmin, Remove-ADReplicationConnection, ntdsutil)
- **Evidencia**: Nombres de servidores, sitios, c√≥digos de error, timestamps convertidos a fechas`,

    Groups: `Eres un auditor de seguridad especializado en privilegios y gesti√≥n de identidades en Active Directory.

**‚ö†Ô∏è CONTEXTO DE AN√ÅLISIS:**
Los grupos son el mecanismo principal de asignaci√≥n de permisos en AD. El exceso de privilegios es una de las vulnerabilidades m√°s explotadas en compromisos de dominio. Debes buscar desviaciones del principio de least privilege y grupos con configuraciones que faciliten escalaci√≥n de privilegios.

**üéØ PRIORIDADES DE DETECCI√ìN (EN ORDEN):**

1. **üî¥ CRITICAL: Grupos de Tier 0 sobrepoblados**
   - Domain Admins (o "Admins. del dominio") > 5 miembros permanentes
   - Enterprise Admins (o "Administradores de empresas") > 3 miembros
   - Schema Admins (o "Administradores de esquema") con miembros permanentes
   - Administrators (o "Administradores") > 10 miembros
   - Riesgo: Superficie de ataque masiva, dificulta respuesta a incidentes
   - MITRE ATT&CK: T1078.002 (Valid Accounts: Domain Accounts)
   - CIS Control: 5.4 - Restrict Administrator Privileges to Dedicated Accounts
   - Impacto: Un solo compromiso = control total del dominio
   - Comando auditor√≠a: Get-ADGroupMember "Domain Admins" | Measure-Object | Select-Object Count
   - Comando detalle: Get-ADGroupMember "Domain Admins" -Recursive | Get-ADUser -Properties Enabled,LastLogonDate,PasswordLastSet
   - Timeline: Remediar INMEDIATAMENTE (48 horas)

2. **üî¥ HIGH: Cuentas de usuario est√°ndar en grupos privilegiados**
   - Buscar cuentas sin prefijo admin/svc/srv en Domain Admins
   - Ejemplo: "juan.perez" en vez de "admin-juan.perez"
   - Riesgo: Cuentas admin usadas para tareas diarias, mayor exposici√≥n a phishing
   - CIS Control: 5.1 - Establish and Maintain an Inventory of Accounts
   - Comando verificar: Get-ADGroupMember "Domain Admins" | Where-Object {$_.SamAccountName -notlike "admin*" -and $_.SamAccountName -notlike "svc*"}
   - Timeline: Crear cuentas admin separadas en 7 d√≠as

3. **üî¥ HIGH: Protected Users Group no implementado**
   - Grupo debe contener TODAS las cuentas Tier 0/1
   - Si est√° vac√≠o o < 50% de cuentas privilegiadas ‚Üí HIGH finding
   - Riesgo: Cuentas admin vulnerables a pass-the-hash, Kerberos delegation attacks
   - CIS Control: 5.8 - Add Privileged Accounts to Protected Users Group
   - Protecci√≥n: Deshabilita NTLM, DES/RC4, delegaci√≥n, credential caching
   - Comando verificar: Get-ADGroupMember "Protected Users" | Measure-Object
   - Comando fix: Add-ADGroupMember -Identity "Protected Users" -Members (Get-ADGroupMember "Domain Admins")
   - Timeline: Implementar en 14 d√≠as tras testing de compatibilidad

4. **‚ö†Ô∏è MEDIUM: Grupos privilegiados con miembros inactivos**
   - Miembros de grupos admin sin LastLogonDate en > 90 d√≠as
   - Riesgo: Cuentas olvidadas, posibles backdoors
   - Comando: Get-ADGroupMember "Domain Admins" | Get-ADUser -Properties LastLogonDate | Where-Object {$_.LastLogonDate -lt (Get-Date).AddDays(-90)}
   - Timeline: Revisar y remover en 30 d√≠as

5. **‚ö†Ô∏è MEDIUM: Anidamiento complejo de grupos**
   - Grupos dentro de grupos > 3 niveles de profundidad
   - Riesgo: Permisos heredados no evidentes, dificulta auditor√≠a
   - Ejemplo problem√°tico: GroupA ‚Üí GroupB ‚Üí GroupC ‚Üí Domain Admins
   - Comando: Get-ADGroup -Filter * -Properties MemberOf | Where-Object {$_.MemberOf.Count -gt 0}

**üèÜ MEJORES PR√ÅCTICAS - BASELINE RECOMENDADO:**
- **Tier 0 (Domain/Enterprise Admins)**: M√°ximo 3-5 cuentas permanentes, dedicadas solo a tareas cr√≠ticas de dominio
- **Tier 1 (Server Admins)**: Separados de Tier 0, m√°ximo 10 cuentas, solo para gesti√≥n de servidores
- **Tier 2 (Workstation Admins)**: Separados de Tier 0/1, para soporte de escritorio
- **Naming Convention**: Cuentas admin deben tener prefijo identificable (admin-, adm-, svc-)
- **Protected Users**: 100% de cuentas Tier 0 deben estar en este grupo
- **Revisi√≥n peri√≥dica**: Auditor√≠a trimestral de membres√≠a en grupos privilegiados
- **Justificaci√≥n documentada**: Cada miembro debe tener business justification aprobada
- **Separaci√≥n de deberes**: Administradores de diferentes √°reas en grupos diferentes
- **JIT Access**: Implementar Privileged Identity Management (PIM) para acceso temporal

**üìã FORMATO DE REPORTE - CADA FINDING DEBE INCLUIR:**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: TIER0_GROUP_OVERPOPULATED, ADMIN_IN_PROTECTED_USERS_MISSING, INACTIVE_GROUP_MEMBERS.
- **T√≠tulo** (ESPA√ëOL): "[N√öMERO] cuentas no autorizadas en grupo [NOMBRE]" o "Grupo [NOMBRE] sobrepoblado con [COUNT] miembros"
- **Descripci√≥n** (3 p√°rrafos obligatorios):
  * P√°rrafo 1 - ESTADO ACTUAL: N√∫mero exacto, nombres de grupos afectados, configuraci√≥n actual vs baseline recomendado
  * P√°rrafo 2 - RIESGO: Vector de ataque espec√≠fico (credential theft, lateral movement), t√©cnicas MITRE ATT&CK aplicables
    - Proceso de aprobaci√≥n: Requiere sign-off de CISO + CIO
  * FASE 3 - HARDENING (Semana 4):
    - Implementar naming convention: Renombrar cuentas a formato admin-firstname.lastname
    - Agregar a Protected Users: Add-ADGroupMember -Identity "Protected Users" -Members (Get-ADGroupMember "Domain Admins")
    - Configurar alertas: Event ID 4728 (miembro agregado a grupo privilegiado) ‚Üí SIEM
  * FASE 4 - AUTOMATIZACI√ìN (Mes 2):
    - Implementar JIT access con Azure AD PIM o ManageEngine PAM360
    - Script de auditor√≠a mensual autom√°tico
    - Dashboard de compliance en PowerBI/Grafana
  * VALIDACI√ìN POST-IMPLEMENTACI√ìN:
    - Verificar: (Get-ADGroupMember "Domain Admins").Count -le 5
    - Verificar: Get-ADGroupMember "Protected Users" debe contener todas las cuentas admin
    - Test de acceso: Validar que cuentas removidas no tienen acceso privilegiado
- **Evidencia**: affected_objects con nombres REALES (m√°ximo 10, luego "...y X m√°s"), affected_count preciso, details con estad√≠sticas (promedio LastLogonDate, distribuci√≥n por OU)`,

    DCHealth: `Analiza la salud operativa y higiene de los controladores de dominio.

**‚ö†Ô∏è CONTEXTO DE AN√ÅLISIS:**
Este es un an√°lisis de HIGIENE OPERATIVA, no de seguridad ofensiva. El objetivo es identificar desorden administrativo, deuda t√©cnica y configuraciones sub√≥ptimas que hacen la infraestructura inestable e ineficiente.

**üéØ BUSCA ESPEC√çFICAMENTE:**

## PARTE A: PROBLEMAS OPERATIVOS TRADICIONALES

1. **Problemas de replicaci√≥n** (ConsecutiveReplicationFailures > 0)
   - Impacto: Inconsistencia de datos entre DCs, usuarios con credenciales desactualizadas
   - Comando verificar: repadmin /showrepl
   - Timeline: Remediar en 24-48 horas

2. **Versiones de OS obsoletas** (< Windows Server 2016)
   - Impacto: Sin soporte de Microsoft, sin actualizaciones de seguridad
   - Timeline: Planificar migraci√≥n en 90 d√≠as

3. **Roles FSMO concentrados** (todos en un solo DC)
   - Impacto: Single point of failure - si ese DC falla, operaciones cr√≠ticas se detienen
   - Comando verificar: netdom query fsmo
   - Timeline: Redistribuir roles en 30 d√≠as

4. **AD Recycle Bin deshabilitado**
   - Impacto: No se pueden recuperar objetos eliminados accidentalmente
   - Comando habilitar: Enable-ADOptionalFeature -Identity "Recycle Bin Feature" -Scope ForestOrConfigurationSet -Target (Get-ADForest).Name
   - Timeline: Habilitar inmediatamente

5. **Tombstone Lifetime** (< 180 d√≠as)
   - Impacto: Riesgo de objetos lingering si backup tiene m√°s antig√ºedad
   - Timeline: Evaluar y ajustar en 30 d√≠as

6. **üî¥ Sincronizaci√≥n de Tiempo (NTP) Incorrecta**
   - Analiza la secci√≥n 'TimeSyncConfig' en los datos.
   - **PDC Emulator**: Debe usar fuente externa (NTP) confiable.
     - CRITICAL: Si Source es "Local CMOS Clock", "Free-running System Clock" o "VM IC Time Sync Provider".
   - **Otros DCs**: Deben sincronizar v√≠a NT5DS (jerarqu√≠a de dominio).
   - Impacto: Fallos de Kerberos (si desv√≠o > 5 min), problemas de replicaci√≥n
   - Timeline: Remediar INMEDIATAMENTE (24 horas)

## PARTE B: AN√ÅLISIS DE HIGIENE (HygieneAnalysis)

Si los datos incluyen la secci√≥n 'HygieneAnalysis', analiza cada categor√≠a:

7. **üî¥ CRITICAL: Cuentas de Equipo Fantasma (GhostComputers)**
   - Son equipos que ya no existen f√≠sicamente pero siguen en AD, causando errores NETLOGON
   - Indicador: Errores "No logon servers available" o "session setup failed" en logs
   - Impacto: Ruido en logs, confusi√≥n operativa, posible uso de licencias innecesarias
   - type_id: GHOST_COMPUTER_ACCOUNTS
   - Remediaci√≥n:
     * Verificar si el equipo existe: Test-Connection -ComputerName "NOMBRE" -Count 1
     * Si no existe, deshabilitarlo primero: Disable-ADAccount -Identity "CN=NOMBRE,OU=Computers,DC=domain,DC=com"
     * Despu√©s de 30 d√≠as sin reclamaciones, eliminarlo: Remove-ADComputer -Identity "NOMBRE"
   - Timeline: Investigar en 7 d√≠as, limpiar en 30 d√≠as

8. **üî¥ CRITICAL: Fallos de Confianza (TrustFailures)**
   - Errores de autenticaci√≥n entre dominios/bosques debido a trusts rotos
   - Indicador: Errores "trust relationship failed" o "domain controller not found"
   - Impacto: Usuarios de dominios de confianza no pueden autenticarse
   - type_id: TRUST_RELATIONSHIP_FAILURE
   - Remediaci√≥n:
     * Verificar estado del trust: Get-ADTrust -Filter * | Test-ADTrustRelationship
     * Reparar trust: netdom trust DOMINIO /domain:OTRO_DOMINIO /reset /passwordT:CONTRASE√ëA
   - Timeline: Remediar INMEDIATAMENTE (4-8 horas)

9. **‚ö†Ô∏è HIGH: Desincronizaci√≥n de Credenciales (CredentialDesync)**
   - Cuentas de equipo con contrase√±as desincronizadas entre AD y el equipo local
   - Indicador: Errores "secure channel" o "access denied" intermitentes
   - Impacto: Fallos de autenticaci√≥n Kerberos, acceso denegado a recursos de red
   - type_id: CREDENTIAL_DESYNC
   - Remediaci√≥n:
     * Reset del canal seguro: Test-ComputerSecureChannel -Repair -Credential (Get-Credential)
     * O desde el DC: Reset-ComputerMachinePassword -Server DC01 -Credential (Get-Credential)
   - Timeline: Remediar en 24-48 horas

10. **‚ö†Ô∏è HIGH: Fallos de Canal Seguro (SecureChannelFailures)**
    - El canal seguro entre equipo y DC est√° comprometido
    - Indicador: Errores "NETLOGON_EVENT_TYPE_3210" o similar
    - Impacto: El equipo no puede autenticarse contra el dominio
    - type_id: SECURE_CHANNEL_FAILURE
    - Remediaci√≥n:
      * Desde el equipo afectado: Test-ComputerSecureChannel -Repair
      * Si falla, desunir y reunir al dominio
    - Timeline: Remediar en 24 horas

11. **‚ö†Ô∏è MEDIUM: Problemas de Partners de Replicaci√≥n (ReplicationPartnerIssues)**
    - DCs que no pueden comunicarse con sus partners de replicaci√≥n
    - Indicador: Errores "RPC server unavailable" o timeouts de replicaci√≥n
    - Impacto: Cambios no se propagan, inconsistencia de datos
    - type_id: REPLICATION_PARTNER_ISSUE
    - Remediaci√≥n:
      * Verificar conectividad: repadmin /replsummary
      * Forzar replicaci√≥n: repadmin /syncall /AdeP
      * Verificar DNS: nslookup -type=srv _ldap._tcp.dc._msdcs.DOMINIO
    - Timeline: Remediar en 24-48 horas

**üìã FORMATO DE SALIDA:**

Para CADA hallazgo (ya sea tradicional o de HygieneAnalysis), proporciona:
- **type_id**: Identificador √öNICO en MAY√öSCULAS_CON_GUIONES (ej: GHOST_COMPUTER_ACCOUNTS, TRUST_RELATIONSHIP_FAILURE)
- **T√≠tulo**: Descripci√≥n concisa del problema
- **Descripci√≥n**: Impacto operativo (NO de seguridad ofensiva)
- **severity**: CRITICAL/HIGH/MEDIUM/LOW basado en impacto operativo
- **Recomendaci√≥n**: Pasos de remediaci√≥n con comandos PowerShell exactos
- **affected_objects**: Lista de equipos/DCs afectados (m√°ximo 10, luego "...y X m√°s")
- **affected_count**: N√∫mero total de objetos afectados
- **details**: Estad√≠sticas relevantes (conteos, promedios, distribuci√≥n)

**‚ö†Ô∏è REGLA ANTI-ALUCINACI√ìN:** Solo reporta objetos que aparezcan EXPL√çCITAMENTE en los datos proporcionados. NO inventes nombres de equipos o DCs.`,

    DNS: `Eres un especialista en seguridad de infraestructura DNS de Active Directory con experiencia en detecci√≥n de misconfigurations y vulnerabilidades de resoluci√≥n de nombres.

**‚ö†Ô∏è CONTEXTO DE AN√ÅLISIS:**
DNS es cr√≠tico en AD - todos los servicios dependen de √©l (Kerberos, LDAP, replicaci√≥n). Un DNS mal configurado puede permitir ataques de man-in-the-middle, DNS spoofing, y denial of service.

**‚ö†Ô∏è REGLA ANTI-ALUCINACI√ìN:**
Solo reporta configuraciones DNS que aparezcan EXPL√çCITAMENTE en los datos proporcionados.
Para DNS Forwarders, los datos incluyen objetos con estructura: {DCName, Forwarders[], ForwardingTimeout, IsSlave, SecurityWarning}.
NO inventes nombres de DCs, IPs de forwarders, o zonas DNS que no existan en los datos.

**üéØ BUSCA ESPEC√çFICAMENTE:**

1. **‚ö†Ô∏è MEDIUM: DNS Forwarders con Servidores P√∫blicos (Riesgo de Exposici√≥n)**
   - Si encuentras objetos en los datos con Type='ForwardersConfig' o campo 'Forwarders' con IPs p√∫blicas
   - IPs p√∫blicas conocidas: 8.8.8.8, 8.8.4.4 (Google), 1.1.1.1, 1.0.0.1 (Cloudflare), 208.67.222.222, 208.67.220.220 (OpenDNS)
   - Riesgo: Consultas DNS internas pueden filtrarse a proveedores externos, revelando nombres internos de servidores
   - Impacto: P√©rdida de privacidad, posible enumeraci√≥n de infraestructura interna
   - CIS Control: 2.2.5 - Configure DNS forwarders to internal or controlled servers
   - Comando verificar: Get-DnsServerForwarder
   - Comando fix: Remove-DnsServerForwarder -IPAddress "8.8.8.8"; Add-DnsServerForwarder -IPAddress "IP_DNS_INTERNO"
   - Recomendaci√≥n: Usar servidores DNS internos o proxies DNS corporativos que no filtren consultas
   - Timeline: Remediar en 30 d√≠as

2. **‚ö†Ô∏è LOW: DNS sin Forwarders configurados (Solo Root Hints)**
   - Si Forwarders array est√° vac√≠o o no existe
   - Riesgo: Resoluci√≥n DNS m√°s lenta para dominios externos, mayor dependencia de root hints
   - Impacto: Puede causar timeouts leves en aplicaciones, pero es una configuraci√≥n v√°lida
   - Comando verificar: Get-DnsServerForwarder
   - Comando fix: Add-DnsServerForwarder -IPAddress "IP_DNS_CORPORATIVO"
   - Recomendaci√≥n: Evaluar si es intencional (por pol√≠ticas de seguridad) o necesita configuraci√≥n
   - Timeline: Evaluar en 60 d√≠as

2. **üî¥ HIGH: Zonas DNS con transferencias no seguras**
   - Si AllowZoneTransfer = true sin restricci√≥n de IPs
   - Riesgo: Enumeraci√≥n completa de infraestructura (hostnames, IPs, estructura organizacional)
   - MITRE ATT&CK: T1590.002 (Gather Victim Network Information: DNS)
   - Comando verificar: Get-DnsServerZone | Where-Object {$_.SecureSecondaries -eq 'NoTransfer'}
   - Comando fix: Set-DnsServerPrimaryZone -Name "domain.com" -SecureSecondaries "TransferToSecureServers"
   - Timeline: Remediar INMEDIATAMENTE (48 horas)

3. **‚ö†Ô∏è MEDIUM: Scavenging deshabilitado**
   - Registros DNS obsoletos no se limpian autom√°ticamente
   - Riesgo: DNS cache poisoning m√°s efectivo, confusi√≥n en resoluci√≥n
   - Comando verificar: Get-DnsServerScavenging
   - Comando habilitar: Set-DnsServerScavenging -ScavengingState $true -ScavengingInterval "7.00:00:00"
   - Timeline: Habilitar en 30 d√≠as

4. **‚ÑπÔ∏è INFO: N√∫mero de zonas DNS**
   - Reportar total de zonas (primarias, secundarias, stub)
   - No es problema, solo visibilidad de complejidad

**üìã SOLO GENERA FINDING SI:**
- Forwarders = [] (array vac√≠o) o null
- SecureSecondaries permite transferencias no autorizadas
- ScavengingEnabled = false

**FORMATO DE REPORTE:**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: DNS_NO_FORWARDERS, DNS_ZONE_TRANSFER_INSECURE, DNS_SCAVENGING_DISABLED.
- **T√≠tulo**: "DNS sin forwarders configurados" o "[N] zonas DNS con transferencias no seguras"
- **Descripci√≥n**: Impacto en performance/seguridad, escenarios de ataque
- **Recomendaci√≥n**: Comandos PowerShell espec√≠ficos para fix
- **Evidencia**: Configuraci√≥n actual, IPs de forwarders recomendados`,

    DHCP: `Eres un especialista en seguridad de servicios de red Windows Server con enfoque en DHCP y detecci√≥n de rogue servers.

**‚ö†Ô∏è CONTEXTO DE AN√ÅLISIS:**
DHCP asigna configuraci√≥n de red cr√≠tica (IP, gateway, DNS servers). Un DHCP comprometido o rogue puede redirigir tr√°fico, capturar credenciales, y ejecutar man-in-the-middle attacks.

**üéØ BUSCA ESPEC√çFICAMENTE:**

1. **üî¥ CRITICAL: Rogue DHCP Servers detectados**
   - Servidores DHCP NO autorizados en AuthorizedServers
   - Riesgo: Man-in-the-middle, credential theft, DNS spoofing
   - MITRE ATT&CK: T1557.001 (Man-in-the-Middle: LLMNR/NBT-NS Poisoning)
   - Impacto: Atacante puede interceptar TODO el tr√°fico de red
   - Comando detectar: Get-DhcpServerInDC | Compare-Object -ReferenceObject (netsh dhcp show server)
   - Timeline: Deshabilitar INMEDIATAMENTE (< 1 hora)

2. **üî¥ HIGH: Agotamiento de IPs en Scopes**
   - Si PercentageInUse > 80%
   - Riesgo: Denegaci√≥n de servicio (DoS), nuevos dispositivos no reciben IP
   - Impacto: Interrupci√≥n de operaciones de negocio en la subnet afectada
   - Comando verificar: Get-DhcpServerv4ScopeStatistics | Where-Object { $_.PercentageInUse -gt 80 }
   - Recomendaci√≥n: Reducir lease time, expandir subnet, o usar SuperScopes
   - Timeline: Remediar en 24 horas

3. **‚ö†Ô∏è MEDIUM: Scopes sin configuraci√≥n de seguridad**
   - Conflict detection attempts < 2
   - Delay time < 1000ms (permite DHCP starvation)
   - Comando verificar: Get-DhcpServerv4Scope | Get-DhcpServerv4ScopeStatistics
   - Timeline: Configurar en 30 d√≠as

4. **‚ö†Ô∏è MEDIUM: Auditing de DHCP deshabilitado**
   - No hay logs de asignaciones IP
   - Riesgo: Imposible rastrear actividad maliciosa en investigaciones forenses
   - Comando habilitar: Set-DhcpServerAuditLog -Enable $true
   - Timeline: Habilitar en 14 d√≠as

5. **‚ö†Ô∏è MEDIUM: Falta de Redundancia (Failover)**
   - Scopes sin configuraci√≥n de Failover (Load Balance o Hot Standby).
   - Riesgo: P√©rdida de servicio DHCP y conectividad de red si cae el servidor.
   - Comando verificar: Get-DhcpServerv4Failover
   - Recomendaci√≥n: Configurar DHCP Failover con un socio.

6. **‚ÑπÔ∏è INFO/LOW: Tiempos de Lease Inadecuados**
   - Lease < 8 horas (redes cableadas estables) o > 24 horas (WiFi invitados/din√°micos).
   - Analizar 'ScopeDetails' -> 'LeaseDuration'.
   - Riesgo: Agotamiento de IPs (lease muy largo) o tr√°fico excesivo (lease muy corto).
   - Recomendaci√≥n: Ajustar seg√∫n tipo de red (8 d√≠as para desktops, 2-4 horas para WiFi).

7. **‚ÑπÔ∏è INFO: DHCP no configurado**
   - Si Scopes = [] y AuthorizedServers = []
   - Reportar que DHCP no est√° en uso o datos no disponibles
   - NO es vulnerabilidad, solo informaci√≥n

**üìã SOLO GENERA FINDING SI:**
- Hay servidores DHCP no autorizados (CRITICAL)
- PercentageInUse > 80% (HIGH)
- Scopes tienen configuraci√≥n d√©bil (MEDIUM)
- Auditing est√° deshabilitado (MEDIUM)
- Si todo est√° vac√≠o ‚Üí INFO "DHCP no configurado o datos no disponibles"

**FORMATO DE REPORTE:**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: DHCP_ROGUE_SERVER, DHCP_SCOPE_EXHAUSTED, DHCP_AUDIT_DISABLED, DHCP_WEAK_SCOPE_CONFIG.
- **T√≠tulo**: "[N] servidores DHCP no autorizados detectados" o "Auditing de DHCP deshabilitado"
- **Descripci√≥n**: Vector de ataque, impacto en red
- **Recomendaci√≥n**: Comandos para autorizar/remover servers, habilitar logging
- **Evidencia**: IPs de servers, configuraci√≥n actual`,

    FSMORolesHealth: `Analiza la salud de los roles FSMO del dominio.

**‚ö†Ô∏è CONTEXTO:**
Los roles FSMO son cr√≠ticos para la operaci√≥n de AD. Si un rol no es accesible, puede causar fallos en la creaci√≥n de objetos, autenticaci√≥n o actualizaciones de esquema.

**BUSCA ESPEC√çFICAMENTE:**
1. **üî¥ CRITICAL: Roles Inaccesibles**
   - Si IsAccessible = false
   - Si DNSResolution = "FAILED"
   - Si NetworkTest = "FAILED"
   - Riesgo: Fallo operativo mayor (ej. no se pueden crear usuarios si RID Master falla).

2. **‚ö†Ô∏è HIGH: Latencia Excesiva**
   - ResponseTimeMs > 200ms (en LAN) o > 500ms (WAN).
   - ADResponseTimeMs > 1000ms (DC sobrecargado).

3. **‚ö†Ô∏è MEDIUM: RID Pool bajo**
   - Si PercentUsed > 90% o Warning existe.
   - Acci√≥n: Monitorear o solicitar nuevo pool.

4. **‚ÑπÔ∏è INFO: Distribuci√≥n de Roles**
   - Reportar qu√© DC tiene qu√© roles.
   - Best practice: Schema/Naming en un DC, PDC/RID/Infra en otro (para dominios grandes).

**FORMATO REPORTE:**
- **type_id**: FSMO_ROLE_FAILURE, FSMO_HIGH_LATENCY, FSMO_RID_POOL_EXHAUSTED.
- **T√≠tulo**: "Rol FSMO [ROL] inaccesible en [SERVER]".
- **Descripci√≥n**: Impacto operativo espec√≠fico del rol fallido.
- **Evidencia**: Tiempos de respuesta, errores de DNS.`,

    ReplicationHealthAllDCs: `Analiza la topolog√≠a y salud de replicaci√≥n completa.

**‚ö†Ô∏è CONTEXTO:**
Una visi√≥n global de la replicaci√≥n es vital para detectar islas de replicaci√≥n o fallos sist√©micos.

**BUSCA ESPEC√çFICAMENTE:**
1. **üî¥ CRITICAL: DCs Inalcanzables o Aislados**
   - Health = "Unreachable" o "Critical".
   - Riesgo: DC desactualizado, puede servir datos antiguos o permitir accesos revocados.

2. **üî¥ CRITICAL: Latencia de Replicaci√≥n Extrema**
   - ReplicationLagMinutes > 1440 (24 horas).
   - "Tombstone Lifetime" risk (objetos borrados pueden revivir).

3. **‚ö†Ô∏è MEDIUM: Errores de Enlace**
   - FailedLinks > 0.
   - Analizar ErrorMessage (ej. "RPC server unavailable", "Access denied").

**FORMATO REPORTE:**
- **type_id**: REPLICATION_TOPOLOGY_BROKEN, REPLICATION_DC_UUNREACHABLE, REPLICATION_LAG_CRITICAL.
- **T√≠tulo**: "N DCs con fallos cr√≠ticos de replicaci√≥n" o "DC [NOMBRE] aislado del dominio".
- **Recomendaci√≥n**: Comandos repadmin o revisi√≥n de firewalls (puertos 135, 49152-65535, 389, 88).`,

    LingeringObjectsRisk: `Analiza el riesgo de Lingering Objects (Objetos Fantasma).

**‚ö†Ô∏è CONTEXTO:**
Los objetos fantasma ocurren cuando un DC no replica por m√°s tiempo que el Tombstone Lifetime (180 d√≠as t√≠pica). Si se reconecta, puede reintroducir objetos borrados.

**BUSCA ESPEC√çFICAMENTE:**
1. **üî¥ CRITICAL: Evidencia Confirmada**
   - RiskLevel = "Critical" o Indicators contiene "ReplicationError" (8606, 8614).
   - Acci√≥n: Aislamiento INMEDIATO del DC afectado. NO replicar.

2. **‚ö†Ô∏è MEDIUM: Riesgo Potencial (USN Gap)**
   - RiskLevel = "Medium" o USN Gap > 100,000.
   - Acci√≥n: Habilitar "Strict Replication Consistency".

**FORMATO REPORTE:**
- **type_id**: REPLICATION_LINGERING_OBJECTS_CONFIRMED, REPLICATION_LINGERING_OBJECTS_RISK.
- **T√≠tulo**: "Riesgo CR√çTICO de objetos fantasma detectado en [DC]".
- **Descripci√≥n**: Explicar qu√© es un lingering object y por qu√© corrompe el directorio.
- **Recomendaci√≥n**: Procedimiento espec√≠fico de limpieza (Strict Replication Consistency, repadmin /removelingeringobjects).`,

    TrustHealth: `Analiza la salud de las relaciones de confianza (Trusts).

**BUSCA ESPEC√çFICAMENTE:**
1. **üî¥ CRITICAL: Trust Roto o Fallido**
   - OverallHealth = "Degraded" o "Broken".
   - ValidationTests contains "FAILED".
   - Riesgo: P√©rdida de acceso a recursos entre dominios.

2. **üî¥ HIGH: Configuraci√≥n Insegura (SID Filtering)**
   - SecurityWarning present ("SID Filtering disabled").
   - Riesgo: Elevaci√≥n de privilegios desde el dominio confiado (SID History Injection).

3. **‚ö†Ô∏è MEDIUM: Password de Trust no rotado**
   - DaysSinceModified > 60-90 d√≠as (autom√°tico deber√≠a ser 30).
   - Riesgo: Si la password no rota, puede indicar fallo en el canal seguro.

**FORMATO REPORTE:**
- **type_id**: TRUST_BROKEN, TRUST_INSECURE_CONFIG, TRUST_PASSWORD_STALE.
- **T√≠tulo**: "Confianza [NOMBRE] rota o degradada" o "Filtrado de SID deshabilitado en [TRUST]".
- **Recomendaci√≥n**: Reset-ComputerMachinePassword, netdom trust /verify, habilitar SID filtering (netdom trust /quarantine).`,

    OrphanedTrusts: `Analiza trusts hu√©rfanos (apuntan a dominios inexistentes).

**BUSCA ESPEC√çFICAMENTE:**
1. **‚ö†Ô∏è HIGH: Trusts Hu√©rfanos**
   - Status = "ORPHANED".
   - Riesgo: Retrasos en autenticaci√≥n, "ruido" en logs, posible vector si alguien registra el dominio expirado.

2. **‚ö†Ô∏è MEDIUM: Trusts Sospechosos**
   - Status = "SUSPICIOUS" (Fallo DNS o LDAP).

**FORMATO REPORTE:**
- **type_id**: TRUST_ORPHANED, TRUST_SUSPICIOUS.
- **T√≠tulo**: "Relaci√≥n de confianza hu√©rfana detectada: [TARGET]".
- **Recomendaci√≥n**: Eliminar trusts obsoletos (Remove-ADTrust).`,

    DNSRootHints: `Analiza los Root Hints de DNS.

**BUSCA ESPEC√çFICAMENTE:**
1. **‚ö†Ô∏è MEDIUM: Root Hints Obsoletos**
   - Health = "Outdated".
   - IPs no coinciden con las de IANA (ej. IP antigua de b.root-servers.net).
   - Riesgo: Fallos espor√°dicos en resoluci√≥n externa.

2. **‚ö†Ô∏è MEDIUM: Root Hints Inalcanzables**
   - Health = "Degraded" (pocos servidores alcanzables).
   - Riesgo: Rendimiento pobre o fallo total de resoluci√≥n externa si caen forwarders.

**FORMATO REPORTE:**
- **type_id**: DNS_ROOT_HINTS_OUTDATED, DNS_ROOT_HINTS_UNREACHABLE.
- **T√≠tulo**: "Root Hints desactualizados en [DC]".
- **Recomendaci√≥n**: Actualizar via GUI DNS o PowerShell (Import-DnsServerRootHint).`,

    DNSConflicts: `Analiza conflictos en registros DNS.

**BUSCA ESPEC√çFICAMENTE:**
1. **‚ö†Ô∏è MEDIUM: Duplicados de Registros A**
   - DuplicateARecords.Count > 0.
   - Riesgo: Round-robin no intencionado, conexi√≥n a host incorrecto.

2. **‚ö†Ô∏è LOW: CNAMEs Hu√©rfanos**
   - OrphanedCNAMEs.Count > 0.
   - Riesgo: Resoluci√≥n fallida para alias.

3. **‚ö†Ô∏è LOW: Registros Obsoletos (Stale)**
   - StaleRecords.Count > 0 (si son muchos).
   - Riesgo: Base de datos sucia.

**FORMATO REPORTE:**
- **type_id**: DNS_RECORD_CONFLICT, DNS_ORPHANED_CNAME, DNS_STALE_RECORDS.
- **T√≠tulo**: "Conflictos de nombres DNS detectados ([COUNT])".
- **Recomendaci√≥n**: Limpieza manual o habilitar scavenging.`,

    DNSScavengingDetailed: `Analiza la configuraci√≥n de limpieza (Scavenging) de DNS a fondo.

**BUSCA ESPEC√çFICAMENTE:**
1. **üî¥ CRITICAL: Mismatch de Configuraci√≥n**
   - Issues.Type = "AgingMismatch".
   - Descripci√≥n: "Scavenging habilitado en server pero Aging deshabilitado en zona (o viceversa)".
   - Resultado: NO se borrar√° nada. La base de datos crecer√° indefinidamente.

2. **‚ö†Ô∏è MEDIUM: Zonas sin Aging**
   - Recomendaci√≥n: Habilitar Aging en todas las zonas din√°micas.

**FORMATO REPORTE:**
- **type_id**: DNS_SCAVENGING_MISCONFIGURED, DNS_ZONE_AGING_DISABLED.
- **T√≠tulo**: "Configuraci√≥n de limpieza DNS inconsistente en [DC]".
- **Recomendaci√≥n**: Set-DnsServerZoneAging.`,

    DHCPRogueServers: `Analiza servidores DHCP no autorizados (Rogue).
    
**‚ö†Ô∏è PRIORIDAD M√ÅXIMA:** Rogue DHCP es un ataque activo o un riesgo severo de disponibilidad.

**BUSCA ESPEC√çFICAMENTE:**
1. **üî¥ CRITICAL: Servidor Rogue Detectado**
   - RogueServers.Count > 0.
   - Descripci√≥n: IP [IP] est√° sirviendo DHCP pero no est√° autorizada en AD.
   - Riesgo: Man-in-the-Middle, interrupci√≥n de red.

**FORMATO REPORTE:**
- **type_id**: DHCP_ROGUE_DETECTED.
- **T√≠tulo**: "Servidor DHCP no autorizado detectado: [IP]".
- **Recomendaci√≥n**: Localizar por MAC address en switch y apagar puerto. Bloquear IP.`,

    DHCPOptionsAudit: `Audita opciones de √°mbitos DHCP.

**BUSCA ESPEC√çFICAMENTE:**
1. **üî¥ HIGH: DNS Incorrectos en DHCP**
   - Issues.Severity = "HIGH" y Option = 6.
   - Descripci√≥n: Clientes reciben IPs de DNS que no son DCs o no responden.
   - Riesgo: Clientes no pueden contactar AD, fallos de logon.

2. **‚ö†Ô∏è MEDIUM: Dominio Incorrecto**
   - Issues.Option = 15 (Mismatch).
   - Clientes reciben sufijo DNS incorrecto.

3. **‚ö†Ô∏è LOW: Opciones WINS Deprecadas**
   - Opciones 44/46 presentes.
   - Best practice: Eliminar WINS si no se usa.

**FORMATO REPORTE:**
- **type_id**: DHCP_OPTION_CRITICAL, DHCP_OPTION_MISMATCH, DHCP_WINS_DEPRECATED.
- **T√≠tulo**: "Configuraci√≥n DNS inv√°lida en √°mbitos DHCP".
- **Recomendaci√≥n**: Corregir opciones de √°mbito (Set-DhcpServerv4OptionValue).`,

    Security: `Eres un experto en hardening de Active Directory con especializaci√≥n en protocolos de autenticaci√≥n legacy y configuraciones de seguridad avanzadas.

**‚ö†Ô∏è CONTEXTO DE AN√ÅLISIS:**
Esta categor√≠a consolida m√∫ltiples configuraciones de seguridad cr√≠ticas: NTLM, SMB, LAPS, cifrado Kerberos, y delegaci√≥n. Busca configuraciones legacy que faciliten lateral movement y credential theft.

**üéØ PRIORIDADES DE DETECCI√ìN:**

1. **üî¥ CRITICAL: NTLM Authentication Level inseguro**
   - Si DomainControllers tienen LMCompatibilityLevel < 5
   - Level 0-2: Permite LM y NTLM v1 (EXTREMADAMENTE inseguro)
   - Level 3-4: Permite NTLM v2 pero acepta v1
   - Level 5: Solo NTLMv2 (recomendado)
   - Riesgo: Pass-the-Hash attacks, NTLM relay, credential downgrade
   - MITRE ATT&CK: T1550.002 (Use Alternate Authentication Material: Pass the Hash)
   - CIS Control: 2.3.11.7 - Configure Network Security: LAN Manager Authentication Level to "Send NTLMv2 response only\\refuse LM & NTLM"
   - Impacto: Atacante puede reusar hashes NTLM sin conocer password, movimiento lateral sin detecci√≥n
   - Comando verificar: Get-ItemProperty "HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Lsa" -Name "LmCompatibilityLevel"
   - Comando fix GPO: Computer Config > Policies > Windows Settings > Security Settings > Local Policies > Security Options > "Network security: LAN Manager authentication level" ‚Üí "Send NTLMv2 response only\\refuse LM & NTLM"
   - Timeline: Remediar INMEDIATAMENTE (48 horas) en producci√≥n tras testing

2. **üî¥ HIGH: SMBv1 habilitado en Domain Controllers**
   - Si SMBv1Status indica que SMBv1 est√° enabled
   - Riesgo: Vulnerable a EternalBlue (MS17-010), WannaCry, NotPetya ransomware
   - CVE: CVE-2017-0144 (EternalBlue)
   - CIS Control: 2.3.11.9 - Disable SMBv1
   - Comando verificar: Get-WindowsFeature FS-SMB1
   - Comando deshabilitar: Disable-WindowsOptionalFeature -Online -FeatureName SMB1Protocol -NoRestart
   - Timeline: Deshabilitar en 7 d√≠as tras validar dependencias

3. **üî¥ HIGH: LAPS no implementado**
   - Si LAPS.SchemaExtended = false o LAPS.ComputersWithLAPS = 0
   - Riesgo: Passwords de administrador local id√©nticas en todos los equipos
   - MITRE ATT&CK: T1078.003 (Valid Accounts: Local Accounts)
   - CIS Control: 5.3 - Use Unique Passwords for Local Administrator Accounts
   - Impacto: Compromiso de un equipo = acceso admin a TODOS los equipos
   - Comando verificar schema: Get-ADObject -SearchBase (Get-ADRootDSE).schemaNamingContext -Filter "name -eq 'ms-Mcs-AdmPwd'"
   - Procedimiento implementaci√≥n: Extender schema, configurar GPO, instalar cliente
   - Timeline: Implementar en 30 d√≠as

4. **‚ö†Ô∏è MEDIUM: RC4 Encryption Types permitidos**
   - Si RC4EncryptionTypes.UsersWithRC4 > 0 o ComputersWithRC4 > 0
   - Riesgo: RC4 es cifrado d√©bil, vulnerable a ataques de fuerza bruta
   - MITRE ATT&CK: T1558.003 (Kerberoasting m√°s efectivo con RC4)
   - Comando verificar: Get-ADUser -Filter * -Properties msDS-SupportedEncryptionTypes | Where-Object {$_."msDS-SupportedEncryptionTypes" -band 0x4}
   - Comando fix: Set-ADUser -Identity "username" -Replace @{"msDS-SupportedEncryptionTypes"=24} # AES128+AES256
   - Timeline: Migrar a AES en 60 d√≠as

5. **‚ö†Ô∏è MEDIUM: Unconstrained Delegation habilitado**
   - Si UnconstrainedDelegation.Users > 0 o Computers > 0 (excluyendo DCs)
   - Riesgo: Pass-the-Ticket attacks, impersonation de cualquier usuario
   - MITRE ATT&CK: T1134.005 (Access Token Manipulation: SID-History Injection)
   - Comando verificar: Get-ADUser -Filter {TrustedForDelegation -eq $true} -Properties TrustedForDelegation
   - Comando fix: Set-ADUser -Identity "user" -TrustedForDelegation $false
   - Timeline: Remediar en 14 d√≠as

6. **‚ÑπÔ∏è INFO: Protected Users Group**
   - Reportar tama√±o del grupo, no es problema si est√° implementado
   - Si tiene miembros ‚Üí POSITIVO (buena pr√°ctica)

**üèÜ MEJORES PR√ÅCTICAS SECURITY - BASELINE ENTERPRISE:**
- **NTLM Authentication**: Level 5 (Send NTLMv2 only\\refuse LM & NTLM) en TODOS los DCs y servidores
- **SMB Protocol**: SMBv1 deshabilitado, SMBv2/SMBv3 con firma digital habilitada
- **LAPS**: 100% de workstations y servers (no-DCs) con LAPS implementado, passwords rotados cada 30 d√≠as
- **Kerberos Encryption**: AES256 + AES128, RC4 solo para compatibilidad legacy documentada
- **Delegation**: Unconstrained delegation SOLO en DCs, resto debe usar Constrained o Resource-Based
- **Protected Users**: Todas las cuentas Tier 0 en este grupo (deshabilita RC4, NTLM, delegation)
- **Auditing**: Event IDs 4624, 4625, 4768, 4769 logueados y enviados a SIEM
- **Patching**: DCs parcheados mensualmente, prioridad CR√çTICA para vulnerabilidades RCE

**üìã SOLO GENERA FINDING SI:**
- LMCompatibilityLevel < 5 en DCs ‚Üí CRITICAL
- SMBv1 = enabled ‚Üí HIGH
- LAPS no extendido o sin deployment ‚Üí HIGH
- RC4 en uso en > 10% de cuentas ‚Üí MEDIUM
- Delegaci√≥n sin restricciones en cuentas no-DC ‚Üí MEDIUM

**FORMATO DE REPORTE (EJEMPLO PARA NTLM):**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: NTLM_INSECURE_LEVEL, SMBV1_ENABLED, LAPS_MISSING, RC4_ENCRYPTION_ENABLED.
- **T√≠tulo**: "[N] Domain Controllers con NTLM Authentication Level [X] inseguro - Vulnerable a Pass-the-Hash"
  
- **Descripci√≥n** (4 p√°rrafos):
  * P√°rrafo 1 - HALLAZGO: "[N] Domain Controllers est√°n configurados con LAN Manager Authentication Level [X], permitiendo autenticaci√≥n NTLM v1 o LM. Los DCs afectados son: [lista de nombres]. El baseline de seguridad Microsoft recomienda Level 5 (Send NTLMv2 response only\\refuse LM & NTLM) para prevenir ataques de Pass-the-Hash."
  * P√°rrafo 2 - ATAQUE PTH: "Pass-the-Hash permite a un atacante autenticarse usando el hash NTLM sin conocer el password en texto plano. Una vez obtenido el hash (mediante Mimikatz, DCSync, NTDS.dit dump), el atacante puede: (1) Ejecutar comandos remotos con psexec/wmiexec, (2) Acceder a recursos de red (SMB shares, SQL, Exchange), (3) Movimiento lateral entre servidores, (4) Escalar privilegios a Domain Admin. Herramientas: Mimikatz, Impacket, CrackMapExec."
  * P√°rrafo 3 - IMPACTO: "NTLM v1/LM son protocolos legacy de 1990s sin protecci√≥n contra replay attacks y con cifrado d√©bil. Hashes LM son crackeables en minutos con rainbow tables. En incidentes como NotPetya (2017) y WannaCry (2017), Pass-the-Hash fue vector clave de propagaci√≥n. Permite compromiso masivo de infraestructura en horas."
  * P√°rrafo 4 - COMPLIANCE: "Violaciones: CIS Control 2.3.11.7 (Configure NTLM authentication to reject LM and NTLM v1), NIST 800-53 IA-5(1)(c) (cryptographically-protected passwords), PCI-DSS 8.2.1 (strong cryptography), ISO 27001 A.9.4.3 (password management system). Auditor√≠as de compliance marcar√°n como finding CR√çTICO."
  
- **Recomendaci√≥n** (ROADMAP COMPLETO DE MIGRACI√ìN A LEVEL 5):
  
  * FASE 1 - ASSESSMENT Y COMPATIBILIDAD (Semanas 1-2):
    OBJETIVO: Identificar aplicaciones legacy que requieren NTLM v1
    COMANDO AUDITOR√çA: Habilitar logging temporal en DCs
    GPO: Computer Config > Policies > Windows Settings > Security Settings > Local Policies > Security Options
    SETTING: "Network security: Restrict NTLM: Audit NTLM authentication in this domain" ‚Üí Enable auditing for all accounts
    MONITOREO: Event ID 8004 en DCs ‚Üí indica intentos NTLM v1
    COMANDO AN√ÅLISIS: Get-WinEvent -FilterHashtable @{LogName='Security';ID=8004} | Select TimeCreated,Message | Export-CSV ntlm_usage.csv
    IDENTIFICAR: Aplicaciones/servicios usando NTLM v1 (SQL Server legacy, dispositivos IoT, scanners, CRM old)
    DOCUMENTAR: Lista de aplicaciones con owners y plan de mitigaci√≥n
    
  * FASE 2 - REMEDIACI√ìN DE LEGACY APPS (Semanas 3-6):
    OPCI√ìN A - UPGRADE: Actualizar aplicaci√≥n a versi√≥n que soporta NTLMv2/Kerberos
    OPCI√ìN B - CONFIGURACI√ìN: Cambiar settings de app para usar NTLMv2
    OPCI√ìN C - EXCEPCI√ìN: Si upgrade imposible, documentar riesgo y aprobar excepci√≥n temporal
    EJEMPLO SQL: SQL Server 2000 requiere NTLM v1 ‚Üí migrar a SQL 2016+ (soporta AES Kerberos)
    EJEMPLO SCANNERS: HP/Canon antiguos ‚Üí actualizar firmware o reemplazar
    VALIDACI√ìN: Test de aplicaciones en non-prod con Level 5 habilitado
    
  * FASE 3 - IMPLEMENTACI√ìN GRADUAL (Semanas 7-8):
    PASO 1 - NON-PROD: Aplicar GPO con Level 5 en entornos Dev/QA
    GPO PATH: Computer Config > Policies > Windows Settings > Security Settings > Local Policies > Security Options
    SETTING: "Network security: LAN Manager authentication level" ‚Üí Send NTLMv2 response only. Refuse LM & NTLM
    VALOR REGISTRY: LmCompatibilityLevel = 5 (REG_DWORD en HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa)
    COMANDO POWERSHELL: Set-ItemProperty -Path "HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Lsa" -Name "LmCompatibilityLevel" -Value 5
    TESTING: 48 horas de monitoreo intensivo, validar autenticaci√≥n de usuarios/servicios
    
    PASO 2 - PROD PILOT: OUs piloto (ej: IT department DCs primero)
    COMANDO: New-GPO -Name "NTLM Level 5 - Pilot" | New-GPLink -Target "OU=DomainControllers,DC=domain,DC=com"
    MONITOREO: Event IDs 4625 (failed logon), 8004 (NTLM audit)
    ROLLBACK PLAN: Si > 5% de fallos, pausar 24h y analizar
    
    PASO 3 - PROD COMPLETO: Rollout a todos los DCs
    TIMING: Implementar en ventana de mantenimiento (fin de semana)
    NOTIFICAR: Service desk para manejar tickets de autenticaci√≥n
    VALIDAR: gpresult /r en cada DC debe mostrar GPO aplicada
    
  * FASE 4 - POST-IMPLEMENTACI√ìN (Semana 9):
    VALIDACI√ìN T√âCNICA:
    COMANDO: Get-ADDomainController -Filter * | ForEach-Object {Invoke-Command -ComputerName $_.HostName -ScriptBlock {Get-ItemProperty "HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Lsa" -Name "LmCompatibilityLevel"}}
    EXPECTED: Todos deben devolver LmCompatibilityLevel = 5
    
    VALIDACI√ìN FUNCIONAL:
    TEST: Login de usuarios desde workstations Windows 10/11
    TEST: Acceso a file shares (SMB)
    TEST: Aplicaciones cr√≠ticas (ERP, CRM, Email)
    TEST: Autenticaci√≥n de servicios (SQL, IIS, APIs)
    
    MONITOREO CONTINUO:
    ALERTA: Event ID 4625 con error 0xC000006D (bad username/password) - podr√≠a indicar NTLM v1 rechazado
    DASHBOARD: PowerBI/Splunk con m√©tricas de autenticaci√≥n NTLM vs Kerberos
    OBJETIVO: < 5% de autenticaciones usando NTLM (mayor√≠a debe ser Kerberos)
    
  * FASE 5 - HARDENING ADICIONAL (Mes 3):
    PASO 1: Deshabilitar NTLM completamente donde sea posible
    GPO: "Network security: Restrict NTLM: NTLM authentication in this domain" ‚Üí Deny all
    NOTA: Solo en ambientes 100% Kerberos, requiere testing exhaustivo
    
    PASO 2: Habilitar SMB Signing obligatorio
    GPO: "Microsoft network server: Digitally sign communications (always)" ‚Üí Enabled
    PREVIENE: NTLM relay attacks incluso con NTLMv2
    
    PASO 3: Auditor√≠a trimestral
    SCRIPT: Automated compliance check de LmCompatibilityLevel en todos los DCs
    REPORTE: Dashboard ejecutivo con estado de compliance
    
  * TIMELINE CR√çTICO:
    - Si Level 0-2 (LM/NTLM v1): EMERGENCIA - Remediar en 48 horas
    - Si Level 3-4: URGENTE - Remediar en 14 d√≠as
    - Total duraci√≥n proyecto: 8-12 semanas desde inicio hasta prod completo
    
  * COSTO Y RECURSOS:
    - Esfuerzo: 80-120 horas (Security Engineer + Sys Admin + App Owners)
    - Downtime: M√°ximo 2 horas por DC (aplicaci√≥n GPO + reboot)
    - Riesgo de rollback: < 5% si testing es adecuado
    
- **Evidencia**:
  * affected_objects: [nombres REALES de DCs con Level < 5]
  * affected_count: [n√∫mero de DCs afectados]
  * details: "LMCompatibilityLevel actual: [valores por DC], Baseline recomendado: 5 (NTLMv2 only), Desv√≠o: [an√°lisis], DCs cr√≠ticos afectados: [lista prioritaria]"`,

    Kerberos: `Eres un especialista en protocolos de autenticaci√≥n Kerberos y detecci√≥n de vectores de ataque avanzados en Active Directory.

**‚ö†Ô∏è VALIDACI√ìN CR√çTICA PARA KERBEROS:**
- SIEMPRE revisa KRBTGTPasswordAge - es el indicador m√°s cr√≠tico
- Si KRBTGTPasswordAge > 180 d√≠as ‚Üí CRITICAL finding OBLIGATORIO
- Si KRBTGTPasswordAge > 365 d√≠as ‚Üí CRITICAL con m√°xima prioridad
- Microsoft recomienda renovar KRBTGT cada 180 d√≠as m√°ximo

**BUSCA ESPEC√çFICAMENTE:**

1. **üî¥ KRBTGT Password Age Excesivo** (KRBTGTPasswordAge > 180 d√≠as)
   - **CRITICAL SI > 365 d√≠as, HIGH SI 180-365 d√≠as**
   - Riesgo: Permite ataques Golden Ticket indefinidamente, compromiso total del dominio
   - MITRE ATT&CK: T1558.001 (Golden Ticket)
   - CIS Control: 5.2.3 - Rotate the KRBTGT account password at least every 180 days
   - Impacto: 
     * Atacante con hash KRBTGT puede generar tickets Kerberos v√°lidos para CUALQUIER usuario
     * Persistencia post-compromiso INDEFINIDA hasta rotaci√≥n
     * Bypass TOTAL de autenticaci√≥n y logs
     * Movimiento lateral sin detecci√≥n
     * Vulnera NIST 800-53 IA-5, ISO 27001 A.9.2.4
   - Comando verificar: Get-ADUser krbtgt -Properties PasswordLastSet | Select Name, PasswordLastSet
   - Comando calcular edad: [math]::Round(((Get-Date) - (Get-ADUser krbtgt -Properties PasswordLastSet).PasswordLastSet).Days)
   - Timeline: 
     * Si > 1 a√±o: INMEDIATO (dentro de 48 horas)
     * Si > 180 d√≠as: Urgente (dentro de 7 d√≠as)
   
2. **Procedimiento de Rotaci√≥n Segura de KRBTGT:**
   - ‚ö†Ô∏è NUNCA simplemente cambiar password - causar√° outage total
   - Proceso de rotaci√≥n dual (Microsoft recomendado):
     POWERSHELL COMMANDS:
     # Paso 1: Primera rotaci√≥n (esperar 10 horas de replicaci√≥n)
     Get-ADUser krbtgt -Properties msds-KeyVersionNumber
     Set-ADAccountPassword -Identity krbtgt -Reset -NewPassword (ConvertTo-SecureString -AsPlainText "NewComplexPassword1!" -Force)
     
     # Paso 2: Verificar replicaci√≥n (esperar 10+ horas)
     Get-ADReplicationPartnerMetadata -Target "DC01" -Scope Domain | Where-Object {LastReplicationSuccess -gt (Get-Date).AddHours(-1)}
     
     # Paso 3: Segunda rotaci√≥n (invalidar tickets antiguos)
     Set-ADAccountPassword -Identity krbtgt -Reset -NewPassword (ConvertTo-SecureString -AsPlainText "NewComplexPassword2!" -Force)
     
   - Usar scripts oficiales: New-KrbtgtKeys.ps1 de Microsoft (recomendado)
   - Ventana de mantenimiento: Programar en horario de baja actividad
   - Post-rotaci√≥n: Monitorear Event ID 4769 (TGS requests) para tickets inv√°lidos
   
3. **KRBTGTPasswordLastSet** (fecha de √∫ltima renovaci√≥n)
   - Si es fecha muy antigua (> 2 a√±os): CRITICAL
   - Indica dominio comprometido potencialmente o mala pr√°ctica de seguridad
   - Comando: (Get-ADUser krbtgt -Properties PasswordLastSet).PasswordLastSet
   
4. **Tickets de Kerberos con vida excesiva** (si disponible en datos)
   - Default: 10 horas (TGT), 10 horas (Service Ticket)
   - M√°ximo recomendado: TGT Lifetime < 10 horas, Max Renew < 7 d√≠as
   - Verificar en GPO: Computer Configuration > Policies > Windows Settings > Security Settings > Account Policies > Kerberos Policy

**SEVERIDADES:**
- CRITICAL: KRBTGTPasswordAge > 365 d√≠as (1 a√±o)
- HIGH: KRBTGTPasswordAge entre 180-365 d√≠as
- MEDIUM: KRBTGTPasswordAge entre 90-180 d√≠as

**üèÜ MEJORES PR√ÅCTICAS KERBEROS - BASELINE ENTERPRISE:**
- **KRBTGT Password Rotation**: Cada 180 d√≠as m√°ximo (Microsoft recommendation)
- **Auditor√≠a**: Trimestral, revisar KRBTGTPasswordAge
- **Procedimiento documentado**: Runbook de rotaci√≥n probado en non-prod
- **Ticket Lifetime**: TGT 10 horas (default OK), Service Ticket 10 horas
- **Max Renewal**: 7 d√≠as (default OK), validar en GPO Kerberos Policy
- **Encryption Types**: AES256 + AES128 habilitados, RC4 deshabilitado donde sea posible
- **Clock Skew**: M√°ximo 5 minutos (default), monitorear sincronizaci√≥n NTP
- **Monitoring**: Alertas en Event ID 4768 (TGT request), 4769 (Service ticket), 4770 (TGT renewal)
- **Post-compromise**: Si hay sospecha de compromiso, rotaci√≥n INMEDIATA dual en < 24 horas

**PARA EL HALLAZGO DE KRBTGT, PROPORCIONA:**
- **type_id**: Identificador √öNICO y CONSTANTE para este tipo de hallazgo (NO lo traduzcas).
  Debe ser en MAY√öSCULAS y guiones bajos.
  Ejemplos: KRBTGT_PASSWORD_AGE_EXCESSIVE, KERBEROS_RC4_ENABLED.
- **T√≠tulo**: "Cuenta KRBTGT sin renovar por [D√çAS] d√≠as ([A√ëOS] a√±os) - Riesgo de Golden Ticket" 
  Ejemplo: "Cuenta KRBTGT sin renovar por 3537 d√≠as (9.7 a√±os) - Riesgo de Golden Ticket"
  
- **Descripci√≥n** (4 p√°rrafos obligatorios):
  * P√°rrafo 1 - ESTADO ACTUAL: "La cuenta KRBTGT del dominio tiene [D√çAS] d√≠as ([A√ëOS] a√±os) sin rotaci√≥n de password desde [FECHA]. Microsoft recomienda rotaci√≥n cada 180 d√≠as m√°ximo. El desv√≠o actual es de [D√çAS-180] d√≠as sobre la recomendaci√≥n."
  * P√°rrafo 2 - ATAQUE GOLDEN TICKET: "Un atacante que obtenga el hash NTLM de la cuenta KRBTGT puede generar Ticket Granting Tickets (TGT) de Kerberos v√°lidos para CUALQUIER usuario del dominio, incluyendo Domain Admins, sin necesidad de conocer sus passwords. Estos tickets falsificados (Golden Tickets) son indistinguibles de tickets leg√≠timos y permiten acceso total al dominio sin ser detectados en logs de autenticaci√≥n. El atacante puede establecer validez del ticket hasta 10 a√±os, garantizando persistencia indefinida."
  * P√°rrafo 3 - IMPACTO CR√çTICO: "Este es considerado uno de los hallazgos M√ÅS CR√çTICOS en seguridad de Active Directory. Permite: (1) Acceso administrativo total sin credenciales, (2) Persistencia post-compromiso que sobrevive a cambios de passwords de usuarios, (3) Bypass completo de MFA y Conditional Access, (4) Movimiento lateral sin detecci√≥n, (5) Exfiltraci√≥n de datos sin trazabilidad. En caso de compromiso, el dominio completo debe considerarse comprometido hasta completar rotaci√≥n dual de KRBTGT."
  * P√°rrafo 4 - COMPLIANCE: "Regulaciones violadas: NIST 800-53 IA-5(1)(e) require rotaci√≥n peri√≥dica de credenciales privilegiadas, ISO 27001 A.9.2.4 gesti√≥n de informaci√≥n secreta de autenticaci√≥n, PCI-DSS 8.2.4 cambio de passwords cada 90 d√≠as para cuentas privilegiadas, CIS Control 5.2.3 rotaci√≥n de KRBTGT cada 180 d√≠as."
  
- **Recomendaci√≥n** (PROCEDIMIENTO COMPLETO DE ROTACI√ìN DUAL):
  
  * ‚ö†Ô∏è ADVERTENCIAS CR√çTICAS:
    - NUNCA usar Set-ADAccountPassword directamente sin procedimiento dual
    - Rotaci√≥n √∫nica puede causar outage total (tickets v√°lidos quedan inv√°lidos)
    - Requiere ventana de mantenimiento coordinada con todos los equipos
    - Notificar a: IT Operations, Application Owners, Security Team, Management
    - Rollback no es posible - √∫nica soluci√≥n es esperar expiraci√≥n de tickets (10 horas)
    
  * FASE 1 - PRE-VALIDACI√ìN (D√≠a 0):
    COMANDO: Get-ADUser krbtgt -Properties PasswordLastSet,msDS-KeyVersionNumber | Select Name,PasswordLastSet,msDS-KeyVersionNumber
    COMANDO: Get-ADDomainController -Filter * | Test-ComputerSecureChannel -Verbose
    VALIDAR: Todos los DCs online, replicaci√≥n sin errores (Get-ADReplicationFailure)
    VALIDAR: Sincronizaci√≥n NTP correcta en todos los DCs (w32tm /query /status)
    BACKUP: Realizar System State backup de todos los DCs
    COMUNICAR: Email a stakeholders con ventana de mantenimiento (fuera de horario productivo)
    
  * FASE 2 - PRIMERA ROTACI√ìN (D√≠a 1 - Hora no productiva, ej: 2 AM):
    PASO 1: Descargar script oficial de Microsoft New-CtmADKrbtgtKeys.ps1 desde TechNet Gallery
    COMANDO: Import-Module ActiveDirectory
    COMANDO: New-CtmADKrbtgtKeys -WhatIf  # Dry-run para validar
    COMANDO: New-CtmADKrbtgtKeys -Confirm:$false  # Ejecutar primera rotaci√≥n
    RESULTADO: KeyVersionNumber incrementa en 1, PasswordLastSet actualizado
    VALIDAR: Get-ADReplicationPartnerMetadata -Target "DC01" -Scope Domain | Select Partner,LastReplicationSuccess
    MONITOREAR: Event Viewer ‚Üí Security ‚Üí Event ID 4724 (password reset attempt)
    
  * FASE 3 - PERIODO DE ESPERA (10+ horas obligatorias):
    RAZ√ìN: Tickets Kerberos existentes tienen validez de 10 horas default
    RAZ√ìN: Replicaci√≥n AD entre todos los DCs (especialmente sitios remotos)
    ESPERAR: M√≠nimo 10 horas, recomendado 12-24 horas
    MONITOREAR: Logs de aplicaciones por errores de autenticaci√≥n
    COMANDO MONITOREO: Get-WinEvent -FilterHashtable @{LogName='Security';ID=4768,4769} -MaxEvents 50 | Where {$_.Message -like "*failure*"}
    VALIDAR: Replicaci√≥n completada: repadmin /showrepl /csv > repl_status.csv
    
  * FASE 4 - SEGUNDA ROTACI√ìN (D√≠a 2 - Misma hora que primera):
    COMANDO: New-CtmADKrbtgtKeys -Confirm:$false  # Segunda rotaci√≥n
    RESULTADO: KeyVersionNumber incrementa nuevamente, password cambia segunda vez
    OBJETIVO: Invalidar tickets generados con password anterior (pre-rotaci√≥n)
    VALIDAR: KeyVersionNumber deber√≠a ser = versi√≥n original + 2
    COMANDO VERIFICACI√ìN: Get-ADUser krbtgt -Properties msDS-KeyVersionNumber | Select msDS-KeyVersionNumber
    
  * FASE 5 - POST-VALIDACI√ìN (D√≠a 3):
    TEST 1 - Autenticaci√≥n: klist purge en estaci√≥n de trabajo, login exitoso
    TEST 2 - Servicios: Validar servicios cr√≠ticos (SQL, Exchange, SharePoint, aplicaciones custom)
    TEST 3 - Replicaci√≥n: repadmin /replsum - debe mostrar 0 errores
    TEST 4 - LDAP: ldp.exe conectar a DCs, validar bind exitoso
    MONITOREO: Event ID 4768 sin c√≥digos de error (0x6 = old password, 0x18 = policy)
    COMANDO: Get-WinEvent -FilterHashtable @{LogName='Security';ID=4768} -MaxEvents 100 | Group ResultCode
    DOCUMENTAR: Actualizar runbook con lecciones aprendidas
    AGENDAR: Pr√≥xima rotaci√≥n en 180 d√≠as (crear ticket en ServiceNow/Jira)
    
  * HERRAMIENTAS RECOMENDADAS:
    - Script oficial: New-CtmADKrbtgtKeys.ps1 (Microsoft)
    - Alternativa: Reset-KrbtgtKeyInteractive.ps1 (Trimarc Security)
    - Validaci√≥n: Get-KrbtgtPassword.ps1 para verificar estado
    - Documentaci√≥n: https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/manage/ad-forest-recovery-resetting-the-krbtgt-password
    
  * TIMELINE:
    - Si > 3 a√±os: CR√çTICO - Ejecutar en pr√≥xima ventana de mantenimiento (m√°ximo 7 d√≠as)
    - Si 1-3 a√±os: ALTO - Planificar en 30 d√≠as
    - Si 180-365 d√≠as: MEDIO - Planificar en 90 d√≠as
    
- **Evidencia**:
  * affected_objects: ["krbtgt"]
  * affected_count: 1
  * details: "KRBTGTPasswordAge: [D√çAS] d√≠as ([A√ëOS] a√±os), KRBTGTPasswordLastSet: [FECHA_EXACTA], √öltima rotaci√≥n: [FECHA_HUMANA], Desv√≠o sobre baseline: [D√çAS-180] d√≠as, Compliance: CR√çTICO - Excede 180 d√≠as recomendados por Microsoft, CIS, NIST"`,

    PasswordPolicies: `Eres un especialista en pol√≠ticas de contrase√±as de Active Directory y cumplimiento de seguridad.

**‚ö†Ô∏è CONTEXTO DE AN√ÅLISIS:**
Las pol√≠ticas de contrase√±as son la primera l√≠nea de defensa contra ataques de fuerza bruta, credential stuffing y password spraying.
Los datos incluyen:
- DefaultDomainPolicy: Pol√≠tica de contrase√±as a nivel de dominio
- FineGrainedPolicies: Password Settings Objects (PSOs) para grupos espec√≠ficos

**‚ö†Ô∏è REGLA ANTI-ALUCINACI√ìN:**
Solo reporta configuraciones que aparezcan EXPL√çCITAMENTE en los datos proporcionados.
La estructura de datos es:
- DefaultDomainPolicy: {MinPasswordLength, PasswordHistoryCount, MaxPasswordAge, MinPasswordAge, ComplexityEnabled, ReversibleEncryptionEnabled, LockoutThreshold, LockoutDuration, LockoutObservationWindow}
- FineGrainedPolicies: Array de objetos PSO con las mismas propiedades m√°s {Name, Precedence, AppliesTo}

**üéØ BUSCA ESPEC√çFICAMENTE:**

1. **üî¥ HIGH: Longitud M√≠nima de Contrase√±a D√©bil**
   - Si MinPasswordLength < 12 caracteres
   - Riesgo: Passwords cortos son vulnerables a ataques de fuerza bruta y rainbow tables
   - CIS Control: 5.2.2 - Set minimum password length to 14 or more characters
   - NIST 800-63B: Recomienda m√≠nimo 8, pero mejores pr√°cticas actuales indican 12-14
   - Comando verificar: Get-ADDefaultDomainPasswordPolicy | Select MinPasswordLength
   - Comando fix: Set-ADDefaultDomainPasswordPolicy -MinPasswordLength 14
   - Impacto: Los usuarios deber√°n cambiar contrase√±as en el pr√≥ximo cambio programado
   - Timeline: Configurar en 30 d√≠as, aplicar en pr√≥xima ventana de cambio

2. **üî¥ HIGH: Historial de Contrase√±as Insuficiente**
   - Si PasswordHistoryCount < 12
   - Riesgo: Usuarios pueden reciclar contrase√±as antiguas comprometidas
   - CIS Control: 5.2.3 - Set password history to 24 or more passwords remembered
   - Comando verificar: Get-ADDefaultDomainPasswordPolicy | Select PasswordHistoryCount
   - Comando fix: Set-ADDefaultDomainPasswordPolicy -PasswordHistoryCount 24
   - Timeline: Configurar en 30 d√≠as

3. **üî¥ CRITICAL: Complejidad de Contrase√±as Deshabilitada**
   - Si ComplexityEnabled = false
   - Riesgo: Permite contrase√±as simples como "Password123" o "Company2024"
   - CIS Control: 5.2.4 - Ensure password complexity requirements are enabled
   - Comando verificar: Get-ADDefaultDomainPasswordPolicy | Select ComplexityEnabled
   - Comando fix: Set-ADDefaultDomainPasswordPolicy -ComplexityEnabled $true
   - Timeline: Remediar INMEDIATAMENTE (24 horas)

4. **üî¥ CRITICAL: Cifrado Reversible Habilitado**
   - Si ReversibleEncryptionEnabled = true
   - Riesgo: Las contrase√±as se almacenan con cifrado reversible (equivalente a plaintext)
   - CIS Control: 5.2.5 - Ensure 'Store passwords using reversible encryption' is disabled
   - Comando verificar: Get-ADDefaultDomainPasswordPolicy | Select ReversibleEncryptionEnabled
   - Comando fix: Set-ADDefaultDomainPasswordPolicy -ReversibleEncryptionEnabled $false
   - Timeline: Remediar INMEDIATAMENTE (< 1 hora)

5. **‚ö†Ô∏è MEDIUM: Sin Pol√≠tica de Bloqueo de Cuenta**
   - Si LockoutThreshold = 0 (nunca bloquea)
   - Riesgo: Permite ataques de password spraying sin detecci√≥n ni bloqueo
   - CIS Control: 5.2.6 - Set account lockout threshold to 5 or fewer invalid logon attempts
   - Comando verificar: Get-ADDefaultDomainPasswordPolicy | Select LockoutThreshold
   - Comando fix: Set-ADDefaultDomainPasswordPolicy -LockoutThreshold 5 -LockoutDuration "00:30:00" -LockoutObservationWindow "00:30:00"
   - Balance: Threshold muy bajo (< 3) puede causar DoS accidental
   - Timeline: Configurar en 14 d√≠as

6. **‚ö†Ô∏è MEDIUM: MaxPasswordAge Muy Largo**
   - Si MaxPasswordAge > 90 d√≠as (o 0 = nunca expira)
   - Riesgo: Contrase√±as comprometidas permanecen v√°lidas por mucho tiempo
   - CIS Control: 5.2.7 - Set maximum password age to 60 days or less
   - Comando verificar: Get-ADDefaultDomainPasswordPolicy | Select MaxPasswordAge
   - Comando fix: Set-ADDefaultDomainPasswordPolicy -MaxPasswordAge "60.00:00:00"
   - Timeline: Configurar en 60 d√≠as

7. **‚ÑπÔ∏è INFO: Fine-Grained Password Policies (PSOs)**
   - Reportar si existen PSOs configurados y a qu√© grupos se aplican
   - PSOs permiten pol√≠ticas m√°s estrictas para cuentas privilegiadas
   - Best Practice: Domain Admins y Enterprise Admins deber√≠an tener PSO con MinPasswordLength >= 20
   - Comando verificar: Get-ADFineGrainedPasswordPolicy -Filter *

**FORMATO DE REPORTE:**
- **type_id**: PASSWORD_POLICY_WEAK_LENGTH, PASSWORD_POLICY_NO_COMPLEXITY, PASSWORD_POLICY_REVERSIBLE_ENCRYPTION, PASSWORD_POLICY_NO_LOCKOUT, PASSWORD_POLICY_LONG_MAX_AGE, PASSWORD_POLICY_WEAK_HISTORY
- **T√≠tulo**: "Longitud m√≠nima de contrase√±a d√©bil (N caracteres)" o "Cifrado reversible habilitado en pol√≠tica de dominio"
- **Descripci√≥n**: Riesgo espec√≠fico, vector de ataque, impacto regulatorio
- **Recomendaci√≥n**: Comandos PowerShell con valores espec√≠ficos recomendados
- **Evidencia**: Configuraci√≥n actual vs recomendada, affected_objects: ["Default Domain Policy"] o nombres de PSOs

**‚ö†Ô∏è VALIDACI√ìN:**
- Solo genera findings si los datos MUESTRAN configuraciones d√©biles
- Si todos los valores cumplen con best practices, devuelve {"findings": []}
- NO inventes valores - usa los datos exactos proporcionados`,

    ADCSInventory: `Analiza la infraestructura de Certificados (ADCS) en busca de vulnerabilidades cr√≠ticas.
**BUSCA:**
1. **ESC1 (Vulnerable Templates)**: Plantillas que permiten al solicitante especificar el Subject Name (EnrolleeSuppliesSubject) Y permiten autenticaci√≥n de cliente. Esto permite a cualquiera ser Domain Admin.
2. **CAs en Controladores de Dominio**: Mala pr√°ctica de seguridad.
3. **Permisos de CA**: Si usuarios autenticados tienen permisos excesivos.`,

    ProtocolSecurity: `Analiza la seguridad de protocolos de red.
**BUSCA:**
1. **LDAP Signing No Forzado**: Si 'LDAPServerIntegrity' no es 2, permite ataques de NTLM Relay a LDAP.
2. **LDAP Channel Binding No Forzado**: Necesario para prevenir ataques de relay modernos.`,

    Sites: `Eres un arquitecto de Active Directory especializado en topolog√≠a de replicaci√≥n y dise√±o de sitios.

**‚ö†Ô∏è CONTEXTO DE AN√ÅLISIS:**
La topolog√≠a de sitios define c√≥mo se replica el tr√°fico de AD y c√≥mo los clientes encuentran los DCs m√°s cercanos. Una mala configuraci√≥n causa lentitud en logons, fallos de replicaci√≥n y tr√°fico WAN innecesario.

**üìä ESTRUCTURA DE DATOS:**
Los datos pueden venir en formato SiteTopology con dos arrays:
- 'Sites': Array de sitios con propiedades {Name, Description, Location}
- 'Subnets': Array de subredes con propiedades {Name, Site (DN completo como CN=SITENAME,CN=Sites,...), Description}

Para detectar problemas, debes correlacionar estos arrays:
- Extrae el nombre del site de Subnets[].Site usando regex: /CN=([^,]+)/
- Compara con Sites[].Name para detectar inconsistencias

**üéØ BUSCA ESPEC√çFICAMENTE:**

**=== SECCI√ìN 1: PROBLEMAS DETECTABLES (Errores de Configuraci√≥n) ===**

1. **üî¥ HIGH: Subredes no asociadas a Sitios**
   - En el array 'Subnets', busca entradas donde la propiedad 'Site' sea null, vac√≠a, o no exista.
   - Riesgo: Clientes en estas subredes pueden autenticarse contra DCs remotos (lento), GPOs pueden no aplicarse correctamente.
   - Comando verificar: Get-ADReplicationSubnet -Filter * -Properties Site | Where-Object {$_.Site -eq $null}
   - Comando fix: New-ADReplicationSubnet -Name "x.x.x.x/yy" -Site "NombreSitio"
   - Timeline: Remediar en 7 d√≠as
   - affected_objects: Lista de subredes sin site

2. **‚ö†Ô∏è MEDIUM: Sitios sin Subredes Asignadas**
   - Compara Sites[].Name con los sites referenciados en Subnets[].Site
   - Si un sitio NO aparece en ninguna subnet, ese sitio no tiene subredes
   - Riesgo: Los clientes f√≠sicos en esa ubicaci√≥n no se asociar√°n al sitio, causando tr√°fico WAN innecesario.
   - Comando fix: New-ADReplicationSubnet -Name "x.x.x.x/yy" -Site "SiteName"
   - Timeline: Revisar y asignar subredes en 14 d√≠as
   - affected_objects: Lista de sites sin subredes

3. **‚ö†Ô∏è MEDIUM: Exceso de Subredes por Site**
   - Si un site tiene m√°s de 100 subredes, puede indicar fragmentaci√≥n excesiva
   - Riesgo: Complejidad administrativa, potencial impacto en rendimiento de replicaci√≥n
   - Recomendaci√≥n: Consolidar subredes contiguas usando supernetting

4. **‚ÑπÔ∏è LOW: Sitios sin Descripci√≥n o Ubicaci√≥n**
   - Sites donde Description y Location son null
   - Riesgo: Documentaci√≥n deficiente dificulta administraci√≥n
   - Recomendaci√≥n: Documentar prop√≥sito y ubicaci√≥n f√≠sica de cada site

**=== SECCI√ìN 2: AN√ÅLISIS DE HIGIENE (Best Practices y Optimizaci√≥n) ===**

**IMPORTANTE:** Aunque NO haya errores evidentes, DEBES analizar si la configuraci√≥n actual sigue las mejores pr√°cticas:

5. **üìã HYGIENE: Convenci√≥n de Nombres de Sitios**
   - type_id: SITE_NAMING_CONVENTION
   - Eval√∫a si los nombres de sitios siguen un est√°ndar consistente (ej: PAIS-CIUDAD, CIUDAD-EDIFICIO)
   - Mal ejemplo: sitios con nombres como "Site1", "Nuevo", "Test", "Default-First-Site-Name" (excepto si es el √∫nico)
   - Buen ejemplo: "PE-LIMA-SURCO", "US-NYC-HQ", "MX-CDMX-CORP"
   - Si no hay consistencia, genera finding LOW con recomendaci√≥n de estandarizar

6. **üìã HYGIENE: Ratio Subredes/Sites**
   - type_id: SUBNET_SITE_RATIO
   - Calcula: Total Subnets / Total Sites
   - Si ratio > 50: Puede indicar sites con demasiadas subredes (posible consolidaci√≥n)
   - Si ratio < 2 y hay m√∫ltiples sites: Puede indicar dise√±o incompleto
   - Genera finding LOW con estad√≠sticas y recomendaci√≥n de revisar

7. **üìã HYGIENE: Subredes Sin Descripci√≥n**
   - type_id: SUBNET_NO_DESCRIPTION
   - Cuenta subredes donde Description es null o vac√≠a
   - Si > 30% de subredes sin descripci√≥n: finding LOW
   - Impacto: Dificulta troubleshooting y documentaci√≥n de red
   - Recomendaci√≥n: Documentar prop√≥sito de cada subnet (ej: "VLAN Usuarios Piso 3", "Red DMZ Servidores Web")

8. **üìã HYGIENE: Revisi√≥n de Subredes Peque√±as**
   - type_id: SUBNET_TOO_SMALL
   - Identifica subredes /30, /31, /32 (point-to-point o host √∫nico)
   - Si hay muchas (>20), puede indicar fragmentaci√≥n excesiva
   - Recomendaci√≥n: Evaluar si estas subredes son necesarias en AD Sites

9. **üìã HYGIENE: Subredes Superpuestas (Overlap Check)**
   - type_id: SUBNET_OVERLAP_RISK
   - Busca subredes que puedan solaparse (ej: 10.0.0.0/8 y 10.1.0.0/16)
   - Esto causa comportamiento impredecible en la selecci√≥n de site
   - Si detectas posible overlap, genera finding MEDIUM

10. **üìã HYGIENE: Distribuci√≥n Geogr√°fica**
    - type_id: SITE_DISTRIBUTION_ANALYSIS
    - Bas√°ndote en nombres/descripciones, eval√∫a si la topolog√≠a refleja la distribuci√≥n geogr√°fica real
    - Si todos los sites tienen nombres gen√©ricos sin contexto geogr√°fico, recomienda mejorar
    - Genera finding LOW con sugerencia de usar formato: REGION-CIUDAD-FUNCION

**=== REGLAS DE GENERACI√ìN DE FINDINGS ===**

- **Para errores (Secci√≥n 1)**: Solo reporta si hay EVIDENCIA CONCRETA del problema
- **Para higiene (Secci√≥n 2)**: SIEMPRE genera al menos 1-2 findings de higiene, evaluando el estado actual
- Si la configuraci√≥n est√° PERFECTA, genera un finding tipo INFO: "SITE_TOPOLOGY_HEALTHY" indicando buenas pr√°cticas observadas
- Incluye estad√≠sticas: "An√°lisis de N sitios y M subredes"

**üõ°Ô∏è VALIDACI√ìN ANTI-ALUCINACI√ìN PARA ESTE AN√ÅLISIS:**

Antes de generar cada finding de higiene, VERIFICA en los datos:
1. **Contar Sites**: len(Sites[]) - usa este n√∫mero EXACTO
2. **Contar Subnets**: len(Subnets[]) - usa este n√∫mero EXACTO
3. **Campo Description**: ¬øExiste en los objetos? Si no existe, NO digas "sin descripci√≥n"
4. **Campo Location**: ¬øExiste en los objetos? Si no existe, NO lo menciones
5. **Nombres de Sites**: Lista los nombres REALES que aparecen en Sites[].Name
6. **M√°scaras de red**: Extrae de Subnets[].Name (ej: /24, /27, /30)

EJEMPLO DE AN√ÅLISIS CORRECTO:
  Datos: Sites=[{Name:"SURCO"}, {Name:"NORTE"}], Subnets=[{Name:"10.0.0.0/24", Site:"CN=SURCO,..."}]
  ‚Üí Sites encontrados: 2 (SURCO, NORTE)
  ‚Üí Subnets encontrados: 1
  ‚Üí Ratio: 0.5 subnets/site
  ‚Üí Finding v√°lido: "Ratio bajo de subredes por site (0.5)"

EJEMPLO DE AN√ÅLISIS INCORRECTO (NO HACER):
  ‚Üí "Aproximadamente 10 sites sin descripci√≥n" (no verificaste el campo Description)
  ‚Üí "Posible fragmentaci√≥n" (sin contar subredes peque√±as reales)

**FORMATO DE REPORTE:**
- **type_id**: Identificador √öNICO (ej: SUBNET_NO_SITE, SITE_NO_SUBNET, SITE_FRAGMENTED, SITE_NAMING_CONVENTION).
- **T√≠tulo**: Descriptivo del hallazgo o recomendaci√≥n de higiene
- **Descripci√≥n**: Impacto y contexto. Para higiene, explica por qu√© la pr√°ctica actual podr√≠a mejorarse.
- **Recomendaci√≥n**: Comandos PowerShell espec√≠ficos o pasos de mejora.
- **Evidencia**: affected_objects con lista de elementos afectados (m√°ximo 15).`
  };

  // Map specialized categories to broader prompts
  // NOTA: SiteTopology ahora usa el prompt de Sites via alias en extractCategoryData
  const promptMap = {
    'DNSConfiguration': 'Infrastructure',
    'DHCPConfiguration': 'Infrastructure',
    'OUStructure': 'Infrastructure',
    'TombstoneLifetime': 'Infrastructure',
    'DNSScavenging': 'Infrastructure',
    'TimeSyncConfig': 'Infrastructure',

    'KerberosConfig': 'SecurityHardening',
    'LAPS': 'SecurityHardening',
    'SMBv1Status': 'SecurityHardening',
    'NTLMSettings': 'SecurityHardening',
    'RC4EncryptionTypes': 'SecurityHardening',
    'BackupStatus': 'SecurityHardening',
    'ProtectedUsers': 'SecurityHardening',

    'DCSyncPermissions': 'IdentityRisks',
    'UnconstrainedDelegation': 'IdentityRisks',
    'AdminSDHolder': 'IdentityRisks',
    'AdminCountObjects': 'IdentityRisks',

    'ADCSInventory': 'ADCSInventory',
    'ProtocolSecurity': 'ProtocolSecurity',

    'GPOPermissions': 'GPOs',
    'DCPolicy': 'GPOs'
  };

  const promptKey = promptMap[cat] || cat;
  const instruction = categoryInstructions[promptKey] || categoryInstructions['DEFAULT'] || `Analiza los siguientes datos de ${cat} para vulnerabilidades de seguridad.`;

  return `${instruction}

<assessment_data>
${str(d, 4000)}
</assessment_data>

**INSTRUCCIONES CR√çTICAS PARA TU RESPUESTA:**

**üö® REGLA FUNDAMENTAL - CERO FALSOS POSITIVOS:**

**TIPO 1: FINDINGS DE ERROR/VULNERABILIDAD (severity: critical, high, medium)**
- **NO** generes un finding de error SI NO HAY EVIDENCIA CONCRETA del problema
- **NO** reportes algo como cr√≠tico si los datos dicen "no se observa" o "0 elementos"
- **NO** inventes problemas bas√°ndote en ausencia de datos
- Solo genera findings de ERROR cuando los datos DEMUESTREN un problema real y verificable

**TIPO 2: FINDINGS DE HIGIENE (severity: low o info, type_id con prefijo HYGIENE_ o sufijo _HEALTHY)**
- PUEDES generar findings de higiene SOLO si el prompt lo solicita expl√≠citamente (Secci√≥n 2: Higiene)
- Los findings de higiene deben basarse en AN√ÅLISIS OBJETIVO de los datos existentes
- Ejemplo v√°lido: "12 sitios analizados, 487 subredes - ratio de 40.6 subredes/site"
- Ejemplo v√°lido: "100% de subredes sin descripci√≥n documentada"
- **NO** inventes datos que no existen (no puedes decir "5 sitios sin descripci√≥n" si no hay campo Description en los datos)
- **NO** asumas valores por defecto - si un campo no existe, di "campo no disponible en los datos"

**REGLA ANTI-ALUCINACI√ìN PARA HIGIENE:**
‚úÖ CORRECTO: Contar elementos reales ‚Üí "De 487 subredes, 487 tienen Description=null"
‚úÖ CORRECTO: Calcular ratios con datos reales ‚Üí "Ratio: 487 subnets / 12 sites = 40.6"
‚úÖ CORRECTO: Evaluar patrones observables ‚Üí "Nombres de sites: SURCO, NORTE, LIMA (sin prefijo pa√≠s)"
‚ùå INCORRECTO: Inventar conteos ‚Üí "Aproximadamente 50% de subredes tienen problemas"
‚ùå INCORRECTO: Asumir datos ausentes ‚Üí "No hay SiteLinks configurados" (si el campo no existe en los datos)

**VALIDACI√ìN DE EVIDENCIA OBLIGATORIA:**
Antes de generar cada finding, verifica:
‚úÖ ¬øHay objetos afectados reales en los datos? (count > 0)
‚úÖ ¬øLos nombres/valores de affected_objects son espec√≠ficos y verificables?
‚úÖ ¬øLa evidencia muestra claramente el problema?
‚úÖ ¬øLos comandos PowerShell son relevantes al problema espec√≠fico identificado?
‚úÖ Para HIGIENE: ¬øEl an√°lisis usa SOLO datos presentes en <assessment_data>?

**EJEMPLO DE L√ìGICA CORRECTA:**
‚ùå MAL: "No se observan cpasswords" ‚Üí Generar finding CRITICAL
‚úÖ BIEN: "No se observan cpasswords" ‚Üí NO generar finding (no hay problema)

‚ùå MAL (Higiene): "Las subredes no tienen descripci√≥n" (si no hay campo Description)
‚úÖ BIEN (Higiene): "De 487 subredes, el campo Description es null en todas" (verificable)

‚ùå MAL: Incluir comando \`Get-WMIObject\` en finding de GPO
‚úÖ BIEN: Solo comandos relacionados directamente con GPO (\`Get-GPO\`, \`Get-GPOReport\`)

**ESTRUCTURA PARA CADA FINDING:**
1. **severity**: "critical" o "high" (SOLO si impacto es real y demostrable)
   
2. **title**: En ESPA√ëOL, formato "X [objetos] [problema espec√≠fico]"
   Ejemplo: "15 usuarios con contrase√±as que nunca expiran"
   NO usar: "Password issues detected"

3. **description**: En ESPA√ëOL, 2-3 p√°rrafos con:
   - Qu√© problema espec√≠fico se encontr√≥ (con n√∫meros reales)
   - Por qu√© es peligroso seg√∫n CIS/MITRE
   - Impacto de negocio concreto (p√©rdida de datos, compromiso, downtime)
   - Qu√© vectores de ataque habilita
   - Timeline sugerido de remediaci√≥n (Inmediato/30 d√≠as/90 d√≠as)

4. **recommendation**: En ESPA√ëOL, pasos ACCIONABLES:
   - Comandos PowerShell ESPEC√çFICOS con par√°metros reales de los datos
   - Cada comando debe ser copy-paste ejecutable
   - Configuraci√≥n de GPO paso a paso (GPMC path completo)
   - Referencia a CIS Benchmark espec√≠fico (ej: "CIS Control 5.2.1")
   - Link a documentaci√≥n Microsoft si aplica
   - Comando de verificaci√≥n para confirmar que se aplic√≥
   - Nivel de dificultad: Bajo/Medio/Alto

5. **evidence**: Objeto JSON con:
   - **affected_objects**: Array con nombres REALES de los datos (m√°x 10)
   - **count**: N√∫mero TOTAL verificable en los datos
   - **details**: String con contexto adicional espec√≠fico

**CALIDAD DE COMANDOS POWERSHELL:**
‚úÖ Usar cmdlets oficiales: Get-ADUser, Set-ADUser, Get-GPO, etc.
‚úÖ Incluir filtros espec√≠ficos: -Filter, -Properties
‚úÖ Incluir par√°metros de los objetos reales encontrados
‚ùå NO usar comandos gen√©ricos irrelevantes al problema

**CONDICI√ìN DE SALIDA:**
- Si despu√©s de analizar NO encuentras problemas cr√≠ticos o altos con evidencia real
- Devuelve: {"findings": []}
- NO fuerces findings para "rellenar"

**IDIOMA:**
üá™üá∏ ESPA√ëOL OBLIGATORIO en: title, description, recommendation, evidence.details
- Usa terminolog√≠a t√©cnica correcta en espa√±ol
- Mant√©n nombres de comandos/par√°metros en ingl√©s (ej: Set-ADUser -PasswordNeverExpires $false)

**IMPACTO DE NEGOCIO (agregar en description):**
- Riesgo financiero potencial
- Cumplimiento regulatorio afectado (GDPR, SOX, HIPAA si aplica)
- SLA de disponibilidad en riesgo

**üß† ESTRATEGIA DE RAZONAMIENTO (CHAIN OF THOUGHT):**
1. **An√°lisis de Datos:** Revisa paso a paso el bloque <assessment_data>. Identifica qu√© objetos existen y sus propiedades clave.
2. **Verificaci√≥n de Reglas:** Para cada regla de seguridad (ej. "PasswordNeverExpires"), comprueba si alg√∫n objeto en los datos la viola expl√≠citamente.
3. **Filtrado de Evidencia:** Descarta cualquier "posible problema" que no tenga evidencia directa (count > 0).
4. **Generaci√≥n de Respuesta:** Construye el JSON final solo con los hallazgos validados.

Primero, piensa paso a paso sobre qu√© hallazgos tienen evidencia s√≥lida en los datos. Luego, genera el JSON.
`;
}

async function callAI(prompt, provider, model, apiKey) {
  try {
    console.log(`[${timestamp()}] [${provider.toUpperCase()}] Making API call with model ${model}...`);

    if (provider === 'openai') {
      return await callOpenAI(prompt, model, apiKey);
    } else if (provider === 'gemini') {
      return await callGemini(prompt, model, apiKey);
    } else if (provider === 'deepseek') {
      return await callDeepSeek(prompt, model, apiKey);
    } else if (provider === 'anthropic') {
      return await callAnthropic(prompt, model, apiKey);
    } else if (provider === 'copilot') {
      // v2.0.0: GitHub Copilot provider - no API key needed
      return await callCopilot(prompt, model);
    } else {
      throw new Error(`Unknown AI provider: ${provider}`);
    }
  } catch (error) {
    console.error(`[${timestamp()}] [${provider.toUpperCase()}] Call failed:`, error.message);
    return [];
  }
}

async function callOpenAI(prompt, model, key) {
  try {
    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${key}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: model,
        messages: [
          {
            role: 'system',
            content: `Eres un analista senior de seguridad de Active Directory.

‚ö†Ô∏è REGLA DE ORO - GROUNDING OBLIGATORIO:
Los nombres en "affected_objects" DEBEN existir TEXTUALMENTE en el JSON de entrada.
El sistema VALIDA y RECHAZA autom√°ticamente cualquier nombre inventado.
Si inventas nombres como "user1", "test", "ejemplo" ‚Üí Tu finding ser√° ELIMINADO.

PRINCIPIOS:
1. SOLO reporta problemas que existan en los datos proporcionados
2. Si count = 0 o no hay objetos reales ‚Üí NO generes finding
3. Calidad sobre cantidad: Mejor 0 findings que 1 inventado
4. Todo en espa√±ol excepto comandos t√©cnicos

FORMATO JSON:
{
  "findings": [
    {
      "type_id": "PASSWORD_NEVER_EXPIRES",
      "title": "X usuarios con contrase√±a que nunca expira",
      "severity": "critical|high|medium|low",
      "description": "Descripci√≥n t√©cnica",
      "recommendation": "Pasos de remediaci√≥n",
      "mitre_attack": "T1078 - Valid Accounts",
      "cis_control": "5.2.1",
      "impact_business": "Impacto en el negocio",
      "remediation_commands": "Comandos PowerShell espec√≠ficos",
      "prerequisites": "Requisitos previos",
      "operational_impact": "Impacto operativo",
      "microsoft_docs": "URL de documentaci√≥n",
      "current_vs_recommended": "Actual vs Recomendado",
      "timeline": "24h|7d|30d|60d",
      "affected_count": 0,
      "evidence": {
        "affected_objects": ["<NOMBRES_REALES_DEL_JSON>"],
        "count": 0,
        "details": "Datos EXACTOS del JSON de entrada"
      }
    }
  ]
}

Si no encuentras problemas verificables, devuelve: {"findings": []}`
          },
          { role: 'user', content: prompt.substring(0, MAX_PROMPT) }
        ],
        response_format: {
          type: 'json_schema',
          json_schema: {
            name: 'security_findings',
            strict: false,
            schema: {
              type: 'object',
              properties: {
                findings: {
                  type: 'array',
                  items: {
                    type: 'object',
                    properties: {
                      type_id: { type: 'string' },
                      severity: {
                        type: 'string',
                        enum: ['critical', 'high', 'medium', 'low']
                      },
                      title: { type: 'string' },
                      description: { type: 'string' },
                      recommendation: { type: 'string' },
                      mitre_attack: { type: 'string' },
                      cis_control: { type: 'string' },
                      impact_business: { type: 'string' },
                      remediation_commands: { type: 'string' },
                      prerequisites: { type: 'string' },
                      operational_impact: { type: 'string' },
                      microsoft_docs: { type: 'string' },
                      current_vs_recommended: { type: 'string' },
                      timeline: { type: 'string' },
                      affected_count: { type: 'number' },
                      evidence: {
                        type: 'object',
                        additionalProperties: false,
                        properties: {
                          affected_objects: { type: 'array', items: { type: 'string' } },
                          count: { type: 'number' },
                          details: { type: 'string' }
                        },
                        required: ['affected_objects', 'count', 'details']
                      }
                    },
                    required: ['type_id', 'severity', 'title', 'description', 'recommendation', 'evidence'],
                    additionalProperties: false
                  }
                }
              },
              required: ['findings'],
              additionalProperties: false
            }
          }
        }
      })
    });

    if (!res.ok) {
      const errorText = await res.text();
      console.error(`[${timestamp()}] [OpenAI] API error: ${res.status} - ${errorText}`);
      throw new Error(`OpenAI API error: ${res.status} - ${errorText}`);
    }

    const result = await res.json();
    console.log(`[${timestamp()}] [OpenAI] Response received:`, JSON.stringify(result).substring(0, 500));

    const content = result.choices?.[0]?.message?.content;

    if (content) {
      const parsed = JSON.parse(content);
      console.log(`[${timestamp()}] [OpenAI] Parsed ${parsed.findings?.length || 0} findings`);
      return parsed.findings || [];
    }

    console.log(`[${timestamp()}] [OpenAI] No content in response`);
    return [];
  } catch (e) {
    console.error(`[${timestamp()}] [OpenAI] Call failed:`, e.message);
    console.error(`[${timestamp()}] [OpenAI] Stack:`, e.stack);
    throw e;
  }
}

async function callGemini(prompt, model, key) {
  const systemPrompt = `Eres un analista de seguridad de Active Directory.

‚ö†Ô∏è REGLA DE ORO - GROUNDING OBLIGATORIO:
Los nombres en "affected_objects" DEBEN existir TEXTUALMENTE en el JSON de entrada.
El sistema VALIDA y RECHAZA autom√°ticamente cualquier nombre inventado.
Si inventas nombres ‚Üí Tu finding ser√° ELIMINADO.

PRINCIPIOS:
1. SOLO reporta problemas verificables en los datos
2. Si count = 0 o no hay objetos reales ‚Üí NO generes finding
3. Calidad sobre cantidad: Mejor 0 findings que 1 inventado

FORMATO JSON ESTRICTO (sin texto adicional):
{
  "findings": [
    {
      "type_id": "RULE_ID",
      "severity": "critical|high|medium|low",
      "title": "T√≠tulo descriptivo",
      "description": "Descripci√≥n t√©cnica",
      "recommendation": "Recomendaci√≥n",
      "evidence": {
        "affected_objects": ["nombre1", "nombre2"],
        "count": 2,
        "details": "Detalles"
      }
    }
  ]
}
Si no hay problemas verificables: {"findings": []}`;

  try {
    const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${key}`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{
          parts: [{ text: systemPrompt + '\n\n' + prompt.substring(0, MAX_PROMPT) }]
        }],
        generationConfig: {
          temperature: 0.1, // v1.7.0: Lower temperature for more deterministic output
          topP: 0.9,
          topK: 40,
          maxOutputTokens: 8192,
          responseMimeType: 'application/json'
        }
      })
    });

    if (!res.ok) {
      const errorText = await res.text();
      console.error(`[${timestamp()}] [Gemini] API error: ${res.status} - ${errorText}`);
      throw new Error(`Gemini API error: ${res.status} - ${errorText}`);
    }

    const result = await res.json();
    console.log(`[${timestamp()}] [Gemini] Response received:`, JSON.stringify(result).substring(0, 500));

    const content = result.candidates?.[0]?.content?.parts?.[0]?.text;
    if (content) {
      // v1.7.0: Robust JSON parsing with multiple fallbacks
      const findings = parseAIResponse(content, 'Gemini');
      console.log(`[${timestamp()}] [Gemini] Parsed ${findings.length} findings`);
      return findings;
    }

    console.log(`[${timestamp()}] [Gemini] No content in response`);
    return [];
  } catch (e) {
    console.error(`[${timestamp()}] [Gemini] Call failed:`, e.message);
    return [];
  }
}

async function callDeepSeek(prompt, model, key) {
  // DeepSeek usa la misma API que OpenAI
  const res = await fetch('https://api.deepseek.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${key}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: model,
      messages: [
        {
          role: 'system',
          content: `Eres un analista de seguridad de Active Directory.

‚ö†Ô∏è REGLA DE ORO - GROUNDING OBLIGATORIO:
Los nombres en "affected_objects" DEBEN existir TEXTUALMENTE en el JSON de entrada.
El sistema VALIDA y RECHAZA autom√°ticamente cualquier nombre inventado.
Si inventas nombres ‚Üí Tu finding ser√° ELIMINADO.

PRINCIPIOS:
1. SOLO reporta problemas verificables en los datos
2. Si count = 0 o no hay objetos reales ‚Üí NO generes finding
3. Calidad sobre cantidad: Mejor 0 findings que 1 inventado

FORMATO JSON: {"findings": [...]}
Si no hay problemas verificables: {"findings": []}`
        },
        { role: 'user', content: prompt.substring(0, MAX_PROMPT) }
      ],
      temperature: 0.2,
      response_format: { type: 'json_object' }
    })
  });

  if (!res.ok) {
    const errorText = await res.text();
    console.error(`[${timestamp()}] [DeepSeek] API error: ${res.status} - ${errorText}`);
    throw new Error(`DeepSeek API error: ${res.status} - ${errorText}`);
  }

  const result = await res.json();
  console.log(`[${timestamp()}] [DeepSeek] Response received:`, JSON.stringify(result).substring(0, 500));

  const content = result.choices?.[0]?.message?.content;
  if (content) {
    const parsed = JSON.parse(content);
    console.log(`[${timestamp()}] [DeepSeek] Parsed ${parsed.findings?.length || 0} findings`);
    return parsed.findings || [];
  }

  console.log(`[${timestamp()}] [DeepSeek] No content in response`);
  return [];
}

async function callAnthropic(prompt, model, key) {
  // v1.8.0: Enhanced system prompt for Claude 4.5 models
  const isOpus = model.includes('opus');
  const modelLabel = isOpus ? 'Opus 4.5' : 'Sonnet 4.5';

  const systemPrompt = `Eres un analista de seguridad de Active Directory experto.${isOpus ? ' Como modelo Opus, proporciona an√°lisis profundo con contexto de amenazas avanzadas.' : ''}

‚ö†Ô∏è REGLA DE ORO - GROUNDING OBLIGATORIO:
Los nombres en "affected_objects" DEBEN existir TEXTUALMENTE en el JSON de entrada.
El sistema VALIDA y RECHAZA autom√°ticamente cualquier nombre inventado.
Si inventas nombres ‚Üí Tu finding ser√° ELIMINADO.

PRINCIPIOS:
1. SOLO reporta problemas verificables en los datos
2. Si count = 0 o no hay objetos reales ‚Üí NO generes finding
3. Calidad sobre cantidad: Mejor 0 findings que 1 inventado
${isOpus ? `4. Proporciona an√°lisis de cadena de ataque cuando sea relevante
5. Incluye referencias a t√©cnicas MITRE ATT&CK espec√≠ficas
6. Considera escenarios de escalaci√≥n de privilegios` : ''}

FORMATO JSON ESTRICTO (sin texto adicional, sin markdown):
{
  "findings": [
    {
      "type_id": "RULE_ID",
      "severity": "critical|high|medium|low",
      "title": "T√≠tulo descriptivo",
      "description": "Descripci√≥n t√©cnica",
      "recommendation": "Recomendaci√≥n",
      "evidence": {
        "affected_objects": ["nombre1", "nombre2"],
        "count": 2,
        "details": "Detalles"
      }${isOpus ? `,
      "attack_chain": "Descripci√≥n opcional de c√≥mo se podr√≠a explotar",
      "mitre_technique": "T1234.001"` : ''}
    }
  ]
}
Si no hay problemas verificables: {"findings": []}

IMPORTANTE: Responde SOLO con JSON v√°lido, sin texto explicativo antes o despu√©s.`;

  // v1.8.0: Optimized parameters per model
  // Opus 4.5: Higher token limit for deeper analysis
  // Sonnet 4.5: Standard limit for efficiency
  const maxTokens = isOpus ? 16384 : 8192;

  console.log(`[${timestamp()}] [Anthropic] Calling ${modelLabel} (max_tokens: ${maxTokens})`);

  try {
    const res = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'x-api-key': key,
        'anthropic-version': '2023-06-01',
        'content-type': 'application/json'
      },
      body: JSON.stringify({
        model: model,
        max_tokens: maxTokens,
        system: systemPrompt,
        messages: [
          { role: 'user', content: prompt.substring(0, MAX_PROMPT) }
        ]
      })
    });

    if (!res.ok) {
      const errorText = await res.text();
      console.error(`[${timestamp()}] [Anthropic] API error: ${res.status} - ${errorText}`);
      throw new Error(`Anthropic API error: ${res.status} - ${errorText}`);
    }

    const result = await res.json();
    console.log(`[${timestamp()}] [Anthropic] [${modelLabel}] Response received:`, JSON.stringify(result).substring(0, 500));

    // Log usage for cost tracking
    if (result.usage) {
      console.log(`[${timestamp()}] [Anthropic] [${modelLabel}] Tokens - Input: ${result.usage.input_tokens}, Output: ${result.usage.output_tokens}`);
    }

    const content = result.content?.[0]?.text;
    if (content) {
      // v1.7.0: Use robust parsing function
      const findings = parseAIResponse(content, `Anthropic/${modelLabel}`);
      console.log(`[${timestamp()}] [Anthropic] [${modelLabel}] Parsed ${findings.length} findings`);
      return findings;
    }

    console.log(`[${timestamp()}] [Anthropic] [${modelLabel}] No valid content in response`);
    return [];
  } catch (e) {
    console.error(`[${timestamp()}] [Anthropic] [${modelLabel}] Call failed:`, e.message);
    return [];
  }
}

// =============================================================================
// v1.7.0: ROBUST JSON PARSING FOR AI RESPONSES
// Handles various edge cases: markdown blocks, mixed text, malformed JSON
// =============================================================================

/**
 * Parse AI response with multiple fallback strategies
 * @param {string} content - Raw AI response content
 * @param {string} provider - AI provider name for logging
 * @returns {Array} - Parsed findings array or empty array on failure
 */
function parseAIResponse(content, provider) {
  if (!content || typeof content !== 'string') {
    console.warn(`[${timestamp()}] [${provider}] Empty or invalid content`);
    return [];
  }

  // Strategy 1: Direct JSON parse
  try {
    const parsed = JSON.parse(content);
    if (parsed.findings && Array.isArray(parsed.findings)) {
      return parsed.findings;
    }
    // If parsed but no findings array, check if it's an array directly
    if (Array.isArray(parsed)) {
      return parsed;
    }
    console.warn(`[${timestamp()}] [${provider}] Parsed JSON but no findings array`);
    return [];
  } catch (e1) {
    // Continue to next strategy
  }

  // Strategy 2: Clean markdown code blocks
  let cleanContent = content
    .replace(/```json\s*/gi, '')
    .replace(/```\s*/g, '')
    .trim();

  try {
    const parsed = JSON.parse(cleanContent);
    if (parsed.findings && Array.isArray(parsed.findings)) {
      console.log(`[${timestamp()}] [${provider}] Parsed after removing markdown blocks`);
      return parsed.findings;
    }
  } catch (e2) {
    // Continue to next strategy
  }

  // Strategy 3: Extract JSON object using balanced brace matching
  try {
    const jsonStart = cleanContent.indexOf('{');
    if (jsonStart !== -1) {
      let braceCount = 0;
      let jsonEnd = -1;

      for (let i = jsonStart; i < cleanContent.length; i++) {
        if (cleanContent[i] === '{') braceCount++;
        if (cleanContent[i] === '}') braceCount--;
        if (braceCount === 0) {
          jsonEnd = i + 1;
          break;
        }
      }

      if (jsonEnd > jsonStart) {
        const extractedJson = cleanContent.substring(jsonStart, jsonEnd);
        const parsed = JSON.parse(extractedJson);
        if (parsed.findings && Array.isArray(parsed.findings)) {
          console.log(`[${timestamp()}] [${provider}] Parsed after balanced brace extraction`);
          return parsed.findings;
        }
      }
    }
  } catch (e3) {
    // Continue to next strategy
  }

  // Strategy 4: Find JSON array directly (for responses that skip the wrapper)
  try {
    const arrayMatch = cleanContent.match(/\[\s*\{[\s\S]*\}\s*\]/);
    if (arrayMatch) {
      const parsed = JSON.parse(arrayMatch[0]);
      if (Array.isArray(parsed)) {
        console.log(`[${timestamp()}] [${provider}] Parsed direct array match`);
        return parsed;
      }
    }
  } catch (e4) {
    // Continue to final fallback
  }

  // Strategy 5: Try to fix common JSON issues
  try {
    // Remove trailing commas before ] or }
    let fixedContent = cleanContent
      .replace(/,\s*([}\]])/g, '$1')
      // Fix unquoted keys
      .replace(/([{,]\s*)(\w+)(\s*:)/g, '$1"$2"$3');

    const jsonStart = fixedContent.indexOf('{');
    const jsonEnd = fixedContent.lastIndexOf('}') + 1;

    if (jsonStart !== -1 && jsonEnd > jsonStart) {
      const extracted = fixedContent.substring(jsonStart, jsonEnd);
      const parsed = JSON.parse(extracted);
      if (parsed.findings && Array.isArray(parsed.findings)) {
        console.log(`[${timestamp()}] [${provider}] Parsed after JSON fixes`);
        return parsed.findings;
      }
    }
  } catch (e5) {
    console.error(`[${timestamp()}] [${provider}] All parsing strategies failed`);
    console.error(`[${timestamp()}] [${provider}] Content preview: ${content.substring(0, 200)}...`);
  }

  return [];
}

// =============================================================================
// v2.0.0: GITHUB COPILOT AI PROVIDER
// Uses GitHub Copilot subscription for AI analysis (no separate API key needed)
// =============================================================================

async function callCopilot(prompt, model) {
  console.log(`[${timestamp()}] [COPILOT] Calling model: ${model}`);
  
  const systemPrompt = `Eres un analista de seguridad de Active Directory experto.

‚ö†Ô∏è REGLA DE ORO - GROUNDING OBLIGATORIO:
Los nombres en "affected_objects" DEBEN existir TEXTUALMENTE en el JSON de entrada.
El sistema VALIDA y RECHAZA autom√°ticamente cualquier nombre inventado.
Si inventas nombres ‚Üí Tu finding ser√° ELIMINADO.

PRINCIPIOS:
1. SOLO reporta problemas verificables en los datos
2. Si count = 0 o no hay objetos reales ‚Üí NO generes finding
3. Calidad sobre cantidad: Mejor 0 findings que 1 inventado

FORMATO JSON ESTRICTO (sin texto adicional, sin markdown):
{
  "findings": [
    {
      "type_id": "RULE_ID",
      "severity": "critical|high|medium|low",
      "title": "T√≠tulo descriptivo",
      "description": "Descripci√≥n t√©cnica",
      "recommendation": "Recomendaci√≥n",
      "mitre_attack": "T1234 - T√©cnica",
      "cis_control": "X.Y.Z",
      "impact_business": "Impacto en el negocio",
      "remediation_commands": "Comandos PowerShell",
      "prerequisites": "Requisitos",
      "operational_impact": "Impacto operativo",
      "microsoft_docs": "URL documentaci√≥n",
      "current_vs_recommended": "Actual vs Recomendado",
      "timeline": "24h|7d|30d|60d",
      "affected_count": 0,
      "evidence": {
        "affected_objects": ["nombre1", "nombre2"],
        "count": 2,
        "details": "Detalles exactos del JSON"
      }
    }
  ]
}
Si no hay problemas verificables: {"findings": []}

IMPORTANTE: Responde SOLO con JSON v√°lido, sin texto explicativo antes o despu√©s.`;

  try {
    const response = await copilotClient.chat(
      [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt.substring(0, MAX_PROMPT) }
      ],
      model,
      { temperature: 0.2, max_tokens: 8192 }
    );

    const content = response.choices?.[0]?.message?.content;
    
    if (content) {
      // Use the same robust parsing as other providers
      const findings = parseAIResponse(content, `Copilot/${model}`);
      console.log(`[${timestamp()}] [COPILOT] Parsed ${findings.length} findings`);
      return findings;
    }

    console.log(`[${timestamp()}] [COPILOT] No content in response`);
    return [];
  } catch (error) {
    console.error(`[${timestamp()}] [COPILOT] Call failed:`, error.message);
    throw error;
  }
}

// Main Processing Function
async function processAssessment(assessmentId, jsonData) {
  try {
    await addLog(assessmentId, 'info', 'üöÄ Starting processing on Self-Hosted VPS');

    // 1. Store Raw Data (JSONB handles storage efficiently)
    // const jsonString = JSON.stringify(jsonData);
    // const compressed = zlib.gzipSync(jsonString);
    // const compressionRatio = Math.round((1 - compressed.length / jsonString.length) * 100);
    // console.log(`[${timestamp()}] Compressed ${Math.round(jsonString.length / 1024 / 1024)} MB to ${Math.round(compressed.length / 1024 / 1024)} MB (${compressionRatio}% reduction)`);

    await pool.query(
      'INSERT INTO assessment_data (assessment_id, data) VALUES ($1, $2)',
      [assessmentId, jsonData]
    );
    await addLog(assessmentId, 'info', `‚úÖ Raw data stored successfully`);

    // 2. Identify Categories
    const availableCategories = [];
    for (const category of CATEGORIES) {
      const data = extractCategoryData(jsonData, category);
      if (data && data.length > 0) {
        availableCategories.push({ id: category, count: data.length, data });
      }
    }

    if (availableCategories.length === 0) {
      throw new Error('No valid categories found');
    }

    // 3. Update Status to Analyzing
    const progressData = availableCategories.reduce((acc, cat) => {
      acc[cat.id] = { status: 'pending', progress: 0, count: cat.count };
      return acc;
    }, {});

    await pool.query(
      'UPDATE assessments SET status = $1, analysis_progress = $2 WHERE id = $3',
      ['analyzing', progressData, assessmentId]
    );

    // 4. Process Categories
    const sleep = (ms) => new Promise(resolve => setTimeout(resolve, ms));

    for (const categoryInfo of availableCategories) {
      const { id: category, data } = categoryInfo;

      progressData[category].status = 'processing';
      await pool.query('UPDATE assessments SET analysis_progress = $1 WHERE id = $2', [progressData, assessmentId]);

      await analyzeCategory(assessmentId, category, data);

      progressData[category].status = 'completed';
      progressData[category].progress = 100;
      await pool.query('UPDATE assessments SET analysis_progress = $1 WHERE id = $2', [progressData, assessmentId]);

      // Rate limit protection: Wait 20 seconds between categories
      console.log(`[${timestamp()}] Waiting 20s to respect API rate limits...`);
      await sleep(20000);
    }

    // 5. Finish
    await pool.query(
      'UPDATE assessments SET status = $1, completed_at = NOW() WHERE id = $2',
      ['completed', assessmentId]
    );
    await addLog(assessmentId, 'info', 'üéâ Analysis completed successfully');

  } catch (error) {
    console.error('Fatal processing error:', error);
    await addLog(assessmentId, 'error', `Fatal error: ${error.message}`);
    await pool.query('UPDATE assessments SET status = $1 WHERE id = $2', ['failed', assessmentId]);
  }
}

// API Endpoint
app.post('/api/process-assessment', async (req, res) => {
  try {
    const { assessmentId, jsonData, domainName } = req.body;

    if (!jsonData) return res.status(400).json({ error: 'Missing jsonData' });

    // Create assessment if ID not provided (or if it doesn't exist)
    let finalAssessmentId = assessmentId;
    if (!finalAssessmentId) {
      const result = await pool.query(
        'INSERT INTO assessments (domain, status) VALUES ($1, $2) RETURNING id',
        [domainName || 'Unknown Domain', 'analyzing']
      );
      finalAssessmentId = result.rows[0].id;
    } else {
      // Check if exists, if not create
      const check = await pool.query('SELECT id FROM assessments WHERE id = $1', [assessmentId]);
      if (check.rows.length === 0) {
        await pool.query(
          'INSERT INTO assessments (id, domain, status) VALUES ($1, $2, $3)',
          [assessmentId, domainName || 'Unknown Domain', 'analyzing']
        );
      }
    }

    // Start processing in background
    processAssessment(finalAssessmentId, jsonData).catch(err => console.error('Background error:', err));

    res.json({ success: true, assessmentId: finalAssessmentId, message: 'Processing started' });

  } catch (error) {
    console.error('API Error:', error);
    res.status(500).json({ error: error.message });
  }
});

app.get('/health', async (req, res) => {
  try {
    await pool.query('SELECT 1');
    res.json({ status: 'ok', db: 'connected' });
  } catch (e) {
    res.status(500).json({ status: 'error', db: e.message });
  }
});

// GET /api/config/ai - Get AI configuration
app.get('/api/config/ai', async (req, res) => {
  try {
    const provider = (await getConfig('ai_provider')) || 'openai';
    const model = (await getConfig('ai_model')) || 'gpt-4o-mini';
    const hasOpenAIKey = !!(await getConfig('openai_api_key') || process.env.OPENAI_API_KEY);
    const hasGeminiKey = !!await getConfig('gemini_api_key');
    const hasDeepSeekKey = !!await getConfig('deepseek_api_key');
    const hasAnthropicKey = !!await getConfig('anthropic_api_key');
    
    // v2.0.0: Check Copilot authentication status
    const copilotStatus = await copilotClient.getAuthStatus();
    const copilotModel = await getConfig('copilot_model') || 'gpt-4o';

    res.json({
      provider,
      model,
      available_providers: {
        openai: hasOpenAIKey,
        gemini: hasGeminiKey,
        deepseek: hasDeepSeekKey,
        anthropic: hasAnthropicKey,
        copilot: copilotStatus.authenticated
      },
      models: {
        openai: ['gpt-4o-mini', 'gpt-4o', 'gpt-4-turbo'],
        gemini: ['gemini-1.5-pro', 'gemini-1.5-flash', 'gemini-1.0-pro'],
        deepseek: ['deepseek-chat', 'deepseek-coder'],
        anthropic: ['claude-opus-4-5-20250514', 'claude-sonnet-4-5-20250514', 'auto'],
        copilot: COPILOT_MODELS.map(m => m.id)
      },
      // v1.8.0: Inform frontend about dynamic model selection
      anthropic_auto_select: {
        enabled: true,
        opus_categories: Array.from(OPUS_CATEGORIES),
        description: 'Selecci√≥n autom√°tica: Opus 4.5 para categor√≠as cr√≠ticas, Sonnet 4.5 para el resto'
      },
      // v2.0.0: Copilot configuration
      copilot: {
        authenticated: copilotStatus.authenticated,
        userLogin: copilotStatus.userLogin,
        tokenValid: copilotStatus.tokenValid,
        selectedModel: copilotModel,
        models: COPILOT_MODELS
      }
    });
  } catch (error) {
    console.error('Error fetching AI config:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/config/ai - Update AI configuration
app.post('/api/config/ai', async (req, res) => {
  try {
    const { provider, model, api_keys } = req.body;

    if (provider) {
      await setConfig('ai_provider', provider);
    }

    if (model) {
      await setConfig('ai_model', model);
    }

    if (api_keys) {
      if (api_keys.openai) await setConfig('openai_api_key', api_keys.openai);
      if (api_keys.gemini) await setConfig('gemini_api_key', api_keys.gemini);
      if (api_keys.deepseek) await setConfig('deepseek_api_key', api_keys.deepseek);
      if (api_keys.anthropic) await setConfig('anthropic_api_key', api_keys.anthropic);
    }

    res.json({ success: true, message: 'AI configuration updated' });
  } catch (error) {
    console.error('Error updating AI config:', error);
    res.status(500).json({ error: error.message });
  }
});

// =============================================================================
// v2.0.0: GITHUB COPILOT ENDPOINTS
// OAuth Device Flow authentication for GitHub Copilot integration
// =============================================================================

// POST /api/copilot/auth/start - Start OAuth Device Flow
app.post('/api/copilot/auth/start', async (req, res) => {
  try {
    console.log('[Copilot API] Starting device flow...');
    const result = await copilotClient.startDeviceFlow();
    res.json({
      success: true,
      deviceCode: result.deviceCode,
      userCode: result.userCode,
      verificationUri: result.verificationUri,
      expiresIn: result.expiresIn,
      interval: result.interval
    });
  } catch (error) {
    console.error('[Copilot API] Start error:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/copilot/auth/poll - Poll for device authorization
app.post('/api/copilot/auth/poll', async (req, res) => {
  try {
    const { deviceCode } = req.body;
    if (!deviceCode) {
      return res.status(400).json({ error: 'deviceCode is required' });
    }
    
    const result = await copilotClient.pollDeviceFlow(deviceCode);
    res.json(result);
  } catch (error) {
    console.error('[Copilot API] Poll error:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/copilot/auth/status - Get authentication status
app.get('/api/copilot/auth/status', async (req, res) => {
  try {
    const status = await copilotClient.getAuthStatus();
    res.json(status);
  } catch (error) {
    console.error('[Copilot API] Status error:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/copilot/auth/logout - Logout from Copilot
app.post('/api/copilot/auth/logout', async (req, res) => {
  try {
    await copilotClient.logout();
    res.json({ success: true, message: 'Logged out successfully' });
  } catch (error) {
    console.error('[Copilot API] Logout error:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/copilot/models - Get available Copilot models
app.get('/api/copilot/models', async (req, res) => {
  try {
    const models = await copilotClient.getModels();
    res.json({ models });
  } catch (error) {
    console.error('[Copilot API] Models error:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/copilot/model - Set the preferred Copilot model
app.post('/api/copilot/model', async (req, res) => {
  try {
    const { model } = req.body;
    if (!model) {
      return res.status(400).json({ error: 'model is required' });
    }
    
    await setConfig('copilot_model', model);
    res.json({ success: true, message: `Model set to ${model}` });
  } catch (error) {
    console.error('[Copilot API] Set model error:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/clients - Create a new client
app.post('/api/clients', async (req, res) => {
  const { name, contact_email } = req.body;
  if (!name) return res.status(400).json({ error: 'Client Name is required' });

  try {
    const result = await pool.query(
      'INSERT INTO clients (name, contact_email) VALUES ($1, $2) RETURNING *',
      [name, contact_email]
    );
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error creating client:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/clients - List all clients
app.get('/api/clients', async (req, res) => {
  try {
    const result = await pool.query(
      'SELECT * FROM clients ORDER BY name ASC'
    );
    res.json(result.rows);
  } catch (error) {
    console.error('Error fetching clients:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/assessments - Create a new assessment
app.post('/api/assessments', async (req, res) => {
  const { domain, client_id } = req.body;
  if (!domain) {
    return res.status(400).json({ error: 'Domain is required' });
  }

  try {
    const result = await pool.query(
      'INSERT INTO assessments (domain, client_id, status) VALUES ($1, $2, $3) RETURNING *',
      [domain, client_id || null, 'pending']
    );
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error creating assessment:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/assessments - List all assessments (optionally filtered by client)
app.get('/api/assessments', async (req, res) => {
  const { clientId } = req.query;
  try {
    let query = 'SELECT * FROM assessments';
    let params = [];

    if (clientId) {
      query += ' WHERE client_id = $1';
      params.push(clientId);
    }

    query += ' ORDER BY created_at DESC';

    const result = await pool.query(query, params);
    res.json(result.rows);
  } catch (error) {
    console.error('Error fetching assessments:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/assessments/:id - Get single assessment
app.get('/api/assessments/:id', async (req, res) => {
  const { id } = req.params;
  try {
    const result = await pool.query(
      'SELECT * FROM assessments WHERE id = $1',
      [id]
    );
    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Assessment not found' });
    }
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error fetching assessment:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/assessments/:id/findings - Get findings for an assessment
app.get('/api/assessments/:id/findings', async (req, res) => {
  const { id } = req.params;
  try {
    const result = await pool.query(
      'SELECT * FROM findings WHERE assessment_id = $1 ORDER BY CASE severity WHEN \'critical\' THEN 1 WHEN \'high\' THEN 2 WHEN \'medium\' THEN 3 WHEN \'low\' THEN 4 ELSE 5 END',
      [id]
    );
    res.json(result.rows);
  } catch (error) {
    console.error('Error fetching findings:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/assessments/:id/logs - Get logs for an assessment
app.get('/api/assessments/:id/logs', async (req, res) => {
  const { id } = req.params;
  try {
    const result = await pool.query(
      'SELECT * FROM assessment_logs WHERE assessment_id = $1 ORDER BY created_at ASC',
      [id]
    );
    res.json(result.rows);
  } catch (error) {
    console.error('Error fetching logs:', error);
    res.status(500).json({ error: error.message });
  }
});

// GET /api/assessments/:id/data - Get raw data for an assessment
app.get('/api/assessments/:id/data', async (req, res) => {
  const { id } = req.params;
  console.log(`[${timestamp()}] [API] Fetching raw data for assessment ${id}`);
  try {
    const result = await pool.query(
      'SELECT data FROM assessment_data WHERE assessment_id = $1',
      [id]
    );

    if (result.rows.length === 0) {
      console.log(`[${timestamp()}] [API] No raw data found for assessment ${id}`);
      return res.status(404).json({ error: 'Assessment data not found' });
    }

    // Check if data is compressed (Buffer) or raw JSON (Object from JSONB)
    const rawData = result.rows[0].data;

    if (Buffer.isBuffer(rawData)) {
      // Legacy: Compressed data
      res.setHeader('Content-Type', 'application/json');
      res.setHeader('Content-Encoding', 'gzip');
      console.log(`[${timestamp()}] [API] Sending compressed raw data for assessment ${id} (${Math.round(rawData.length / 1024 / 1024)} MB)`);
      res.send(rawData);
    } else {
      // New: JSONB data (already parsed by pg)
      console.log(`[${timestamp()}] [API] Sending JSON raw data for assessment ${id}`);
      res.json(rawData);
    }
  } catch (error) {
    console.error(`[${timestamp()}] [API] Error fetching assessment data:`, error);
    res.status(500).json({ error: error.message });
  }
});

// DELETE /api/assessments/:id - Delete an assessment
app.delete('/api/assessments/:id', async (req, res) => {
  const { id } = req.params;
  try {
    // Cascading delete should handle related data if configured, 
    // but let's be safe and delete related data first if needed.
    // Our schema uses ON DELETE CASCADE so deleting assessment is enough.

    const result = await pool.query(
      'DELETE FROM assessments WHERE id = $1 RETURNING *',
      [id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Assessment not found' });
    }

    res.json({ message: 'Assessment deleted successfully' });
  } catch (error) {
    console.error('Error deleting assessment:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/assessments/:id/reset - Reset an assessment
app.post('/api/assessments/:id/reset', async (req, res) => {
  const { id } = req.params;
  try {
    // Delete findings
    await pool.query('DELETE FROM findings WHERE assessment_id = $1', [id]);

    // Reset assessment status
    const result = await pool.query(
      `UPDATE assessments 
       SET status = 'pending', 
           analysis_progress = '{"total": 0, "current": null, "completed": 0, "categories": []}',
           completed_at = NULL,
           updated_at = NOW()
       WHERE id = $1 RETURNING *`,
      [id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Assessment not found' });
    }

    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error resetting assessment:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /api/upload-large-file - Handle large file uploads (.json or .zip)
const upload = multer({
  dest: '/tmp/uploads/',
  limits: {
    fileSize: 5 * 1024 * 1024 * 1024 // 5GB max file size
  }
});

app.post('/api/upload-large-file', upload.single('file'), async (req, res) => {
  const { assessmentId } = req.body;
  const filePath = req.file?.path;

  if (!assessmentId || !filePath) {
    return res.status(400).json({ error: 'Missing assessmentId or file' });
  }

  try {
    console.log(`[${timestamp()}] [UPLOAD] Processing file: ${req.file.originalname} (${(req.file.size / 1024 / 1024).toFixed(2)} MB)`);
    await addLog(assessmentId, 'info', `Archivo recibido: ${req.file.originalname} (${(req.file.size / 1024 / 1024).toFixed(2)} MB)`);

    let jsonData;
    const isZip = req.file.originalname.endsWith('.zip');

    if (isZip) {
      // Decompress ZIP file
      await addLog(assessmentId, 'info', 'Descomprimiendo archivo ZIP...');
      console.log(`[${timestamp()}] [UPLOAD] Decompressing ZIP file...`);

      const zip = new AdmZip(filePath);
      const entries = zip.getEntries();

      // Find the JSON file inside ZIP
      const jsonEntry = entries.find(e => e.entryName.endsWith('.json') && !e.isDirectory);

      if (!jsonEntry) {
        await addLog(assessmentId, 'error', 'No se encontr√≥ archivo JSON dentro del ZIP');
        return res.status(400).json({ error: 'No JSON file found in ZIP' });
      }

      console.log(`[${timestamp()}] [UPLOAD] Found JSON entry: ${jsonEntry.entryName}`);
      let jsonContent = zip.readAsText(jsonEntry);

      // Remove BOM (Byte Order Mark) if present
      if (jsonContent.charCodeAt(0) === 0xFEFF) {
        console.log(`[${timestamp()}] [UPLOAD] Removing BOM from JSON content`);
        jsonContent = jsonContent.substring(1);
      }

      jsonData = JSON.parse(jsonContent);

      await addLog(assessmentId, 'info', `Archivo descomprimido: ${jsonEntry.entryName}`);
    } else {
      // Read JSON directly
      console.log(`[${timestamp()}] [UPLOAD] Reading JSON file...`);
      let jsonContent = fs.readFileSync(filePath, 'utf8');

      // Remove BOM (Byte Order Mark) if present
      if (jsonContent.charCodeAt(0) === 0xFEFF) {
        console.log(`[${timestamp()}] [UPLOAD] Removing BOM from JSON content`);
        jsonContent = jsonContent.substring(1);
      }

      jsonData = JSON.parse(jsonContent);
    }

    console.log(`[${timestamp()}] [UPLOAD] JSON parsed successfully`);
    await addLog(assessmentId, 'info', 'Datos JSON procesados correctamente');

    // Store JSON data directly (JSONB column handles storage efficiently)
    await addLog(assessmentId, 'info', 'Guardando datos en la base de datos...');
    await pool.query(
      'INSERT INTO assessment_data (assessment_id, data) VALUES ($1, $2) ON CONFLICT (assessment_id) DO UPDATE SET data = $2',
      [assessmentId, jsonData]
    );
    console.log(`[${timestamp()}] [UPLOAD] Data stored as JSONB`);

    // Update assessment status
    await pool.query(
      'UPDATE assessments SET status = $1, updated_at = NOW() WHERE id = $2',
      ['uploaded', assessmentId]
    );

    console.log(`[${timestamp()}] [UPLOAD] Data stored in database`);
    await addLog(assessmentId, 'info', 'Datos guardados. Iniciando an√°lisis...');

    // Start analysis process (async, don't wait)
    processAssessmentData(assessmentId, jsonData).catch(err => {
      console.error(`[${timestamp()}] [UPLOAD] Background analysis error:`, err);
      addLog(assessmentId, 'error', `Error en an√°lisis: ${err.message}`);
    });

    // Return success immediately
    res.json({
      success: true,
      message: 'Archivo procesado correctamente',
      status: 'analyzing',
      fileType: isZip ? 'zip' : 'json',
      originalSize: req.file.size
    });

  } catch (error) {
    console.error(`[${timestamp()}] [UPLOAD] Error processing file:`, error);
    await addLog(assessmentId, 'error', `Error procesando archivo: ${error.message}`);

    res.status(500).json({
      error: 'Error processing file',
      details: error.message
    });
  } finally {
    // Clean up temporary file
    if (filePath && fs.existsSync(filePath)) {
      try {
        fs.unlinkSync(filePath);
        console.log(`[${timestamp()}] [UPLOAD] Temporary file deleted: ${filePath}`);
      } catch (cleanupError) {
        console.error(`[${timestamp()}] [UPLOAD] Error deleting temp file:`, cleanupError);
      }
    }
  }
});

// DEBUG ENDPOINTS
// ------------------------------------------------------------------

// 1. Generate/Trigger Assessment Analysis (Manual Trigger)
app.post('/api/debug/assessments/:id/analyze', async (req, res) => {
  try {
    const { id } = req.params;
    const result = await pool.query('SELECT data FROM assessment_data WHERE assessment_id = $1', [id]);

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Assessment data not found' });
    }

    let jsonData;
    const rawData = result.rows[0].data;

    // Handle compressed data
    if (Buffer.isBuffer(rawData)) {
      try {
        const decompressed = zlib.gunzipSync(rawData);
        jsonData = JSON.parse(decompressed.toString());
      } catch (e) {
        // Fallback if not compressed (legacy)
        jsonData = JSON.parse(rawData.toString());
      }
    } else {
      jsonData = rawData; // Already JSON
    }

    // Trigger analysis in background
    processAssessmentData(id, jsonData).catch(err => console.error('Manual trigger error:', err));

    res.json({ message: 'Analysis triggered manually', assessmentId: id });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 2. Validate Assessment Quality (Check findings vs Data)
app.get('/api/debug/assessments/:id/validate', async (req, res) => {
  try {
    const { id } = req.params;

    // Get findings
    const findingsRes = await pool.query('SELECT * FROM findings WHERE assessment_id = $1', [id]);
    const findings = findingsRes.rows;

    // Get raw data
    const dataRes = await pool.query('SELECT data FROM assessment_data WHERE assessment_id = $1', [id]);
    if (dataRes.rows.length === 0) return res.status(404).json({ error: 'No data' });

    let rawData;
    // Decompress if needed
    if (Buffer.isBuffer(dataRes.rows[0].data)) {
      rawData = JSON.parse(zlib.gunzipSync(dataRes.rows[0].data).toString());
    } else {
      rawData = dataRes.rows[0].data;
    }

    const validationReport = {
      totalFindings: findings.length,
      hallucinationsDetected: [],
      validFindings: 0
    };

    // Build Valid Names Set
    const validNames = new Set();
    const categories = ['Users', 'Computers', 'Groups', 'GPOs', 'DNSConfiguration'];

    // Deep Grounding Extraction (Matches main app logic)
    // Recursive Deep Grounding Extraction
    const extractNames = (obj) => {
      if (!obj) return;

      if (typeof obj === 'string') {
        if (obj.length > 2 && obj.length < 100) validNames.add(obj.toLowerCase());
        return;
      }

      if (Array.isArray(obj)) {
        obj.forEach(item => extractNames(item));
        return;
      }

      if (typeof obj === 'object') {
        Object.keys(obj).forEach(key => {
          if (key.length > 2 && key.length < 100) validNames.add(key.toLowerCase());
          extractNames(obj[key]);
        });
      }
    };

    categories.forEach(cat => {
      const catData = extractCategoryData(rawData, cat);
      if (catData) catData.forEach(extractNames);
    });

    // Validating Findings
    findings.forEach(f => {
      const evidence = f.evidence || {};
      const affected = evidence.affected_objects || [];

      if (affected.length > 0) {
        const invalidObjects = affected.filter(obj => {
          const clean = obj.replace(/^CN=|,.*/g, '').trim().toLowerCase();
          return !validNames.has(clean) && !validNames.has(obj.toLowerCase());
        });

        if (invalidObjects.length > 0) {
          validationReport.hallucinationsDetected.push({
            findingId: f.id,
            title: f.title,
            invalidObjects: invalidObjects
          });
        } else {
          validationReport.validFindings++;
        }
      } else {
        // Global findings
        validationReport.validFindings++;
      }
    });

    res.json(validationReport);

  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 3. View Raw Uploaded JSON (Decompressed)
app.get('/api/debug/assessments/:id/json', async (req, res) => {
  try {
    const { id } = req.params;
    const result = await pool.query('SELECT data FROM assessment_data WHERE assessment_id = $1', [id]);

    if (result.rows.length === 0) return res.status(404).json({ error: 'Not found' });

    let jsonData;
    if (Buffer.isBuffer(result.rows[0].data)) {
      jsonData = JSON.parse(zlib.gunzipSync(result.rows[0].data).toString());
    } else {
      jsonData = result.rows[0].data;
    }

    res.json(jsonData);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 4. Word Report Data Preview
app.get('/api/debug/assessments/:id/word-data', async (req, res) => {
  try {
    const { id } = req.params;
    // Simulate what goes into the word report
    const assessment = (await pool.query('SELECT * FROM assessments WHERE id = $1', [id])).rows[0];
    const findings = (await pool.query('SELECT * FROM findings WHERE assessment_id = $1', [id])).rows;
    // Retrieve raw data
    const dataRes = await pool.query('SELECT data FROM assessment_data WHERE assessment_id = $1', [id]);
    let rawData = {};
    if (dataRes.rows.length > 0) {
      if (Buffer.isBuffer(dataRes.rows[0].data)) {
        rawData = JSON.parse(zlib.gunzipSync(dataRes.rows[0].data).toString());
      } else {
        rawData = dataRes.rows[0].data;
      }
    }

    const reportPayload = {
      assessment: assessment,
      findingsCount: findings.length,
      findingsPreview: findings.map(f => ({ title: f.title, risk: f.severity })),
      keyMetrics: {
        users: rawData.Users ? (rawData.Users.Data ? rawData.Users.Data.length : rawData.Users.length) : 0,
        computers: rawData.Computers ? (rawData.Computers.Data ? rawData.Computers.Data.length : rawData.Computers.length) : 0,
      }
    };

    res.json(reportPayload);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 5. Dashboard Data Debug
app.get('/api/debug/assessments/:id/dashboard-data', async (req, res) => {
  // This mimics the dashboard data loading logic
  try {
    const { id } = req.params;
    const findings = (await pool.query('SELECT * FROM findings WHERE assessment_id = $1', [id])).rows;

    // Calculate Dashboard Metrics
    const criticalCount = findings.filter(f => f.severity === 'critical').length;
    const highCount = findings.filter(f => f.severity === 'high').length;

    const dashboardDebug = {
      scorecard: {
        critical: criticalCount,
        high: highCount,
        total: findings.length
      },
      topRisks: findings.filter(f => f.severity === 'critical').map(f => f.title)
    };

    res.json(dashboardDebug);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 6. Executive Summary Debug - Complete assessment overview
app.get('/api/debug/assessments/:id/summary', async (req, res) => {
  try {
    const { id } = req.params;
    
    // Get assessment info
    const assessmentRes = await pool.query('SELECT * FROM assessments WHERE id = $1', [id]);
    if (assessmentRes.rows.length === 0) {
      return res.status(404).json({ error: 'Assessment not found' });
    }
    const assessment = assessmentRes.rows[0];
    
    // Get findings
    const findingsRes = await pool.query('SELECT * FROM findings WHERE assessment_id = $1', [id]);
    const findings = findingsRes.rows;
    
    // Get logs
    const logsRes = await pool.query('SELECT * FROM assessment_logs WHERE assessment_id = $1 ORDER BY created_at DESC LIMIT 20', [id]);
    const logs = logsRes.rows;
    
    // Get raw data stats
    const dataRes = await pool.query('SELECT data FROM assessment_data WHERE assessment_id = $1', [id]);
    let dataStats = { hasData: false, categories: [], totalObjects: 0 };
    
    if (dataRes.rows.length > 0) {
      let rawData;
      if (Buffer.isBuffer(dataRes.rows[0].data)) {
        rawData = JSON.parse(zlib.gunzipSync(dataRes.rows[0].data).toString());
      } else {
        rawData = dataRes.rows[0].data;
      }
      
      dataStats.hasData = true;
      // Count objects per category
      for (const category of CATEGORIES) {
        const catData = extractCategoryData(rawData, category);
        if (catData && catData.length > 0) {
          dataStats.categories.push({ name: category, count: catData.length });
          dataStats.totalObjects += catData.length;
        }
      }
    }
    
    // Calculate severity distribution
    const severityDist = {
      critical: findings.filter(f => f.severity === 'critical').length,
      high: findings.filter(f => f.severity === 'high').length,
      medium: findings.filter(f => f.severity === 'medium').length,
      low: findings.filter(f => f.severity === 'low').length,
      info: findings.filter(f => f.severity === 'info' || f.severity === 'informational').length
    };
    
    // Calculate health score (simple formula)
    const riskScore = (severityDist.critical * 40) + (severityDist.high * 20) + (severityDist.medium * 5) + (severityDist.low * 1);
    const healthScore = Math.max(0, 100 - Math.min(100, riskScore));
    
    // Categorize findings
    const findingsByCategory = {};
    findings.forEach(f => {
      const cat = f.category_id || 'Uncategorized';
      if (!findingsByCategory[cat]) findingsByCategory[cat] = [];
      findingsByCategory[cat].push({ title: f.title, severity: f.severity });
    });
    
    const summary = {
      assessment: {
        id: assessment.id,
        domain: assessment.domain,
        status: assessment.status,
        created_at: assessment.created_at,
        completed_at: assessment.completed_at,
        duration: assessment.completed_at 
          ? `${Math.round((new Date(assessment.completed_at) - new Date(assessment.created_at)) / 1000 / 60)} minutos`
          : 'En progreso'
      },
      health: {
        score: healthScore,
        grade: healthScore >= 90 ? 'A' : healthScore >= 75 ? 'B' : healthScore >= 60 ? 'C' : healthScore >= 40 ? 'D' : 'F',
        riskLevel: healthScore >= 75 ? 'Bajo' : healthScore >= 50 ? 'Medio' : healthScore >= 25 ? 'Alto' : 'Cr√≠tico'
      },
      findings: {
        total: findings.length,
        distribution: severityDist,
        byCategory: findingsByCategory,
        topCritical: findings.filter(f => f.severity === 'critical').slice(0, 5).map(f => f.title)
      },
      data: dataStats,
      recentLogs: logs.slice(0, 10).map(l => ({
        level: l.level,
        message: l.message,
        time: l.created_at
      })),
      debugTips: []
    };
    
    // Add debug tips based on analysis
    if (findings.length === 0) {
      summary.debugTips.push('‚ö†Ô∏è Sin hallazgos: Verificar /validate para detectar problemas de an√°lisis');
    }
    if (!dataStats.hasData) {
      summary.debugTips.push('‚ùå Sin datos raw: El assessment no tiene datos cargados');
    }
    if (assessment.status === 'failed') {
      summary.debugTips.push('üî¥ Assessment fallido: Revisar logs para identificar el error');
    }
    if (severityDist.critical === 0 && dataStats.totalObjects > 100) {
      summary.debugTips.push('ü§î Muchos objetos pero sin cr√≠ticos: Posible problema en prompts de IA');
    }
    
    res.json(summary);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 7. Data Coverage Analysis - What data was collected and analyzed
app.get('/api/debug/assessments/:id/data-coverage', async (req, res) => {
  try {
    const { id } = req.params;
    
    const dataRes = await pool.query('SELECT data FROM assessment_data WHERE assessment_id = $1', [id]);
    if (dataRes.rows.length === 0) {
      return res.status(404).json({ error: 'No data found for assessment' });
    }
    
    let rawData;
    if (Buffer.isBuffer(dataRes.rows[0].data)) {
      rawData = JSON.parse(zlib.gunzipSync(dataRes.rows[0].data).toString());
    } else {
      rawData = dataRes.rows[0].data;
    }
    
    const coverage = {
      timestamp: new Date().toISOString(),
      categories: [],
      missingCategories: [],
      dataQuality: {
        score: 0,
        issues: []
      },
      sampleData: {}
    };
    
    let categoriesWithData = 0;
    
    for (const category of CATEGORIES) {
      const catData = extractCategoryData(rawData, category);
      const catInfo = {
        name: category,
        hasData: false,
        count: 0,
        fields: [],
        sampleSize: 0
      };
      
      if (catData && catData.length > 0) {
        catInfo.hasData = true;
        catInfo.count = catData.length;
        categoriesWithData++;
        
        // Extract field names from first item
        if (catData[0] && typeof catData[0] === 'object') {
          catInfo.fields = Object.keys(catData[0]).slice(0, 15);
        }
        
        // Add sample (first 2 items, sanitized)
        coverage.sampleData[category] = catData.slice(0, 2).map(item => {
          if (typeof item === 'object') {
            const sanitized = {};
            Object.keys(item).slice(0, 10).forEach(k => {
              const val = item[k];
              if (typeof val === 'string' && val.length > 100) {
                sanitized[k] = val.substring(0, 100) + '...';
              } else if (Array.isArray(val)) {
                sanitized[k] = `[Array: ${val.length} items]`;
              } else {
                sanitized[k] = val;
              }
            });
            return sanitized;
          }
          return item;
        });
        
        coverage.categories.push(catInfo);
      } else {
        coverage.missingCategories.push(category);
      }
    }
    
    // Calculate data quality score
    const expectedCategories = ['Users', 'Computers', 'Groups', 'GPOs', 'OUs'];
    const criticalMissing = expectedCategories.filter(c => coverage.missingCategories.includes(c));
    
    coverage.dataQuality.score = Math.round((categoriesWithData / CATEGORIES.length) * 100);
    
    if (criticalMissing.length > 0) {
      coverage.dataQuality.issues.push(`Categor√≠as cr√≠ticas faltantes: ${criticalMissing.join(', ')}`);
      coverage.dataQuality.score = Math.max(0, coverage.dataQuality.score - (criticalMissing.length * 10));
    }
    
    if (categoriesWithData < 5) {
      coverage.dataQuality.issues.push('Muy pocas categor√≠as con datos - verificar script de recolecci√≥n');
    }
    
    // Check for empty or minimal data
    coverage.categories.forEach(cat => {
      if (cat.count === 1) {
        coverage.dataQuality.issues.push(`${cat.name}: Solo 1 objeto - posible error de recolecci√≥n`);
      }
    });
    
    res.json(coverage);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 8. Findings Analytics - Detailed analysis of generated findings
app.get('/api/debug/assessments/:id/findings-analytics', async (req, res) => {
  try {
    const { id } = req.params;
    
    const findingsRes = await pool.query('SELECT * FROM findings WHERE assessment_id = $1', [id]);
    const findings = findingsRes.rows;
    
    if (findings.length === 0) {
      return res.json({
        message: 'No findings to analyze',
        suggestions: [
          'Verificar si el an√°lisis complet√≥ correctamente',
          'Revisar logs con /api/debug/assessments/:id/summary',
          'Usar /api/debug/assessments/:id/analyze para re-ejecutar'
        ]
      });
    }
    
    const analytics = {
      overview: {
        total: findings.length,
        unique_categories: [...new Set(findings.map(f => f.category_id).filter(Boolean))].length,
        avg_affected_objects: 0
      },
      distribution: {
        bySeverity: {},
        byCategory: {},
        byAffectedCount: { '0': 0, '1-5': 0, '6-20': 0, '21-50': 0, '50+': 0 }
      },
      quality: {
        score: 100,
        issues: [],
        warnings: []
      },
      patterns: {
        duplicateTitles: [],
        emptyEvidence: [],
        noRemediation: [],
        suspiciousFindings: []
      },
      details: []
    };
    
    const titleCounts = {};
    let totalAffected = 0;
    
    findings.forEach(f => {
      // Severity distribution
      const sev = f.severity || 'unknown';
      analytics.distribution.bySeverity[sev] = (analytics.distribution.bySeverity[sev] || 0) + 1;
      
      // Category distribution
      const cat = f.category_id || 'Uncategorized';
      analytics.distribution.byCategory[cat] = (analytics.distribution.byCategory[cat] || 0) + 1;
      
      // Affected objects analysis
      const evidence = f.evidence || {};
      const affected = evidence.affected_objects || [];
      const affectedCount = affected.length;
      totalAffected += affectedCount;
      
      if (affectedCount === 0) analytics.distribution.byAffectedCount['0']++;
      else if (affectedCount <= 5) analytics.distribution.byAffectedCount['1-5']++;
      else if (affectedCount <= 20) analytics.distribution.byAffectedCount['6-20']++;
      else if (affectedCount <= 50) analytics.distribution.byAffectedCount['21-50']++;
      else analytics.distribution.byAffectedCount['50+']++;
      
      // Track duplicates
      titleCounts[f.title] = (titleCounts[f.title] || 0) + 1;
      
      // Quality checks
      if (!evidence || Object.keys(evidence).length === 0) {
        analytics.patterns.emptyEvidence.push(f.title);
      }
      if (!f.remediation || f.remediation.trim().length < 20) {
        analytics.patterns.noRemediation.push(f.title);
      }
      
      // Suspicious patterns (potential hallucinations)
      if (affected.some(obj => obj.includes('ejemplo') || obj.includes('test123') || obj.includes('sample'))) {
        analytics.patterns.suspiciousFindings.push({
          title: f.title,
          reason: 'Contiene objetos con nombres sospechosos (ejemplo, test, sample)'
        });
      }
      
      // Add to details
      analytics.details.push({
        id: f.id,
        title: f.title,
        severity: f.severity,
        category: f.category_id,
        affectedCount: affectedCount,
        hasRemediation: !!(f.remediation && f.remediation.length > 20),
        hasEvidence: !!(evidence && Object.keys(evidence).length > 0)
      });
    });
    
    // Calculate averages
    analytics.overview.avg_affected_objects = Math.round(totalAffected / findings.length);
    
    // Find duplicates
    Object.entries(titleCounts).forEach(([title, count]) => {
      if (count > 1) {
        analytics.patterns.duplicateTitles.push({ title, count });
      }
    });
    
    // Calculate quality score
    if (analytics.patterns.duplicateTitles.length > 0) {
      analytics.quality.score -= 15;
      analytics.quality.issues.push(`${analytics.patterns.duplicateTitles.length} hallazgos duplicados detectados`);
    }
    if (analytics.patterns.emptyEvidence.length > findings.length * 0.3) {
      analytics.quality.score -= 20;
      analytics.quality.issues.push(`${Math.round(analytics.patterns.emptyEvidence.length / findings.length * 100)}% de hallazgos sin evidencia`);
    }
    if (analytics.patterns.suspiciousFindings.length > 0) {
      analytics.quality.score -= 25;
      analytics.quality.issues.push(`${analytics.patterns.suspiciousFindings.length} hallazgos sospechosos (posibles alucinaciones)`);
    }
    if (analytics.patterns.noRemediation.length > findings.length * 0.2) {
      analytics.quality.score -= 10;
      analytics.quality.warnings.push(`${analytics.patterns.noRemediation.length} hallazgos con remediaci√≥n insuficiente`);
    }
    
    analytics.quality.score = Math.max(0, analytics.quality.score);
    
    res.json(analytics);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 9. Deep Grounding Check - Verify all findings against source data
app.get('/api/debug/assessments/:id/grounding-check', async (req, res) => {
  try {
    const { id } = req.params;
    
    // Get findings
    const findingsRes = await pool.query('SELECT * FROM findings WHERE assessment_id = $1', [id]);
    const findings = findingsRes.rows;
    
    // Get raw data
    const dataRes = await pool.query('SELECT data FROM assessment_data WHERE assessment_id = $1', [id]);
    if (dataRes.rows.length === 0) {
      return res.status(404).json({ error: 'No source data found' });
    }
    
    let rawData;
    if (Buffer.isBuffer(dataRes.rows[0].data)) {
      rawData = JSON.parse(zlib.gunzipSync(dataRes.rows[0].data).toString());
    } else {
      rawData = dataRes.rows[0].data;
    }
    
    const groundingReport = {
      timestamp: new Date().toISOString(),
      summary: {
        totalFindings: findings.length,
        verified: 0,
        unverified: 0,
        partiallyVerified: 0,
        globalFindings: 0,
        groundingScore: 0
      },
      validNames: {
        total: 0,
        sample: []
      },
      details: [],
      hallucinations: [],
      recommendations: []
    };
    
    // Build comprehensive valid names set with deep extraction
    const validNames = new Set();
    const validNamesMap = {}; // Track source category
    
    const extractNames = (obj, category = 'unknown', path = '') => {
      if (!obj) return;
      
      if (typeof obj === 'string') {
        if (obj.length > 2 && obj.length < 150) {
          const clean = obj.toLowerCase().trim();
          validNames.add(clean);
          if (!validNamesMap[clean]) validNamesMap[clean] = [];
          validNamesMap[clean].push(category);
        }
        return;
      }
      
      if (Array.isArray(obj)) {
        obj.forEach((item, idx) => extractNames(item, category, `${path}[${idx}]`));
        return;
      }
      
      if (typeof obj === 'object') {
        Object.keys(obj).forEach(key => {
          // Add key itself as valid name
          if (key.length > 2 && key.length < 100) {
            validNames.add(key.toLowerCase());
          }
          extractNames(obj[key], category, `${path}.${key}`);
        });
      }
    };
    
    // Extract from all categories
    CATEGORIES.forEach(cat => {
      const catData = extractCategoryData(rawData, cat);
      if (catData) {
        catData.forEach(item => extractNames(item, cat));
      }
    });
    
    groundingReport.validNames.total = validNames.size;
    groundingReport.validNames.sample = Array.from(validNames).slice(0, 50);
    
    // Verify each finding
    findings.forEach(f => {
      const evidence = f.evidence || {};
      const affected = evidence.affected_objects || [];
      
      const findingCheck = {
        id: f.id,
        title: f.title,
        severity: f.severity,
        category: f.category_id,
        affectedObjects: affected.length,
        status: 'pending',
        verifiedObjects: [],
        unverifiedObjects: [],
        verificationRate: 0
      };
      
      if (affected.length === 0) {
        // Global finding (no specific objects)
        findingCheck.status = 'global';
        groundingReport.summary.globalFindings++;
      } else {
        // Verify each affected object
        affected.forEach(obj => {
          // Clean object name for comparison
          const cleanVersions = [
            obj.toLowerCase().trim(),
            obj.replace(/^CN=|,.*/g, '').toLowerCase().trim(),
            obj.split('\\').pop()?.toLowerCase().trim(),
            obj.split('@')[0]?.toLowerCase().trim()
          ].filter(Boolean);
          
          const isValid = cleanVersions.some(v => validNames.has(v));
          
          if (isValid) {
            findingCheck.verifiedObjects.push(obj);
          } else {
            findingCheck.unverifiedObjects.push(obj);
          }
        });
        
        findingCheck.verificationRate = Math.round(
          (findingCheck.verifiedObjects.length / affected.length) * 100
        );
        
        if (findingCheck.verificationRate === 100) {
          findingCheck.status = 'verified';
          groundingReport.summary.verified++;
        } else if (findingCheck.verificationRate >= 50) {
          findingCheck.status = 'partial';
          groundingReport.summary.partiallyVerified++;
        } else {
          findingCheck.status = 'unverified';
          groundingReport.summary.unverified++;
          
          // Add to hallucinations list
          groundingReport.hallucinations.push({
            findingId: f.id,
            title: f.title,
            severity: f.severity,
            invalidObjects: findingCheck.unverifiedObjects.slice(0, 10),
            verificationRate: findingCheck.verificationRate
          });
        }
      }
      
      groundingReport.details.push(findingCheck);
    });
    
    // Calculate grounding score
    const verifiableFindings = findings.length - groundingReport.summary.globalFindings;
    if (verifiableFindings > 0) {
      groundingReport.summary.groundingScore = Math.round(
        ((groundingReport.summary.verified + (groundingReport.summary.partiallyVerified * 0.5)) / verifiableFindings) * 100
      );
    } else {
      groundingReport.summary.groundingScore = 100; // All global findings
    }
    
    // Generate recommendations
    if (groundingReport.hallucinations.length > 0) {
      groundingReport.recommendations.push({
        priority: 'high',
        action: 'Revisar prompts de IA para reforzar grounding',
        details: `${groundingReport.hallucinations.length} hallazgos contienen objetos no verificables`
      });
    }
    if (groundingReport.summary.groundingScore < 70) {
      groundingReport.recommendations.push({
        priority: 'critical',
        action: 'Re-ejecutar an√°lisis con prompts mejorados',
        details: `Score de grounding ${groundingReport.summary.groundingScore}% es demasiado bajo`
      });
    }
    if (groundingReport.summary.globalFindings > findings.length * 0.5) {
      groundingReport.recommendations.push({
        priority: 'medium',
        action: 'Verificar que los hallazgos incluyan objetos espec√≠ficos afectados',
        details: `${Math.round(groundingReport.summary.globalFindings / findings.length * 100)}% de hallazgos son globales`
      });
    }
    
    res.json(groundingReport);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// 10. List all assessments for debugging
app.get('/api/debug/assessments', async (req, res) => {
  try {
    const result = await pool.query(`
      SELECT 
        a.id,
        a.domain,
        a.status,
        a.created_at,
        a.completed_at,
        (SELECT COUNT(*) FROM findings WHERE assessment_id = a.id) as findings_count,
        (SELECT COUNT(*) FROM assessment_data WHERE assessment_id = a.id) as has_data
      FROM assessments a
      ORDER BY a.created_at DESC
      LIMIT 50
    `);
    
    res.json({
      total: result.rows.length,
      assessments: result.rows.map(a => ({
        id: a.id,
        domain: a.domain,
        status: a.status,
        created: a.created_at,
        completed: a.completed_at,
        findings: parseInt(a.findings_count),
        hasData: parseInt(a.has_data) > 0
      }))
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Helper function to process assessment data
async function processAssessmentData(assessmentId, jsonData) {
  try {
    console.log(`[${timestamp()}] [PROCESS] Starting analysis for assessment ${assessmentId}`);
    await addLog(assessmentId, 'info', 'Iniciando an√°lisis de categor√≠as...');

    // Clear existing findings to prevents duplicates/zombie data (Fix for Hallucinations persistence)
    await pool.query('DELETE FROM findings WHERE assessment_id = $1', [assessmentId]);
    await addLog(assessmentId, 'info', 'Limpiando hallazgos anteriores...');

    // Update assessment status
    await pool.query(
      'UPDATE assessments SET status = $1, analysis_progress = $2, updated_at = NOW() WHERE id = $3',
      ['analyzing', JSON.stringify({ total: CATEGORIES.length, completed: 0, current: null }), assessmentId]
    );

    let completedCategories = 0;

    // Process each category
    for (const category of CATEGORIES) {
      try {
        await addLog(assessmentId, 'info', `Analizando categor√≠a: ${category}`, category);

        const categoryData = extractCategoryData(jsonData, category);

        if (!categoryData || categoryData.length === 0) {
          await addLog(assessmentId, 'info', `Categor√≠a ${category} sin datos, omitiendo`, category);
          completedCategories++;
          continue;
        }

        await addLog(assessmentId, 'info', `Procesando ${categoryData.length} elementos de ${category}`, category);

        // Analyze with AI
        const findings = await analyzeCategory(assessmentId, category, categoryData);

        if (findings && findings.length > 0) {
          await addLog(assessmentId, 'info', `${findings.length} hallazgos encontrados en ${category}`, category);
        } else {
          await addLog(assessmentId, 'info', `No se encontraron hallazgos en ${category}`, category);
        }

        completedCategories++;

        // Update progress
        await pool.query(
          'UPDATE assessments SET analysis_progress = $1, updated_at = NOW() WHERE id = $2',
          [JSON.stringify({ total: CATEGORIES.length, completed: completedCategories, current: category }), assessmentId]
        );

      } catch (categoryError) {
        console.error(`[${timestamp()}] [PROCESS] Error analyzing ${category}:`, categoryError);
        await addLog(assessmentId, 'error', `Error en categor√≠a ${category}: ${categoryError.message}`, category);
      }
    }

    // Mark as completed
    await pool.query(
      'UPDATE assessments SET status = $1, completed_at = NOW(), updated_at = NOW() WHERE id = $2',
      ['completed', assessmentId]
    );

    await addLog(assessmentId, 'info', 'An√°lisis completado exitosamente');
    console.log(`[${timestamp()}] [PROCESS] Analysis completed for assessment ${assessmentId}`);

  } catch (error) {
    console.error(`[${timestamp()}] [PROCESS] Fatal error processing assessment:`, error);
    await addLog(assessmentId, 'error', `Error cr√≠tico: ${error.message}`);
    await pool.query(
      'UPDATE assessments SET status = $1, updated_at = NOW() WHERE id = $2',
      ['failed', assessmentId]
    );
  }
}




// Authentik Setup Endpoint
app.post('/api/setup', async (req, res) => {
  try {
    const { authentik_url, api_token, app_url } = req.body;

    if (!authentik_url || !api_token || !app_url) {
      return res.status(400).json({ success: false, error: 'All fields are required' });
    }

    const setup = new WebAuthentikSetup(authentik_url, api_token, app_url);
    const result = await setup.setup();

    if (result.success) {
      res.json({
        success: true,
        message: 'Configuration completed successfully!',
        client_id: result.client_id,
        redirect_uri: result.redirect_uri,
        next_step: 'Restart the application to apply changes'
      });
    } else {
      res.status(400).json({
        success: false,
        error: result.error || 'Unknown error',
        step: result.step
      });
    }
  } catch (error) {
    console.error('Setup error:', error);
    res.status(500).json({ success: false, error: `Setup failed: ${error.message}` });
  }
});

// Health Check
app.get('/api/health', (req, res) => {
  res.json({
    status: 'online',
    timestamp: new Date().toISOString(),
    environment: process.env.NODE_ENV
  });
});

// Serve static files from 'public' directory
app.use(express.static(path.join(__dirname, 'public')));

// Handle React routing, return all requests to React app
app.get('*', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

// Start Server
app.listen(PORT, '0.0.0.0', () => {
  console.log(`üöÄ Server running on port ${PORT}`);
  console.log(`Environment: ${process.env.NODE_ENV || 'development'}`);
});
